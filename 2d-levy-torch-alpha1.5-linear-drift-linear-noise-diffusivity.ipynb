{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "# import torch.nn.init as init\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "from scipy.stats import levy_stable\n",
    "import datetime\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "\n",
    "from scipy import optimize\n",
    "from scipy import integrate\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook parameters\n",
    "random_seed = 1\n",
    "step_size = 1e-1  # 5e-2 # step size\n",
    "n_pts = 5000      # number of points (one-dim)\n",
    "alpha = 1.5\n",
    "\n",
    "n_x=5 #number of different x\n",
    "\n",
    "n_totlal = n_pts * n_x\n",
    "\n",
    "#n_layers = 2\n",
    "n_hidden_dim = 25\n",
    "\n",
    "n_input_dim = 2\n",
    "n_output_dim = 2 \n",
    "\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "\n",
    "\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    #torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    # random.seed(seed)\n",
    "    #torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape (25000, 2) (25000, 2)\n"
     ]
    }
   ],
   "source": [
    "# added: data generation \n",
    "setup_seed(random_seed)\n",
    "class SDEIntegrators:\n",
    "    \"\"\"\n",
    "    Implements the common Euler-Maruyama\n",
    "    scheme used in integration of SDE.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def euler_maruyama(xn, h, _f_sigma, rng):\n",
    "\n",
    "        #np.random.seed(random_seed)\n",
    "        dL = levy_stable.rvs(alpha=alpha, beta=0, size=xn.shape, scale=h**(1/alpha))    # added for levy \n",
    "        \n",
    "        xk = xn.reshape(1, -1)  # we only allow a single point as input\n",
    "\n",
    "        fk, sk = _f_sigma(xk)\n",
    "        if np.prod(sk.shape) == xk.shape[-1]:\n",
    "            skL = sk * dL  \n",
    "        else:\n",
    "            sk = sk.reshape(xk.shape[-1], xk.shape[-1])\n",
    "            skL = ((sk @ dL.T).T)\n",
    "        return xk + h * fk + skL   # added for levy \n",
    "\n",
    "    \n",
    "def sample_data(drift_diffusivity, step_size, n_dimensions, low, high, n_pts, rng, n_subsample=1):\n",
    "\n",
    "    x0 = np.linspace(low, high, n_x+1)\n",
    "    x1 = np.tile(np.repeat(x0[:-1], n_pts/n_x), n_x)\n",
    "    x2 = np.repeat(x0[:-1], n_pts)\n",
    "    x_data = np.concatenate((x1.reshape(-1, 1),x2.reshape(-1, 1)),1)\n",
    "    y_data = x_data.copy()\n",
    "    for k in range(n_subsample):\n",
    "        y_data = np.row_stack([\n",
    "            SDEIntegrators.euler_maruyama(y_data[k, :],\n",
    "                                          step_size / n_subsample,\n",
    "                                          drift_diffusivity,\n",
    "                                          rng)\n",
    "            for k in range(x_data.shape[0])\n",
    "        ])\n",
    "\n",
    "    return x_data, y_data\n",
    "\n",
    "\n",
    "# EXAMPLE 1\n",
    "def true_drift(x):\n",
    "    return np.hstack(((x[:,0]+x[:,1]).reshape(-1,1),(4*x[:,0]-2*x[:,1]).reshape(-1,1)))\n",
    "\n",
    "\n",
    "def true_diffusivity(x):\n",
    "    return np.hstack(((0.5*x[:,1]+1).reshape(-1,1),(0.5*x[:,0]+1).reshape(-1,1)))\n",
    "\n",
    "\n",
    "def true_drift_diffusivity(x):\n",
    "    return true_drift(x), true_diffusivity(x)\n",
    "\n",
    "\n",
    "rng = np.random.default_rng(random_seed)\n",
    "\n",
    "x_data, y_data = sample_data(true_drift_diffusivity,\n",
    "                             step_size=step_size, n_dimensions=n_input_dim,\n",
    "                             low=-1, high=1, n_pts=n_pts,\n",
    "                             rng=rng)\n",
    "print('data shape', x_data.shape, y_data.shape)\n",
    "\n",
    "# print(x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trick\n",
    "\n",
    "y_mean = np.array([])\n",
    "y_median = np.array([])\n",
    "x_mean = np.array([])\n",
    "for i in range(n_x*n_x):\n",
    "    yi_mean = np.mean(y_data[(i*np.int(n_pts/n_x)):((i+1)*np.int(n_pts/n_x)),:], 0)\n",
    "    yi_median = np.median(y_data[(i*np.int(n_pts/n_x)):((i+1)*np.int(n_pts/n_x)),:], 0)\n",
    "    xi_mean = x_data[i*np.int(n_pts/n_x),:]\n",
    "    y_mean = np.append(y_mean, yi_mean)\n",
    "    y_median = np.append(y_median, yi_median)\n",
    "    x_mean = np.append(x_mean, xi_mean)\n",
    "\n",
    "y_mean = y_mean.reshape(-1,2)\n",
    "y_median = y_median.reshape(-1,2)\n",
    "x_mean = x_mean.reshape(-1,2)\n",
    "# print(y_mean, y_median, x_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#20% statistics\n",
    "\n",
    "y_mean2 = np.array([])\n",
    "#####\n",
    "for i in range(n_x * n_x):\n",
    "    yi_mean1 = np.mean(np.sort(y_data[:, 0].ravel()[(i*np.int(n_pts/n_x)):((i+1)*np.int(n_pts/n_x))])[400:600]) ##\n",
    "    yi_mean2 = np.mean(np.sort(y_data[:, 1].ravel()[(i*np.int(n_pts/n_x)):((i+1)*np.int(n_pts/n_x))])[400:600])\n",
    "    yi_mean = np.array([yi_mean1, yi_mean2])\n",
    "    y_mean2 = np.append(y_mean2, yi_mean)\n",
    "    \n",
    "y_mean2 = y_mean2.reshape(-1,2)\n",
    "# print(y_mean2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#network initialization\n",
    "small_init=1e-2\n",
    "def weight_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.constant_(m.bias,0.1)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        m.weight.data.fill_(1)\n",
    "        m.bias.data.zero_()\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.uniform_(m.weight.data,-small_init,small_init)\n",
    "        nn.init.uniform_(m.bias,-small_init,small_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neural network structure\n",
    "class FCNN1(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, hidden_dim):\n",
    "        super(FCNN1,self).__init__()\n",
    "        self.hidden1 = nn.Linear(in_dim, hidden_dim)\n",
    "        self.hidden2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.hidden3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.predict = nn.Linear(hidden_dim, out_dim)\n",
    "    def forward(self,input):\n",
    "        out = self.hidden1(input)\n",
    "        out = torch.nn.functional.elu(out)\n",
    "        out = self.hidden2(out)\n",
    "        out = torch.nn.functional.elu(out)\n",
    "        out = self.hidden3(out)\n",
    "        out = torch.nn.functional.elu(out)\n",
    "        out = self.predict(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "class FCNN2(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, hidden_dim):\n",
    "        super(FCNN2,self).__init__()\n",
    "        self.hidden1 = nn.Linear(in_dim, hidden_dim)\n",
    "        self.hidden2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.predict = nn.Linear(hidden_dim, out_dim)\n",
    "    def forward(self,input):\n",
    "        out = self.hidden1(input)\n",
    "        out = torch.nn.functional.elu(out)\n",
    "        out = self.hidden2(out)\n",
    "        out = torch.nn.functional.elu(out)\n",
    "        out = self.predict(out)\n",
    "        out = torch.nn.functional.softplus(out) + torch.tensor([1e-13])\n",
    "\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ms_model = FCNN(n_input_dim, n_output_dim, n_hidden_dim)\n",
    "mean_model = FCNN1(n_input_dim, n_output_dim, n_hidden_dim)\n",
    "std_model = FCNN2(int(n_input_dim/2), int(n_output_dim/2), n_hidden_dim)\n",
    "std_model2 = FCNN2(int(n_input_dim/2), int(n_output_dim/2), n_hidden_dim)\n",
    "\n",
    "# weight_init(ms_model)\n",
    "weight_init(std_model)\n",
    "# weight_init(std_model2)\n",
    "\n",
    "# optimizer = optim.Adamax(ms_model.parameters(), lr=0.005,eps=1e-07)\n",
    "optimizer1 = optim.Adam(mean_model.parameters(), lr=0.005)\n",
    "optimizer2 = optim.Adamax(std_model.parameters(),lr=0.005, eps=1e-07)\n",
    "optimizer3 = optim.Adamax(std_model2.parameters(),lr=0.005, eps=1e-07)\n",
    "#optimizer2 = optim.Adamax(std_model.parameters(),lr=0.001, eps=1e-07)\n",
    "#mean_model,std_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20203815960784008"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#S0(alpha,beta,sigmma,gamma),beta=0,sigmma=1,gamma=0 in numpy\n",
    "import math\n",
    "def pdf_zolotarev(x, alpha=alpha):\n",
    "    \"\"\"Calculate pdf using Zolotarev's methods as detailed in [BS].\n",
    "    \"\"\"\n",
    "    \n",
    "    if alpha != 1:\n",
    "        x0 = x   # convert to S_0 parameterization\n",
    "        \n",
    "        def V(theta):\n",
    "            return (np.cos(theta)/np.sin(alpha*theta))**(alpha/(alpha-1)) * \\\n",
    "                    (np.cos((alpha-1)*theta)/np.cos(theta))\n",
    "        if x0 > 0:\n",
    "            def g(theta):\n",
    "                return (V(theta) *\n",
    "                        np.real(np.complex128(x0)**(alpha/(alpha-1))))\n",
    "\n",
    "            def f(theta):\n",
    "                return g(theta) * np.exp(-g(theta))\n",
    "\n",
    "            # spare calculating integral on null set\n",
    "            # use isclose as macos has fp differences\n",
    "\n",
    "            with np.errstate(all=\"ignore\"):\n",
    "                intg_max = optimize.minimize_scalar(lambda theta: -f(theta), bounds=[0, np.pi/2])\n",
    "                intg_kwargs = {}\n",
    "                # windows quadpack less forgiving with points out of bounds\n",
    "                if intg_max.success and not np.isnan(intg_max.fun)\\\n",
    "                        and intg_max.x > 0 and intg_max.x < np.pi/2:\n",
    "                    intg_kwargs[\"points\"] = [intg_max.x]\n",
    "                intg = integrate.quad(f, 0, np.pi/2, **intg_kwargs)[0]\n",
    "                return alpha * intg / np.pi / np.abs(alpha-1) / x0\n",
    "        elif x0 == 0:\n",
    "            return math.gamma(1+1/alpha)/np.pi\n",
    "        else:\n",
    "            return pdf_zolotarev(-x, alpha)\n",
    "r=pdf_zolotarev(1);r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2020], grad_fn=<DivBackward0>) tensor([-0.1356])\n"
     ]
    }
   ],
   "source": [
    "#S0(alpha,beta,sigmma,gamma),beta=0,sigmma=1,gamma=0 in torch\n",
    "import math\n",
    "def pdf_zolotarev2(x0, alpha=alpha):\n",
    "    \"\"\"Calculate pdf using Zolotarev's methods as detailed in [BS].\n",
    "    \"\"\"\n",
    "    small_value = torch.Tensor([1e-8])\n",
    "    \n",
    "    if alpha != 1:\n",
    "        #x0 = x   # convert to S_0 parameterization\n",
    "        #x0 = torch.tensor([x], dtype=torch.float32, requires_grad=True)\n",
    "        def V(theta):\n",
    "            if alpha > 1:\n",
    "                if torch.sin(alpha*theta) == 0 or torch.cos(theta) == 0:\n",
    "                    return (torch.cos(theta)/(torch.sin(alpha*theta) + small_value))**(alpha/(alpha-1)) * \\\n",
    "                            (torch.cos((alpha-1)*theta)/(torch.cos(theta) + small_value))\n",
    "                else:\n",
    "                    return (torch.cos(theta)/torch.sin(alpha*theta))**(alpha/(alpha-1)) * \\\n",
    "                            (torch.cos((alpha-1)*theta)/torch.cos(theta))\n",
    "            else:\n",
    "                if theta == torch.tensor([np.pi/2]):\n",
    "                    return ((torch.cos(theta)+small_value)/torch.sin(alpha*theta))**(alpha/(alpha-1)) * \\\n",
    "                            (torch.cos((alpha-1)*theta)/(torch.cos(theta)+small_value))\n",
    "                else:\n",
    "                    return (torch.cos(theta)/torch.sin(alpha*theta))**(alpha/(alpha-1)) * \\\n",
    "                            (torch.cos((alpha-1)*theta)/torch.cos(theta))\n",
    "        if x0 > 0:\n",
    "            def g(theta):\n",
    "                return (V(theta) * x0 **(alpha/(alpha-1)))\n",
    "#                         torch.real(torch.complex(x0,torch.Tensor([0.]))**(alpha/(alpha-1))))\n",
    "\n",
    "            def f(theta):\n",
    "                return g(theta) * torch.exp(-g(theta))\n",
    "\n",
    "            # spare calculating integral on null set\n",
    "            # use isclose as macos has fp differences\n",
    "            intg_n = 100 \n",
    "            theta = torch.linspace(0., np.pi/2, intg_n+1)\n",
    "            ff = torch.zeros_like(theta, dtype=torch.float32)\n",
    "            for i in range(theta.shape[0]):\n",
    "                ff[i] = f(theta[i])\n",
    "        \n",
    "#             fnotnan = ff>=0\n",
    "#             fnan =~fnotnan\n",
    "#             ff = torch.where(fnan, torch.zeros_like(ff,dtype=torch.float32), ff)\n",
    "            intg = 0\n",
    "            for i in range(intg_n):\n",
    "                intg += (ff[i + 1] + ff[i]) * (theta[1] - theta[0]) / 2\n",
    "\n",
    "            \n",
    "            return alpha * intg / np.pi / np.abs((alpha-1))/ x0\n",
    "        elif x0 == 0:\n",
    "            return torch.Tensor([math.gamma(1+1/alpha)/np.pi]) + 0*x0\n",
    "        else:\n",
    "            return pdf_zolotarev2(-x0, alpha)\n",
    "        \n",
    "t=torch.tensor([1.],requires_grad=True)\n",
    "r=pdf_zolotarev2(t);r.backward()\n",
    "print(r,t.grad)\n",
    "#r=pdf_zolotarev2(69814);r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#S_alpha(h**(1/alpha)*sigma(x),0,x+f(x)*h) pdf\n",
    "def alpha_stable_pdf(yn, ynp1, step_size_, drift_, diffusivity_, alpha=alpha):\n",
    "    \n",
    "    f_alpha = torch.zeros_like(torch.Tensor(yn))\n",
    "    ynp1_std = ((ynp1-yn-step_size_*drift_)/(step_size_**(1/alpha)*diffusivity_))\n",
    "    for k in range(yn.shape[0]):\n",
    "        f_alpha[k] = pdf_zolotarev2(ynp1_std[k])\n",
    "\n",
    "\n",
    "    return f_alpha/(step_size_**(1/alpha)*diffusivity_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prob_loss(mean, std, step_size, x, y):\n",
    "    \n",
    "    y_dist = alpha_stable_pdf(x.reshape(-1,1) ,y.reshape(-1,1), step_size, mean.reshape(-1,1), std.reshape(-1,1))\n",
    "    y_log_prob = -torch.log(y_dist)\n",
    "    return y_log_prob\n",
    "\n",
    "\n",
    "def square_loss(mean, step_size, x, y):\n",
    "#     dL = levy_stable.rvs(alpha=alpha, beta=0, size=x.shape, scale=step_size**(1/alpha))\n",
    "    absloss = torch.square(y - (x + mean * step_size))# + std.reshape(-1,1) * torch.Tensor(dL)))\n",
    "    \n",
    "    return absloss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 Loss: tensor(0.0403, grad_fn=<MeanBackward0>)\n",
      "tensor([[ 0.0253,  0.1432],\n",
      "        [ 0.0167,  0.1312],\n",
      "        [ 0.0091,  0.1137],\n",
      "        [ 0.0049,  0.0890],\n",
      "        [ 0.0057,  0.0589],\n",
      "        [ 0.0151,  0.1456],\n",
      "        [ 0.0054,  0.1363],\n",
      "        [-0.0023,  0.1199],\n",
      "        [-0.0076,  0.0962],\n",
      "        [-0.0078,  0.0666],\n",
      "        [ 0.0063,  0.1447],\n",
      "        [-0.0044,  0.1377],\n",
      "        [-0.0121,  0.1231],\n",
      "        [-0.0177,  0.1008],\n",
      "        [-0.0194,  0.0731],\n",
      "        [ 0.0002,  0.1397],\n",
      "        [-0.0113,  0.1341],\n",
      "        [-0.0192,  0.1219],\n",
      "        [-0.0255,  0.1025],\n",
      "        [-0.0276,  0.0774],\n",
      "        [-0.0029,  0.1297],\n",
      "        [-0.0147,  0.1258],\n",
      "        [-0.0238,  0.1162],\n",
      "        [-0.0308,  0.1014],\n",
      "        [-0.0341,  0.0808]], grad_fn=<AddmmBackward>)\n",
      "epoch: 2 Loss: tensor(0.0381, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.0379,  0.0416],\n",
      "        [-0.0515,  0.0605],\n",
      "        [-0.0635,  0.0757],\n",
      "        [-0.0712,  0.0846],\n",
      "        [-0.0729,  0.0870],\n",
      "        [-0.0377,  0.0264],\n",
      "        [-0.0524,  0.0478],\n",
      "        [-0.0648,  0.0642],\n",
      "        [-0.0739,  0.0750],\n",
      "        [-0.0770,  0.0792],\n",
      "        [-0.0356,  0.0088],\n",
      "        [-0.0508,  0.0314],\n",
      "        [-0.0633,  0.0496],\n",
      "        [-0.0730,  0.0620],\n",
      "        [-0.0781,  0.0682],\n",
      "        [-0.0305, -0.0120],\n",
      "        [-0.0460,  0.0106],\n",
      "        [-0.0584,  0.0303],\n",
      "        [-0.0688,  0.0451],\n",
      "        [-0.0750,  0.0537],\n",
      "        [-0.0220, -0.0372],\n",
      "        [-0.0375, -0.0142],\n",
      "        [-0.0508,  0.0069],\n",
      "        [-0.0622,  0.0255],\n",
      "        [-0.0697,  0.0376]], grad_fn=<AddmmBackward>)\n",
      "epoch: 3 Loss: tensor(0.0362, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.1015, -0.0553],\n",
      "        [-0.1200, -0.0077],\n",
      "        [-0.1363,  0.0374],\n",
      "        [-0.1464,  0.0769],\n",
      "        [-0.1500,  0.1083],\n",
      "        [-0.0901, -0.0867],\n",
      "        [-0.1100, -0.0368],\n",
      "        [-0.1269,  0.0099],\n",
      "        [-0.1392,  0.0520],\n",
      "        [-0.1446,  0.0863],\n",
      "        [-0.0765, -0.1203],\n",
      "        [-0.0965, -0.0698],\n",
      "        [-0.1137, -0.0215],\n",
      "        [-0.1272,  0.0228],\n",
      "        [-0.1352,  0.0596],\n",
      "        [-0.0594, -0.1570],\n",
      "        [-0.0794, -0.1072],\n",
      "        [-0.0963, -0.0580],\n",
      "        [-0.1108, -0.0116],\n",
      "        [-0.1206,  0.0276],\n",
      "        [-0.0386, -0.1975],\n",
      "        [-0.0582, -0.1483],\n",
      "        [-0.0760, -0.0982],\n",
      "        [-0.0917, -0.0490],\n",
      "        [-0.1034, -0.0067]], grad_fn=<AddmmBackward>)\n",
      "epoch: 4 Loss: tensor(0.0345, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.1668, -0.1515],\n",
      "        [-0.1897, -0.0757],\n",
      "        [-0.2094, -0.0010],\n",
      "        [-0.2213,  0.0681],\n",
      "        [-0.2256,  0.1276],\n",
      "        [-0.1438, -0.1989],\n",
      "        [-0.1684, -0.1207],\n",
      "        [-0.1894, -0.0440],\n",
      "        [-0.2042,  0.0290],\n",
      "        [-0.2110,  0.0925],\n",
      "        [-0.1183, -0.2483],\n",
      "        [-0.1428, -0.1702],\n",
      "        [-0.1643, -0.0919],\n",
      "        [-0.1812, -0.0161],\n",
      "        [-0.1913,  0.0508],\n",
      "        [-0.0889, -0.3007],\n",
      "        [-0.1129, -0.2242],\n",
      "        [-0.1342, -0.1455],\n",
      "        [-0.1523, -0.0677],\n",
      "        [-0.1651,  0.0019],\n",
      "        [-0.0554, -0.3569],\n",
      "        [-0.0786, -0.2817],\n",
      "        [-0.1006, -0.2028],\n",
      "        [-0.1205, -0.1230],\n",
      "        [-0.1359, -0.0503]], grad_fn=<AddmmBackward>)\n",
      "epoch: 5 Loss: tensor(0.0329, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.2346, -0.2505],\n",
      "        [-0.2612, -0.1447],\n",
      "        [-0.2834, -0.0385],\n",
      "        [-0.2959,  0.0619],\n",
      "        [-0.2993,  0.1505],\n",
      "        [-0.2001, -0.3147],\n",
      "        [-0.2287, -0.2064],\n",
      "        [-0.2528, -0.0977],\n",
      "        [-0.2691,  0.0081],\n",
      "        [-0.2759,  0.1023],\n",
      "        [-0.1624, -0.3807],\n",
      "        [-0.1908, -0.2733],\n",
      "        [-0.2159, -0.1631],\n",
      "        [-0.2351, -0.0535],\n",
      "        [-0.2462,  0.0455],\n",
      "        [-0.1202, -0.4499],\n",
      "        [-0.1479, -0.3449],\n",
      "        [-0.1727, -0.2350],\n",
      "        [-0.1937, -0.1236],\n",
      "        [-0.2086, -0.0211],\n",
      "        [-0.0736, -0.5227],\n",
      "        [-0.1000, -0.4199],\n",
      "        [-0.1255, -0.3104],\n",
      "        [-0.1488, -0.1982],\n",
      "        [-0.1671, -0.0923]], grad_fn=<AddmmBackward>)\n",
      "epoch: 6 Loss: tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.3051, -0.3546],\n",
      "        [-0.3346, -0.2150],\n",
      "        [-0.3580, -0.0736],\n",
      "        [-0.3694,  0.0620],\n",
      "        [-0.3703,  0.1831],\n",
      "        [-0.2589, -0.4376],\n",
      "        [-0.2909, -0.2954],\n",
      "        [-0.3169, -0.1510],\n",
      "        [-0.3334, -0.0080],\n",
      "        [-0.3383,  0.1208],\n",
      "        [-0.2087, -0.5224],\n",
      "        [-0.2405, -0.3818],\n",
      "        [-0.2681, -0.2359],\n",
      "        [-0.2887, -0.0882],\n",
      "        [-0.2990,  0.0475],\n",
      "        [-0.1531, -0.6105],\n",
      "        [-0.1841, -0.4734],\n",
      "        [-0.2118, -0.3283],\n",
      "        [-0.2345, -0.1792],\n",
      "        [-0.2502, -0.0387],\n",
      "        [-0.0935, -0.7010],\n",
      "        [-0.1224, -0.5677],\n",
      "        [-0.1506, -0.4241],\n",
      "        [-0.1762, -0.2753],\n",
      "        [-0.1962, -0.1314]], grad_fn=<AddmmBackward>)\n",
      "epoch: 7 Loss: tensor(0.0297, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.3775, -0.4647],\n",
      "        [-0.4090, -0.2861],\n",
      "        [-0.4323, -0.1035],\n",
      "        [-0.4409,  0.0730],\n",
      "        [-0.4365,  0.2314],\n",
      "        [-0.3194, -0.5697],\n",
      "        [-0.3541, -0.3881],\n",
      "        [-0.3808, -0.2022],\n",
      "        [-0.3960, -0.0157],\n",
      "        [-0.3969,  0.1534],\n",
      "        [-0.2561, -0.6765],\n",
      "        [-0.2910, -0.4974],\n",
      "        [-0.3201, -0.3099],\n",
      "        [-0.3406, -0.1177],\n",
      "        [-0.3484,  0.0610],\n",
      "        [-0.1872, -0.7861],\n",
      "        [-0.2204, -0.6125],\n",
      "        [-0.2503, -0.4263],\n",
      "        [-0.2736, -0.2335],\n",
      "        [-0.2885, -0.0479],\n",
      "        [-0.1146, -0.8968],\n",
      "        [-0.1452, -0.7286],\n",
      "        [-0.1748, -0.5462],\n",
      "        [-0.2017, -0.3546],\n",
      "        [-0.2221, -0.1660]], grad_fn=<AddmmBackward>)\n",
      "epoch: 8 Loss: tensor(0.0280, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.4505, -0.5809],\n",
      "        [-0.4829, -0.3564],\n",
      "        [-0.5047, -0.1252],\n",
      "        [-0.5081,  0.0997],\n",
      "        [-0.4956,  0.3016],\n",
      "        [-0.3802, -0.7123],\n",
      "        [-0.4169, -0.4844],\n",
      "        [-0.4431, -0.2494],\n",
      "        [-0.4551, -0.0111],\n",
      "        [-0.4489,  0.2056],\n",
      "        [-0.3033, -0.8453],\n",
      "        [-0.3408, -0.6212],\n",
      "        [-0.3706, -0.3843],\n",
      "        [-0.3892, -0.1391],\n",
      "        [-0.3922,  0.0908],\n",
      "        [-0.2211, -0.9800],\n",
      "        [-0.2557, -0.7640],\n",
      "        [-0.2868, -0.5296],\n",
      "        [-0.3093, -0.2846],\n",
      "        [-0.3217, -0.0451],\n",
      "        [-0.1362, -1.1138],\n",
      "        [-0.1669, -0.9057],\n",
      "        [-0.1969, -0.6779],\n",
      "        [-0.2236, -0.4358],\n",
      "        [-0.2429, -0.1936]], grad_fn=<AddmmBackward>)\n",
      "epoch: 9 Loss: tensor(0.0261, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.5224, -0.7031],\n",
      "        [-0.5547, -0.4242],\n",
      "        [-0.5731, -0.1349],\n",
      "        [-0.5684,  0.1477],\n",
      "        [-0.5443,  0.3999],\n",
      "        [-0.4393, -0.8661],\n",
      "        [-0.4775, -0.5833],\n",
      "        [-0.5019, -0.2898],\n",
      "        [-0.5082,  0.0104],\n",
      "        [-0.4915,  0.2832],\n",
      "        [-0.3489, -1.0304],\n",
      "        [-0.3882, -0.7533],\n",
      "        [-0.4178, -0.4575],\n",
      "        [-0.4327, -0.1489],\n",
      "        [-0.4276,  0.1421],\n",
      "        [-0.2539, -1.1940],\n",
      "        [-0.2887, -0.9292],\n",
      "        [-0.3199, -0.6379],\n",
      "        [-0.3401, -0.3302],\n",
      "        [-0.3477, -0.0262],\n",
      "        [-0.1574, -1.3548],\n",
      "        [-0.1868, -1.1009],\n",
      "        [-0.2155, -0.8202],\n",
      "        [-0.2404, -0.5182],\n",
      "        [-0.2568, -0.2116]], grad_fn=<AddmmBackward>)\n",
      "epoch: 10 Loss: tensor(0.0241, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.5919, -0.8308],\n",
      "        [-0.6229, -0.4873],\n",
      "        [-0.6357, -0.1286],\n",
      "        [-0.6190,  0.2224],\n",
      "        [-0.5796,  0.5314],\n",
      "        [-0.4959, -1.0318],\n",
      "        [-0.5349, -0.6839],\n",
      "        [-0.5558, -0.3203],\n",
      "        [-0.5530,  0.0538],\n",
      "        [-0.5215,  0.3918],\n",
      "        [-0.3926, -1.2325],\n",
      "        [-0.4321, -0.8938],\n",
      "        [-0.4604, -0.5276],\n",
      "        [-0.4691, -0.1430],\n",
      "        [-0.4521,  0.2202],\n",
      "        [-0.2850, -1.4301],\n",
      "        [-0.3185, -1.1086],\n",
      "        [-0.3483, -0.7507],\n",
      "        [-0.3647, -0.3677],\n",
      "        [-0.3644,  0.0133],\n",
      "        [-0.1787, -1.6220],\n",
      "        [-0.2044, -1.3153],\n",
      "        [-0.2301, -0.9733],\n",
      "        [-0.2512, -0.6002],\n",
      "        [-0.2625, -0.2165]], grad_fn=<AddmmBackward>)\n",
      "epoch: 11 Loss: tensor(0.0218, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.6584, -0.9628],\n",
      "        [-0.6868, -0.5426],\n",
      "        [-0.6906, -0.1011],\n",
      "        [-0.6569,  0.3294],\n",
      "        [-0.5994,  0.7005],\n",
      "        [-0.5502, -1.2085],\n",
      "        [-0.5884, -0.7842],\n",
      "        [-0.6034, -0.3369],\n",
      "        [-0.5872,  0.1246],\n",
      "        [-0.5365,  0.5362],\n",
      "        [-0.4346, -1.4519],\n",
      "        [-0.4724, -1.0417],\n",
      "        [-0.4977, -0.5920],\n",
      "        [-0.4968, -0.1165],\n",
      "        [-0.4632,  0.3304],\n",
      "        [-0.3152, -1.6891],\n",
      "        [-0.3457, -1.3019],\n",
      "        [-0.3718, -0.8663],\n",
      "        [-0.3819, -0.3932],\n",
      "        [-0.3703,  0.0787],\n",
      "        [-0.2010, -1.9166],\n",
      "        [-0.2205, -1.5495],\n",
      "        [-0.2409, -1.1362],\n",
      "        [-0.2559, -0.6795],\n",
      "        [-0.2592, -0.2043]], grad_fn=<AddmmBackward>)\n",
      "epoch: 12 Loss: tensor(0.0194, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.7225, -1.0966],\n",
      "        [-0.7459, -0.5861],\n",
      "        [-0.7362, -0.0465],\n",
      "        [-0.6793,  0.4751],\n",
      "        [-0.6019,  0.9102],\n",
      "        [-0.6031, -1.3949],\n",
      "        [-0.6382, -0.8811],\n",
      "        [-0.6441, -0.3346],\n",
      "        [-0.6084,  0.2290],\n",
      "        [-0.5352,  0.7199],\n",
      "        [-0.4758, -1.6875],\n",
      "        [-0.5099, -1.1949],\n",
      "        [-0.5295, -0.6469],\n",
      "        [-0.5144, -0.0635],\n",
      "        [-0.4587,  0.4782],\n",
      "        [-0.3464, -1.9702],\n",
      "        [-0.3712, -1.5080],\n",
      "        [-0.3908, -0.9821],\n",
      "        [-0.3914, -0.4021],\n",
      "        [-0.3636,  0.1758],\n",
      "        [-0.2264, -2.2384],\n",
      "        [-0.2372, -1.8027],\n",
      "        [-0.2489, -1.3073],\n",
      "        [-0.2546, -0.7528],\n",
      "        [-0.2463, -0.1697]], grad_fn=<AddmmBackward>)\n",
      "epoch: 13 Loss: tensor(0.0168, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.7853, -1.2296],\n",
      "        [-0.8003, -0.6135],\n",
      "        [-0.7711,  0.0410],\n",
      "        [-0.6840,  0.6637],\n",
      "        [-0.5858,  1.1614],\n",
      "        [-0.6559, -1.5889],\n",
      "        [-0.6848, -0.9715],\n",
      "        [-0.6774, -0.3081],\n",
      "        [-0.6147,  0.3724],\n",
      "        [-0.5167,  0.9446],\n",
      "        [-0.5177, -1.9384],\n",
      "        [-0.5458, -1.3511],\n",
      "        [-0.5561, -0.6882],\n",
      "        [-0.5207,  0.0216],\n",
      "        [-0.4384,  0.6659],\n",
      "        [-0.3810, -2.2729],\n",
      "        [-0.3964, -1.7256],\n",
      "        [-0.4065, -1.0950],\n",
      "        [-0.3929, -0.3896],\n",
      "        [-0.3428,  0.3096],\n",
      "        [-0.2571, -2.5871],\n",
      "        [-0.2566, -2.0738],\n",
      "        [-0.2555, -1.4849],\n",
      "        [-0.2480, -0.8167],\n",
      "        [-0.2233, -0.1077]], grad_fn=<AddmmBackward>)\n",
      "epoch: 14 Loss: tensor(0.0140, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.8482, -1.3588],\n",
      "        [-0.8502, -0.6204],\n",
      "        [-0.7935,  0.1666],\n",
      "        [-0.6706,  0.8962],\n",
      "        [-0.5506,  1.4531],\n",
      "        [-0.7104, -1.7884],\n",
      "        [-0.7294, -1.0519],\n",
      "        [-0.7025, -0.2519],\n",
      "        [-0.6036,  0.5597],\n",
      "        [-0.4806,  1.2102],\n",
      "        [-0.5629, -2.2030],\n",
      "        [-0.5817, -1.5077],\n",
      "        [-0.5778, -0.7116],\n",
      "        [-0.5143,  0.1443],\n",
      "        [-0.4020,  0.8942],\n",
      "        [-0.4210, -2.5957],\n",
      "        [-0.4238, -1.9526],\n",
      "        [-0.4200, -1.2020],\n",
      "        [-0.3863, -0.3506],\n",
      "        [-0.3067,  0.4844],\n",
      "        [-0.2960, -2.9615],\n",
      "        [-0.2808, -2.3614],\n",
      "        [-0.2628, -1.6669],\n",
      "        [-0.2367, -0.8673],\n",
      "        [-0.1898, -0.0131]], grad_fn=<AddmmBackward>)\n",
      "epoch: 15 Loss: tensor(0.0113, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.9126, -1.4810],\n",
      "        [-0.8958, -0.6019],\n",
      "        [-0.8017,  0.3347],\n",
      "        [-0.6390,  1.1716],\n",
      "        [-0.4965,  1.7833],\n",
      "        [-0.7682, -1.9909],\n",
      "        [-0.7730, -1.1183],\n",
      "        [-0.7184, -0.1602],\n",
      "        [-0.5747,  0.7923],\n",
      "        [-0.4269,  1.5148],\n",
      "        [-0.6133, -2.4786],\n",
      "        [-0.6189, -1.6616],\n",
      "        [-0.5949, -0.7121],\n",
      "        [-0.4935,  0.3089],\n",
      "        [-0.3494,  1.1624],\n",
      "        [-0.4690, -2.9366],\n",
      "        [-0.4552, -2.1864],\n",
      "        [-0.4322, -1.2995],\n",
      "        [-0.3709, -0.2800],\n",
      "        [-0.2558,  0.7000],\n",
      "        [-0.3458, -3.3595],\n",
      "        [-0.3120, -2.6630],\n",
      "        [-0.2723, -1.8502],\n",
      "        [-0.2211, -0.9004],\n",
      "        [-0.1444,  0.1193]], grad_fn=<AddmmBackward>)\n",
      "epoch: 16 Loss: tensor(0.0085, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.9795, -1.5926],\n",
      "        [-0.9366, -0.5535],\n",
      "        [-0.7930,  0.5491],\n",
      "        [-0.5891,  1.4870],\n",
      "        [-0.4235,  2.1485],\n",
      "        [-0.8306, -2.1929],\n",
      "        [-0.8160, -1.1664],\n",
      "        [-0.7234, -0.0282],\n",
      "        [-0.5285,  1.0675],\n",
      "        [-0.3558,  1.8552],\n",
      "        [-0.6708, -2.7623],\n",
      "        [-0.6584, -1.8091],\n",
      "        [-0.6069, -0.6847],\n",
      "        [-0.4563,  0.5189],\n",
      "        [-0.2805,  1.4684],\n",
      "        [-0.5272, -3.2922],\n",
      "        [-0.4918, -2.4235],\n",
      "        [-0.4434, -1.3833],\n",
      "        [-0.3456, -0.1724],\n",
      "        [-0.1904,  0.9546],\n",
      "        [-0.4082, -3.7782],\n",
      "        [-0.3516, -2.9755],\n",
      "        [-0.2845, -2.0312],\n",
      "        [-0.2009, -0.9111],\n",
      "        [-0.0851,  0.2937]], grad_fn=<AddmmBackward>)\n",
      "epoch: 17 Loss: tensor(0.0061, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.0495, -1.6898],\n",
      "        [-0.9716, -0.4712],\n",
      "        [-0.7651,  0.8113],\n",
      "        [-0.5217,  1.8376],\n",
      "        [-0.3323,  2.5436],\n",
      "        [-0.8984, -2.3901],\n",
      "        [-0.8582, -1.1920],\n",
      "        [-0.7156,  0.1474],\n",
      "        [-0.4658,  1.3808],\n",
      "        [-0.2675,  2.2266],\n",
      "        [-0.7363, -3.0492],\n",
      "        [-0.7005, -1.9458],\n",
      "        [-0.6126, -0.6243],\n",
      "        [-0.4015,  0.7741],\n",
      "        [-0.1956,  1.8077],\n",
      "        [-0.5961, -3.6574],\n",
      "        [-0.5340, -2.6593],\n",
      "        [-0.4531, -1.4485],\n",
      "        [-0.3081, -0.0236],\n",
      "        [-0.1100,  1.2455],\n",
      "        [-0.4835, -4.2117],\n",
      "        [-0.3997, -3.2938],\n",
      "        [-0.2991, -2.2051],\n",
      "        [-0.1745, -0.8944],\n",
      "        [-0.0106,  0.5106]], grad_fn=<AddmmBackward>)\n",
      "epoch: 18 Loss: tensor(0.0040, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.1222, -1.7687],\n",
      "        [-0.9998, -0.3527],\n",
      "        [-0.7197,  1.1143],\n",
      "        [-0.4392,  2.2149],\n",
      "        [-0.2259,  2.9605],\n",
      "        [-0.9711, -2.5773],\n",
      "        [-0.8987, -1.1914],\n",
      "        [-0.6929,  0.3658],\n",
      "        [-0.3885,  1.7246],\n",
      "        [-0.1639,  2.6214],\n",
      "        [-0.8089, -3.3326],\n",
      "        [-0.7441, -2.0665],\n",
      "        [-0.6100, -0.5269],\n",
      "        [-0.3315,  1.0659],\n",
      "        [-0.0959,  2.1728],\n",
      "        [-0.6739, -4.0241],\n",
      "        [-0.5803, -2.8873],\n",
      "        [-0.4592, -1.4898],\n",
      "        [-0.2559,  0.1685],\n",
      "        [-0.0151,  1.5670],\n",
      "        [-0.5693, -4.6506],\n",
      "        [-0.4540, -3.6099],\n",
      "        [-0.3137, -2.3654],\n",
      "        [-0.1393, -0.8452],\n",
      "        [ 0.0785,  0.7643]], grad_fn=<AddmmBackward>)\n",
      "epoch: 19 Loss: tensor(0.0025, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.1962, -1.8269],\n",
      "        [-1.0205, -0.2007],\n",
      "        [-0.6627,  1.4416],\n",
      "        [-0.3469,  2.6053],\n",
      "        [-0.1108,  3.3861],\n",
      "        [-1.0464, -2.7481],\n",
      "        [-0.9359, -1.1631],\n",
      "        [-0.6551,  0.6207],\n",
      "        [-0.3005,  2.0859],\n",
      "        [-0.0505,  3.0267],\n",
      "        [-0.8848, -3.6029],\n",
      "        [-0.7864, -2.1659],\n",
      "        [-0.5968, -0.3926],\n",
      "        [-0.2495,  1.3823],\n",
      "        [ 0.0150,  2.5517],\n",
      "        [-0.7551, -4.3798],\n",
      "        [-0.6263, -3.0986],\n",
      "        [-0.4585, -1.5024],\n",
      "        [-0.1873,  0.4003],\n",
      "        [ 0.0923,  1.9081],\n",
      "        [-0.6586, -5.0797],\n",
      "        [-0.5086, -3.9120],\n",
      "        [-0.3237, -2.5038],\n",
      "        [-0.0915, -0.7595],\n",
      "        [ 0.1814,  1.0462]], grad_fn=<AddmmBackward>)\n",
      "epoch: 20 Loss: tensor(0.0017, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.2687e+00, -1.8654e+00],\n",
      "        [-1.0349e+00, -2.7890e-02],\n",
      "        [-6.0323e-01,  1.7702e+00],\n",
      "        [-2.5541e-01,  2.9875e+00],\n",
      "        [ 1.3965e-03,  3.7997e+00],\n",
      "        [-1.1185e+00, -2.8969e+00],\n",
      "        [-9.6786e-01, -1.1109e+00],\n",
      "        [-6.0649e-01,  8.9530e-01],\n",
      "        [-2.1030e-01,  2.4442e+00],\n",
      "        [ 6.2019e-02,  3.4220e+00],\n",
      "        [-9.5518e-01, -3.8483e+00],\n",
      "        [-8.2218e-01, -2.2401e+00],\n",
      "        [-5.7187e-01, -2.2938e-01],\n",
      "        [-1.6119e-01,  1.7047e+00],\n",
      "        [ 1.2824e-01,  2.9246e+00],\n",
      "        [-8.2849e-01, -4.7070e+00],\n",
      "        [-6.6369e-01, -3.2825e+00],\n",
      "        [-4.4624e-01, -1.4842e+00],\n",
      "        [-1.0355e-01,  6.5927e-01],\n",
      "        [ 2.0610e-01,  2.2503e+00],\n",
      "        [-7.3792e-01, -5.4768e+00],\n",
      "        [-5.5234e-01, -4.1834e+00],\n",
      "        [-3.2092e-01, -2.6109e+00],\n",
      "        [-2.7097e-02, -6.3802e-01],\n",
      "        [ 2.9579e-01,  1.3418e+00]], grad_fn=<AddmmBackward>)\n",
      "epoch: 21 Loss: tensor(0.0018, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.3367, -1.8917],\n",
      "        [-1.0485,  0.1399],\n",
      "        [-0.5542,  2.0682],\n",
      "        [-0.1797,  3.3301],\n",
      "        [ 0.0951,  4.1697],\n",
      "        [-1.1806, -3.0206],\n",
      "        [-0.9938, -1.0478],\n",
      "        [-0.5576,  1.1573],\n",
      "        [-0.1304,  2.7692],\n",
      "        [ 0.1599,  3.7770],\n",
      "        [-1.0099, -4.0567],\n",
      "        [-0.8459, -2.2901],\n",
      "        [-0.5373, -0.0571],\n",
      "        [-0.0763,  2.0039],\n",
      "        [ 0.2316,  3.2621],\n",
      "        [-0.8806, -4.9863],\n",
      "        [-0.6831, -3.4297],\n",
      "        [-0.4181, -1.4408],\n",
      "        [-0.0117,  0.9154],\n",
      "        [ 0.3167,  2.5653],\n",
      "        [-0.7908, -5.8157],\n",
      "        [-0.5726, -4.4067],\n",
      "        [-0.2970, -2.6807],\n",
      "        [ 0.0557, -0.4920],\n",
      "        [ 0.4154,  1.6248]], grad_fn=<AddmmBackward>)\n",
      "epoch: 22 Loss: tensor(0.0024, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.3988e+00, -1.9179e+00],\n",
      "        [-1.0689e+00,  2.7006e-01],\n",
      "        [-5.2721e-01,  2.2995e+00],\n",
      "        [-1.3224e-01,  3.5969e+00],\n",
      "        [ 1.5744e-01,  4.4580e+00],\n",
      "        [-1.2283e+00, -3.1200e+00],\n",
      "        [-1.0150e+00, -9.9498e-01],\n",
      "        [-5.2083e-01,  1.3669e+00],\n",
      "        [-7.2236e-02,  3.0247e+00],\n",
      "        [ 2.3146e-01,  4.0549e+00],\n",
      "        [-1.0421e+00, -4.2196e+00],\n",
      "        [-8.5481e-01, -2.3240e+00],\n",
      "        [-4.9902e-01,  9.2409e-02],\n",
      "        [-4.6367e-03,  2.2441e+00],\n",
      "        [ 3.1466e-01,  3.5281e+00],\n",
      "        [-9.0281e-01, -5.2010e+00],\n",
      "        [-6.7909e-01, -3.5367e+00],\n",
      "        [-3.7395e-01, -1.3891e+00],\n",
      "        [ 7.8468e-02,  1.1306e+00],\n",
      "        [ 4.1482e-01,  2.8173e+00],\n",
      "        [-8.0691e-01, -6.0734e+00],\n",
      "        [-5.6180e-01, -4.5693e+00],\n",
      "        [-2.4860e-01, -2.7158e+00],\n",
      "        [ 1.5370e-01, -3.4771e-01],\n",
      "        [ 5.3196e-01,  1.8596e+00]], grad_fn=<AddmmBackward>)\n",
      "epoch: 23 Loss: tensor(0.0033, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.4550, -1.9532],\n",
      "        [-1.1022,  0.3377],\n",
      "        [-0.5293,  2.4386],\n",
      "        [-0.1191,  3.7615],\n",
      "        [ 0.1820,  4.6364],\n",
      "        [-1.2611, -3.1972],\n",
      "        [-1.0344, -0.9712],\n",
      "        [-0.5043,  1.4959],\n",
      "        [-0.0422,  3.1846],\n",
      "        [ 0.2704,  4.2278],\n",
      "        [-1.0514, -4.3327],\n",
      "        [-0.8500, -2.3512],\n",
      "        [-0.4639,  0.1905],\n",
      "        [ 0.0472,  2.3980],\n",
      "        [ 0.3714,  3.6953],\n",
      "        [-0.8943, -5.3423],\n",
      "        [-0.6524, -3.6049],\n",
      "        [-0.3178, -1.3487],\n",
      "        [ 0.1599,  1.2754],\n",
      "        [ 0.4945,  2.9786],\n",
      "        [-0.7851, -6.2372],\n",
      "        [-0.5203, -4.6671],\n",
      "        [-0.1786, -2.7250],\n",
      "        [ 0.2597, -0.2342],\n",
      "        [ 0.6391,  2.0167]], grad_fn=<AddmmBackward>)\n",
      "epoch: 24 Loss: tensor(0.0041, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.5068, -1.9966],\n",
      "        [-1.1504,  0.3385],\n",
      "        [-0.5607,  2.4813],\n",
      "        [-0.1393,  3.8197],\n",
      "        [ 0.1703,  4.6994],\n",
      "        [-1.2822, -3.2504],\n",
      "        [-1.0545, -0.9809],\n",
      "        [-0.5097,  1.5388],\n",
      "        [-0.0400,  3.2440],\n",
      "        [ 0.2780,  4.2903],\n",
      "        [-1.0420, -4.3941],\n",
      "        [-0.8353, -2.3742],\n",
      "        [-0.4365,  0.2273],\n",
      "        [ 0.0783,  2.4596],\n",
      "        [ 0.4027,  3.7579],\n",
      "        [-0.8605, -5.4083],\n",
      "        [-0.6081, -3.6361],\n",
      "        [-0.2554, -1.3285],\n",
      "        [ 0.2299,  1.3411],\n",
      "        [ 0.5558,  3.0425],\n",
      "        [-0.7316, -6.3055],\n",
      "        [-0.4539, -4.7016],\n",
      "        [-0.0933, -2.7151],\n",
      "        [ 0.3664, -0.1658],\n",
      "        [ 0.7346,  2.0874]], grad_fn=<AddmmBackward>)\n",
      "epoch: 25 Loss: tensor(0.0043, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.5568e+00, -2.0399e+00],\n",
      "        [-1.2118e+00,  2.8474e-01],\n",
      "        [-6.1696e-01,  2.4411e+00],\n",
      "        [-1.8664e-01,  3.7851e+00],\n",
      "        [ 1.2993e-01,  4.6614e+00],\n",
      "        [-1.2970e+00, -3.2756e+00],\n",
      "        [-1.0772e+00, -1.0157e+00],\n",
      "        [-5.3445e-01,  1.5077e+00],\n",
      "        [-6.0475e-02,  3.2158e+00],\n",
      "        [ 2.6105e-01,  4.2560e+00],\n",
      "        [-1.0214e+00, -4.4040e+00],\n",
      "        [-8.1543e-01, -2.3895e+00],\n",
      "        [-4.1769e-01,  2.1058e-01],\n",
      "        [ 9.2570e-02,  2.4404e+00],\n",
      "        [ 4.1427e-01,  3.7284e+00],\n",
      "        [-8.1008e-01, -5.4032e+00],\n",
      "        [-5.5283e-01, -3.6312e+00],\n",
      "        [-1.9094e-01, -1.3259e+00],\n",
      "        [ 2.8944e-01,  1.3369e+00],\n",
      "        [ 6.0318e-01,  3.0201e+00],\n",
      "        [-6.5638e-01, -6.2854e+00],\n",
      "        [-3.7098e-01, -4.6778e+00],\n",
      "        [ 8.8171e-04, -2.6885e+00],\n",
      "        [ 4.6995e-01, -1.4080e-01],\n",
      "        [ 8.2104e-01,  2.0808e+00]], grad_fn=<AddmmBackward>)\n",
      "epoch: 26 Loss: tensor(0.0040, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.6083, -2.0738],\n",
      "        [-1.2833,  0.1954],\n",
      "        [-0.6921,  2.3385],\n",
      "        [-0.2530,  3.6792],\n",
      "        [ 0.0704,  4.5450],\n",
      "        [-1.3120, -3.2703],\n",
      "        [-1.1038, -1.0625],\n",
      "        [-0.5741,  1.4218],\n",
      "        [-0.0965,  3.1202],\n",
      "        [ 0.2283,  4.1464],\n",
      "        [-0.9977, -4.3661],\n",
      "        [-0.7955, -2.3920],\n",
      "        [-0.4066,  0.1559],\n",
      "        [ 0.0955,  2.3595],\n",
      "        [ 0.4142,  3.6271],\n",
      "        [-0.7527, -5.3354],\n",
      "        [-0.4937, -3.5927],\n",
      "        [-0.1281, -1.3330],\n",
      "        [ 0.3418,  1.2798],\n",
      "        [ 0.6434,  2.9306],\n",
      "        [-0.5707, -6.1900],\n",
      "        [-0.2802, -4.6038],\n",
      "        [ 0.0982, -2.6458],\n",
      "        [ 0.5688, -0.1488],\n",
      "        [ 0.9023,  2.0142]], grad_fn=<AddmmBackward>)\n",
      "epoch: 27 Loss: tensor(0.0033, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.6655e+00, -2.0917e+00],\n",
      "        [-1.3626e+00,  8.9140e-02],\n",
      "        [-7.8052e-01,  2.1945e+00],\n",
      "        [-3.3115e-01,  3.5245e+00],\n",
      "        [ 6.8330e-04,  4.3744e+00],\n",
      "        [-1.3338e+00, -3.2350e+00],\n",
      "        [-1.1363e+00, -1.1098e+00],\n",
      "        [-6.2473e-01,  1.3009e+00],\n",
      "        [-1.4180e-01,  2.9789e+00],\n",
      "        [ 1.8816e-01,  3.9846e+00],\n",
      "        [-9.7948e-01, -4.2867e+00],\n",
      "        [-7.8079e-01, -2.3783e+00],\n",
      "        [-4.0235e-01,  7.9612e-02],\n",
      "        [ 9.2099e-02,  2.2368e+00],\n",
      "        [ 4.0969e-01,  3.4761e+00],\n",
      "        [-6.9831e-01, -5.2168e+00],\n",
      "        [-4.3767e-01, -3.5248e+00],\n",
      "        [-6.9735e-02, -1.3418e+00],\n",
      "        [ 3.8959e-01,  1.1878e+00],\n",
      "        [ 6.8167e-01,  2.7948e+00],\n",
      "        [-4.8568e-01, -6.0351e+00],\n",
      "        [-1.9034e-01, -4.4897e+00],\n",
      "        [ 1.9336e-01, -2.5885e+00],\n",
      "        [ 6.6234e-01, -1.7759e-01],\n",
      "        [ 9.8150e-01,  1.9064e+00]], grad_fn=<AddmmBackward>)\n",
      "epoch: 28 Loss: tensor(0.0025, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.7321e+00, -2.0907e+00],\n",
      "        [-1.4481e+00, -1.8816e-02],\n",
      "        [-8.7787e-01,  2.0282e+00],\n",
      "        [-4.1520e-01,  3.3415e+00],\n",
      "        [-7.2120e-02,  4.1718e+00],\n",
      "        [-1.3686e+00, -3.1729e+00],\n",
      "        [-1.1771e+00, -1.1490e+00],\n",
      "        [-6.8365e-01,  1.1627e+00],\n",
      "        [-1.9156e-01,  2.8112e+00],\n",
      "        [ 1.4680e-01,  3.7920e+00],\n",
      "        [-9.7443e-01, -4.1745e+00],\n",
      "        [-7.7627e-01, -2.3477e+00],\n",
      "        [-4.0510e-01, -4.1891e-03],\n",
      "        [ 8.5722e-02,  2.0906e+00],\n",
      "        [ 4.0618e-01,  3.2954e+00],\n",
      "        [-6.5552e-01, -5.0606e+00],\n",
      "        [-3.9116e-01, -3.4335e+00],\n",
      "        [-1.9043e-02, -1.3467e+00],\n",
      "        [ 4.3434e-01,  1.0771e+00],\n",
      "        [ 7.2120e-01,  2.6318e+00],\n",
      "        [-4.1108e-01, -5.8384e+00],\n",
      "        [-1.0898e-01, -4.3468e+00],\n",
      "        [ 2.8148e-01, -2.5191e+00],\n",
      "        [ 7.4977e-01, -2.1649e-01],\n",
      "        [ 1.0607e+00,  1.7747e+00]], grad_fn=<AddmmBackward>)\n",
      "epoch: 29 Loss: tensor(0.0018, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.8106, -2.0715],\n",
      "        [-1.5394, -0.1180],\n",
      "        [-0.9808,  1.8552],\n",
      "        [-0.5013,  3.1477],\n",
      "        [-0.1434,  3.9565],\n",
      "        [-1.4200, -3.0900],\n",
      "        [-1.2280, -1.1760],\n",
      "        [-0.7490,  1.0216],\n",
      "        [-0.2431,  2.6338],\n",
      "        [ 0.1080,  3.5869],\n",
      "        [-0.9879, -4.0394],\n",
      "        [-0.7856, -2.3022],\n",
      "        [-0.4158, -0.0854],\n",
      "        [ 0.0777,  1.9362],\n",
      "        [ 0.4063,  3.1026],\n",
      "        [-0.6305, -4.8808],\n",
      "        [-0.3589, -3.3261],\n",
      "        [ 0.0213, -1.3449],\n",
      "        [ 0.4758,  0.9605],\n",
      "        [ 0.7632,  2.4580],\n",
      "        [-0.3539, -5.6169],\n",
      "        [-0.0419, -4.1867],\n",
      "        [ 0.3586, -2.4415],\n",
      "        [ 0.8297, -0.2577],\n",
      "        [ 1.1383,  1.6343]], grad_fn=<AddmmBackward>)\n",
      "epoch: 30 Loss: tensor(0.0011, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9002, -2.0381],\n",
      "        [-1.6352, -0.2030],\n",
      "        [-1.0867,  1.6872],\n",
      "        [-0.5873,  2.9570],\n",
      "        [-0.2110,  3.7440],\n",
      "        [-1.4880, -2.9942],\n",
      "        [-1.2891, -1.1903],\n",
      "        [-0.8194,  0.8876],\n",
      "        [-0.2951,  2.4595],\n",
      "        [ 0.0730,  3.3842],\n",
      "        [-1.0216, -3.8926],\n",
      "        [-0.8099, -2.2461],\n",
      "        [-0.4350, -0.1579],\n",
      "        [ 0.0679,  1.7851],\n",
      "        [ 0.4101,  2.9118],\n",
      "        [-0.6258, -4.6912],\n",
      "        [-0.3431, -3.2109],\n",
      "        [ 0.0496, -1.3364],\n",
      "        [ 0.5123,  0.8478],\n",
      "        [ 0.8066,  2.2862],\n",
      "        [-0.3173, -5.3874],\n",
      "        [ 0.0080, -4.0211],\n",
      "        [ 0.4222, -2.3605],\n",
      "        [ 0.9006, -0.2966],\n",
      "        [ 1.2126,  1.4962]], grad_fn=<AddmmBackward>)\n",
      "epoch: 31 Loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9968, -1.9969],\n",
      "        [-1.7325, -0.2726],\n",
      "        [-1.1924,  1.5321],\n",
      "        [-0.6716,  2.7794],\n",
      "        [-0.2743,  3.5460],\n",
      "        [-1.5671, -2.8953],\n",
      "        [-1.3575, -1.1949],\n",
      "        [-0.8925,  0.7667],\n",
      "        [-0.3472,  2.2976],\n",
      "        [ 0.0411,  3.1951],\n",
      "        [-1.0725, -3.7452],\n",
      "        [-0.8470, -2.1857],\n",
      "        [-0.4622, -0.2195],\n",
      "        [ 0.0557,  1.6454],\n",
      "        [ 0.4155,  2.7337],\n",
      "        [-0.6392, -4.5050],\n",
      "        [-0.3427, -3.0965],\n",
      "        [ 0.0658, -1.3234],\n",
      "        [ 0.5422,  0.7451],\n",
      "        [ 0.8485,  2.1261],\n",
      "        [-0.3000, -5.1646],\n",
      "        [ 0.0411, -3.8605],\n",
      "        [ 0.4716, -2.2814],\n",
      "        [ 0.9608, -0.3309],\n",
      "        [ 1.2812,  1.3680]], grad_fn=<AddmmBackward>)\n",
      "epoch: 32 Loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "tensor([[-2.0922, -1.9551],\n",
      "        [-1.8257, -0.3290],\n",
      "        [-1.2936,  1.3944],\n",
      "        [-0.7523,  2.6216],\n",
      "        [-0.3336,  3.3706],\n",
      "        [-1.6485, -2.8024],\n",
      "        [-1.4272, -1.1941],\n",
      "        [-0.9641,  0.6618],\n",
      "        [-0.3984,  2.1540],\n",
      "        [ 0.0110,  3.0276],\n",
      "        [-1.1322, -3.6082],\n",
      "        [-0.8908, -2.1275],\n",
      "        [-0.4943, -0.2707],\n",
      "        [ 0.0407,  1.5220],\n",
      "        [ 0.4198,  2.5758],\n",
      "        [-0.6645, -4.3337],\n",
      "        [-0.3531, -2.9907],\n",
      "        [ 0.0722, -1.3090],\n",
      "        [ 0.5645,  0.6552],\n",
      "        [ 0.8851,  1.9845],\n",
      "        [-0.2969, -4.9609],\n",
      "        [ 0.0605, -3.7142],\n",
      "        [ 0.5082, -2.2092],\n",
      "        [ 1.0097, -0.3604],\n",
      "        [ 1.3408,  1.2547]], grad_fn=<AddmmBackward>)\n",
      "epoch: 33 Loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "tensor([[-2.1759, -1.9198],\n",
      "        [-1.9074, -0.3758],\n",
      "        [-1.3839,  1.2765],\n",
      "        [-0.8263,  2.4875],\n",
      "        [-0.3888,  3.2230],\n",
      "        [-1.7209, -2.7237],\n",
      "        [-1.4898, -1.1931],\n",
      "        [-1.0286,  0.5731],\n",
      "        [-0.4466,  2.0318],\n",
      "        [-0.0185,  2.8863],\n",
      "        [-1.1884, -3.4910],\n",
      "        [-0.9328, -2.0777],\n",
      "        [-0.5263, -0.3138],\n",
      "        [ 0.0240,  1.4171],\n",
      "        [ 0.4204,  2.4426],\n",
      "        [-0.6922, -4.1865],\n",
      "        [-0.3672, -2.9003],\n",
      "        [ 0.0729, -1.2966],\n",
      "        [ 0.5796,  0.5792],\n",
      "        [ 0.9135,  1.8651],\n",
      "        [-0.3000, -4.7860],\n",
      "        [ 0.0721, -3.5891],\n",
      "        [ 0.5348, -2.1481],\n",
      "        [ 1.0473, -0.3854],\n",
      "        [ 1.3887,  1.1592]], grad_fn=<AddmmBackward>)\n",
      "epoch: 34 Loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "tensor([[-2.2372, -1.8963],\n",
      "        [-1.9697, -0.4166],\n",
      "        [-1.4572,  1.1787],\n",
      "        [-0.8896,  2.3787],\n",
      "        [-0.4389,  3.1053],\n",
      "        [-1.7732, -2.6650],\n",
      "        [-1.5366, -1.1961],\n",
      "        [-1.0803,  0.4993],\n",
      "        [-0.4888,  1.9324],\n",
      "        [-0.0474,  2.7735],\n",
      "        [-1.2294, -3.4000],\n",
      "        [-0.9640, -2.0411],\n",
      "        [-0.5520, -0.3510],\n",
      "        [ 0.0077,  1.3314],\n",
      "        [ 0.4161,  2.3361],\n",
      "        [-0.7123, -4.0698],\n",
      "        [-0.3775, -2.8297],\n",
      "        [ 0.0728, -1.2888],\n",
      "        [ 0.5887,  0.5168],\n",
      "        [ 0.9317,  1.7696],\n",
      "        [-0.3013, -4.6458],\n",
      "        [ 0.0817, -3.4896],\n",
      "        [ 0.5551, -2.1004],\n",
      "        [ 1.0745, -0.4065],\n",
      "        [ 1.4227,  1.0830]], grad_fn=<AddmmBackward>)\n",
      "epoch: 35 Loss: tensor(0.0010, grad_fn=<MeanBackward0>)\n",
      "tensor([[-2.2690, -1.8875],\n",
      "        [-2.0069, -0.4540],\n",
      "        [-1.5085,  1.1008],\n",
      "        [-0.9389,  2.2955],\n",
      "        [-0.4824,  3.0181],\n",
      "        [-1.7980, -2.6289],\n",
      "        [-1.5614, -1.2054],\n",
      "        [-1.1145,  0.4388],\n",
      "        [-0.5222,  1.8558],\n",
      "        [-0.0751,  2.6896],\n",
      "        [-1.2471, -3.3382],\n",
      "        [-0.9777, -2.0198],\n",
      "        [-0.5668, -0.3839],\n",
      "        [-0.0060,  1.2646],\n",
      "        [ 0.4069,  2.2567],\n",
      "        [-0.7178, -3.9862],\n",
      "        [-0.3782, -2.7809],\n",
      "        [ 0.0757, -1.2869],\n",
      "        [ 0.5937,  0.4676],\n",
      "        [ 0.9392,  1.6984],\n",
      "        [-0.2948, -4.5429],\n",
      "        [ 0.0939, -3.4175],\n",
      "        [ 0.5719, -2.0672],\n",
      "        [ 1.0922, -0.4241],\n",
      "        [ 1.4420,  1.0263]], grad_fn=<AddmmBackward>)\n",
      "epoch: 36 Loss: tensor(0.0012, grad_fn=<MeanBackward0>)\n",
      "tensor([[-2.2695, -1.8935],\n",
      "        [-2.0173, -0.4887],\n",
      "        [-1.5358,  1.0425],\n",
      "        [-0.9722,  2.2377],\n",
      "        [-0.5176,  2.9609],\n",
      "        [-1.7938, -2.6152],\n",
      "        [-1.5626, -1.2213],\n",
      "        [-1.1296,  0.3912],\n",
      "        [-0.5447,  1.8016],\n",
      "        [-0.1002,  2.6342],\n",
      "        [-1.2398, -3.3051],\n",
      "        [-0.9721, -2.0137],\n",
      "        [-0.5688, -0.4131],\n",
      "        [-0.0156,  1.2163],\n",
      "        [ 0.3937,  2.2040],\n",
      "        [-0.7068, -3.9354],\n",
      "        [-0.3676, -2.7536],\n",
      "        [ 0.0831, -1.2907],\n",
      "        [ 0.5955,  0.4314],\n",
      "        [ 0.9365,  1.6511],\n",
      "        [-0.2792, -4.4766],\n",
      "        [ 0.1099, -3.3720],\n",
      "        [ 0.5861, -2.0478],\n",
      "        [ 1.1014, -0.4379],\n",
      "        [ 1.4470,  0.9888]], grad_fn=<AddmmBackward>)\n",
      "epoch: 37 Loss: tensor(0.0014, grad_fn=<MeanBackward0>)\n",
      "tensor([[-2.2425, -1.9121],\n",
      "        [-2.0036, -0.5200],\n",
      "        [-1.5406,  1.0034],\n",
      "        [-0.9892,  2.2047],\n",
      "        [-0.5437,  2.9323],\n",
      "        [-1.7645, -2.6210],\n",
      "        [-1.5429, -1.2423],\n",
      "        [-1.1271,  0.3565],\n",
      "        [-0.5565,  1.7694],\n",
      "        [-0.1218,  2.6060],\n",
      "        [-1.2113, -3.2977],\n",
      "        [-0.9501, -2.0207],\n",
      "        [-0.5594, -0.4377],\n",
      "        [-0.0210,  1.1866],\n",
      "        [ 0.3775,  2.1768],\n",
      "        [-0.6827, -3.9143],\n",
      "        [-0.3484, -2.7453],\n",
      "        [ 0.0937, -1.2988],\n",
      "        [ 0.5942,  0.4082],\n",
      "        [ 0.9248,  1.6267],\n",
      "        [-0.2575, -4.4439],\n",
      "        [ 0.1274, -3.3505],\n",
      "        [ 0.5969, -2.0404],\n",
      "        [ 1.1022, -0.4473],\n",
      "        [ 1.4388,  0.9698]], grad_fn=<AddmmBackward>)\n",
      "epoch: 38 Loss: tensor(0.0014, grad_fn=<MeanBackward0>)\n",
      "tensor([[-2.1954, -1.9396],\n",
      "        [-1.9713, -0.5462],\n",
      "        [-1.5268,  0.9838],\n",
      "        [-0.9916,  2.1957],\n",
      "        [-0.5604,  2.9308],\n",
      "        [-1.7181, -2.6422],\n",
      "        [-1.5083, -1.2656],\n",
      "        [-1.1109,  0.3354],\n",
      "        [-0.5587,  1.7589],\n",
      "        [-0.1393,  2.6036],\n",
      "        [-1.1698, -3.3112],\n",
      "        [-0.9178, -2.0372],\n",
      "        [-0.5426, -0.4561],\n",
      "        [-0.0233,  1.1752],\n",
      "        [ 0.3593,  2.1738],\n",
      "        [-0.6524, -3.9182],\n",
      "        [-0.3258, -2.7524],\n",
      "        [ 0.1044, -1.3089],\n",
      "        [ 0.5893,  0.3987],\n",
      "        [ 0.9054,  1.6242],\n",
      "        [-0.2357, -4.4400],\n",
      "        [ 0.1422, -3.3495],\n",
      "        [ 0.6019, -2.0423],\n",
      "        [ 1.0944, -0.4512],\n",
      "        [ 1.4189,  0.9688]], grad_fn=<AddmmBackward>)\n",
      "epoch: 39 Loss: tensor(0.0014, grad_fn=<MeanBackward0>)\n",
      "tensor([[-2.1375, -1.9717],\n",
      "        [-1.9275, -0.5651],\n",
      "        [-1.4991,  0.9838],\n",
      "        [-0.9818,  2.2100],\n",
      "        [-0.5680,  2.9546],\n",
      "        [-1.6642, -2.6737],\n",
      "        [-1.4662, -1.2879],\n",
      "        [-1.0858,  0.3291],\n",
      "        [-0.5534,  1.7693],\n",
      "        [-0.1523,  2.6252],\n",
      "        [-1.1249, -3.3402],\n",
      "        [-0.8827, -2.0595],\n",
      "        [-0.5233, -0.4663],\n",
      "        [-0.0243,  1.1823],\n",
      "        [ 0.3401,  2.1936],\n",
      "        [-0.6244, -3.9418],\n",
      "        [-0.3062, -2.7707],\n",
      "        [ 0.1113, -1.3186],\n",
      "        [ 0.5798,  0.4034],\n",
      "        [ 0.8800,  1.6422],\n",
      "        [-0.2208, -4.4598],\n",
      "        [ 0.1492, -3.3648],\n",
      "        [ 0.5983, -2.0508],\n",
      "        [ 1.0780, -0.4484],\n",
      "        [ 1.3894,  0.9849]], grad_fn=<AddmmBackward>)\n",
      "epoch: 40 Loss: tensor(0.0014, grad_fn=<MeanBackward0>)\n",
      "tensor([[-2.0779, -2.0041],\n",
      "        [-1.8790, -0.5744],\n",
      "        [-1.4623,  1.0036],\n",
      "        [-0.9625,  2.2460],\n",
      "        [-0.5668,  3.0015],\n",
      "        [-1.6119, -2.7108],\n",
      "        [-1.4238, -1.3062],\n",
      "        [-1.0566,  0.3385],\n",
      "        [-0.5428,  1.8000],\n",
      "        [-0.1603,  2.6689],\n",
      "        [-1.0859, -3.3794],\n",
      "        [-0.8518, -2.0836],\n",
      "        [-0.5060, -0.4665],\n",
      "        [-0.0251,  1.2073],\n",
      "        [ 0.3213,  2.2341],\n",
      "        [-0.6062, -3.9799],\n",
      "        [-0.2952, -2.7964],\n",
      "        [ 0.1113, -1.3257],\n",
      "        [ 0.5655,  0.4223],\n",
      "        [ 0.8507,  1.6793],\n",
      "        [-0.2189, -4.4982],\n",
      "        [ 0.1441, -3.3923],\n",
      "        [ 0.5841, -2.0634],\n",
      "        [ 1.0531, -0.4383],\n",
      "        [ 1.3528,  1.0169]], grad_fn=<AddmmBackward>)\n",
      "epoch: 41 Loss: tensor(0.0012, grad_fn=<MeanBackward0>)\n",
      "tensor([[-2.0237, -2.0333],\n",
      "        [-1.8314, -0.5723],\n",
      "        [-1.4204,  1.0425],\n",
      "        [-0.9358,  2.3019],\n",
      "        [-0.5573,  3.0689],\n",
      "        [-1.5685, -2.7494],\n",
      "        [-1.3865, -1.3180],\n",
      "        [-1.0270,  0.3638],\n",
      "        [-0.5281,  1.8491],\n",
      "        [-0.1629,  2.7320],\n",
      "        [-1.0592, -3.4244],\n",
      "        [-0.8302, -2.1067],\n",
      "        [-0.4937, -0.4559],\n",
      "        [-0.0264,  1.2491],\n",
      "        [ 0.3043,  2.2930],\n",
      "        [-0.6029, -4.0280],\n",
      "        [-0.2964, -2.8263],\n",
      "        [ 0.1026, -1.3287],\n",
      "        [ 0.5466,  0.4547],\n",
      "        [ 0.8198,  1.7329],\n",
      "        [-0.2341, -4.5502],\n",
      "        [ 0.1243, -3.4287],\n",
      "        [ 0.5585, -2.0781],\n",
      "        [ 1.0208, -0.4207],\n",
      "        [ 1.3120,  1.0629]], grad_fn=<AddmmBackward>)\n",
      "epoch: 42 Loss: tensor(0.0011, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9793, -2.0569],\n",
      "        [-1.7880, -0.5584],\n",
      "        [-1.3760,  1.0989],\n",
      "        [-0.9034,  2.3749],\n",
      "        [-0.5400,  3.1534],\n",
      "        [-1.5378, -2.7866],\n",
      "        [-1.3573, -1.3221],\n",
      "        [-0.9987,  0.4041],\n",
      "        [-0.5103,  1.9141],\n",
      "        [-0.1595,  2.8114],\n",
      "        [-1.0483, -3.4718],\n",
      "        [-0.8201, -2.1268],\n",
      "        [-0.4872, -0.4347],\n",
      "        [-0.0276,  1.3053],\n",
      "        [ 0.2908,  2.3670],\n",
      "        [-0.6164, -4.0823],\n",
      "        [-0.3108, -2.8581],\n",
      "        [ 0.0853, -1.3271],\n",
      "        [ 0.5248,  0.4989],\n",
      "        [ 0.7898,  1.8003],\n",
      "        [-0.2674, -4.6121],\n",
      "        [ 0.0897, -3.4711],\n",
      "        [ 0.5222, -2.0936],\n",
      "        [ 0.9831, -0.3964],\n",
      "        [ 1.2700,  1.1201]], grad_fn=<AddmmBackward>)\n",
      "epoch: 43 Loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9458, -2.0740],\n",
      "        [-1.7500, -0.5333],\n",
      "        [-1.3302,  1.1701],\n",
      "        [-0.8666,  2.4614],\n",
      "        [-0.5155,  3.2514],\n",
      "        [-1.5204, -2.8207],\n",
      "        [-1.3365, -1.3186],\n",
      "        [-0.9721,  0.4570],\n",
      "        [-0.4896,  1.9918],\n",
      "        [-0.1500,  2.9032],\n",
      "        [-1.0525, -3.5193],\n",
      "        [-0.8209, -2.1434],\n",
      "        [-0.4857, -0.4043],\n",
      "        [-0.0279,  1.3727],\n",
      "        [ 0.2822,  2.4523],\n",
      "        [-0.6452, -4.1404],\n",
      "        [-0.3368, -2.8905],\n",
      "        [ 0.0613, -1.3216],\n",
      "        [ 0.5020,  0.5519],\n",
      "        [ 0.7631,  1.8774],\n",
      "        [-0.3167, -4.6805],\n",
      "        [ 0.0426, -3.5177],\n",
      "        [ 0.4779, -2.1098],\n",
      "        [ 0.9427, -0.3676],\n",
      "        [ 1.2297,  1.1850]], grad_fn=<AddmmBackward>)\n",
      "epoch: 44 Loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9219, -2.0849],\n",
      "        [-1.7167, -0.4991],\n",
      "        [-1.2840,  1.2517],\n",
      "        [-0.8264,  2.5571],\n",
      "        [-0.4850,  3.3582],\n",
      "        [-1.5139, -2.8515],\n",
      "        [-1.3225, -1.3090],\n",
      "        [-0.9466,  0.5191],\n",
      "        [-0.4659,  2.0776],\n",
      "        [-0.1346,  3.0029],\n",
      "        [-1.0685, -3.5662],\n",
      "        [-0.8296, -2.1571],\n",
      "        [-0.4870, -0.3679],\n",
      "        [-0.0259,  1.4469],\n",
      "        [ 0.2793,  2.5444],\n",
      "        [-0.6854, -4.2004],\n",
      "        [-0.3708, -2.9234],\n",
      "        [ 0.0336, -1.3139],\n",
      "        [ 0.4806,  0.6097],\n",
      "        [ 0.7415,  1.9599],\n",
      "        [-0.3775, -4.7531],\n",
      "        [-0.0129, -3.5673],\n",
      "        [ 0.4290, -2.1272],\n",
      "        [ 0.9024, -0.3369],\n",
      "        [ 1.1935,  1.2535]], grad_fn=<AddmmBackward>)\n",
      "epoch: 45 Loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9045, -2.0911],\n",
      "        [-1.6867, -0.4591],\n",
      "        [-1.2376,  1.3387],\n",
      "        [-0.7840,  2.6569],\n",
      "        [-0.4502,  3.4689],\n",
      "        [-1.5143, -2.8796],\n",
      "        [-1.3124, -1.2958],\n",
      "        [-0.9210,  0.5856],\n",
      "        [-0.4397,  2.1667],\n",
      "        [-0.1143,  3.1057],\n",
      "        [-1.0912, -3.6120],\n",
      "        [-0.8423, -2.1694],\n",
      "        [-0.4885, -0.3292],\n",
      "        [-0.0207,  1.5229],\n",
      "        [ 0.2820,  2.6384],\n",
      "        [-0.7315, -4.2611],\n",
      "        [-0.4082, -2.9569],\n",
      "        [ 0.0057, -1.3067],\n",
      "        [ 0.4626,  0.6676],\n",
      "        [ 0.7259,  2.0429],\n",
      "        [-0.4437, -4.8277],\n",
      "        [-0.0717, -3.6192],\n",
      "        [ 0.3795, -2.1470],\n",
      "        [ 0.8649, -0.3083],\n",
      "        [ 1.1632,  1.3207]], grad_fn=<AddmmBackward>)\n",
      "epoch: 46 Loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.8901, -2.0946],\n",
      "        [-1.6581, -0.4172],\n",
      "        [-1.1919,  1.4253],\n",
      "        [-0.7413,  2.7555],\n",
      "        [-0.4136,  3.5783],\n",
      "        [-1.5168, -2.9059],\n",
      "        [-1.3031, -1.2820],\n",
      "        [-0.8948,  0.6512],\n",
      "        [-0.4118,  2.2537],\n",
      "        [-0.0908,  3.2063],\n",
      "        [-1.1149, -3.6569],\n",
      "        [-0.8547, -2.1823],\n",
      "        [-0.4880, -0.2928],\n",
      "        [-0.0120,  1.5956],\n",
      "        [ 0.2895,  2.7291],\n",
      "        [-0.7773, -4.3215],\n",
      "        [-0.4441, -2.9918],\n",
      "        [-0.0192, -1.3027],\n",
      "        [ 0.4493,  0.7205],\n",
      "        [ 0.7164,  2.1213],\n",
      "        [-0.5086, -4.9026],\n",
      "        [-0.1281, -3.6728],\n",
      "        [ 0.3336, -2.1705],\n",
      "        [ 0.8323, -0.2858],\n",
      "        [ 1.1395,  1.3819]], grad_fn=<AddmmBackward>)\n",
      "epoch: 47 Loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.8753e+00, -2.0974e+00],\n",
      "        [-1.6299e+00, -3.7755e-01],\n",
      "        [-1.1480e+00,  1.5060e+00],\n",
      "        [-7.0019e-01,  2.8477e+00],\n",
      "        [-3.7783e-01,  3.6811e+00],\n",
      "        [-1.5172e+00, -2.9312e+00],\n",
      "        [-1.2922e+00, -1.2705e+00],\n",
      "        [-8.6783e-01,  7.1072e-01],\n",
      "        [-3.8361e-01,  2.3334e+00],\n",
      "        [-6.6293e-02,  3.2995e+00],\n",
      "        [-1.1346e+00, -3.7005e+00],\n",
      "        [-8.6323e-01, -2.1974e+00],\n",
      "        [-4.8402e-01, -2.6285e-01],\n",
      "        [-3.9552e-04,  1.6599e+00],\n",
      "        [ 3.0028e-01,  2.8115e+00],\n",
      "        [-8.1722e-01, -4.3804e+00],\n",
      "        [-4.7426e-01, -3.0281e+00],\n",
      "        [-3.8495e-02, -1.3046e+00],\n",
      "        [ 4.4149e-01,  7.6362e-01],\n",
      "        [ 7.1218e-01,  2.1901e+00],\n",
      "        [-5.6609e-01, -4.9753e+00],\n",
      "        [-1.7740e-01, -3.7271e+00],\n",
      "        [ 2.9439e-01, -2.1986e+00],\n",
      "        [ 8.0619e-01, -2.7287e-01],\n",
      "        [ 1.1226e+00,  1.4323e+00]], grad_fn=<AddmmBackward>)\n",
      "epoch: 48 Loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.8581, -2.1005],\n",
      "        [-1.6017, -0.3434],\n",
      "        [-1.1074,  1.5759],\n",
      "        [-0.6632,  2.9287],\n",
      "        [-0.3459,  3.7723],\n",
      "        [-1.5123, -2.9557],\n",
      "        [-1.2782, -1.2634],\n",
      "        [-0.8410,  0.7597],\n",
      "        [-0.3569,  2.4014],\n",
      "        [-0.0434,  3.3808],\n",
      "        [-1.1464, -3.7419],\n",
      "        [-0.8653, -2.2153],\n",
      "        [-0.4760, -0.2426],\n",
      "        [ 0.0130,  1.7116],\n",
      "        [ 0.3122,  2.8811],\n",
      "        [-0.8468, -4.4356],\n",
      "        [-0.4955, -3.0653],\n",
      "        [-0.0507, -1.3139],\n",
      "        [ 0.4387,  0.7934],\n",
      "        [ 0.7120,  2.2453],\n",
      "        [-0.6111, -5.0431],\n",
      "        [-0.2156, -3.7803],\n",
      "        [ 0.2644, -2.2313],\n",
      "        [ 0.7869, -0.2722],\n",
      "        [ 1.1116,  1.4684]], grad_fn=<AddmmBackward>)\n",
      "epoch: 49 Loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.8374, -2.1039],\n",
      "        [-1.5737, -0.3169],\n",
      "        [-1.0720,  1.6318],\n",
      "        [-0.6324,  2.9949],\n",
      "        [-0.3205,  3.8479],\n",
      "        [-1.5007, -2.9781],\n",
      "        [-1.2606, -1.2614],\n",
      "        [-0.8154,  0.7953],\n",
      "        [-0.3337,  2.4544],\n",
      "        [-0.0246,  3.4463],\n",
      "        [-1.1485, -3.7788],\n",
      "        [-0.8601, -2.2353],\n",
      "        [-0.4645, -0.2335],\n",
      "        [ 0.0266,  1.7480],\n",
      "        [ 0.3232,  2.9346],\n",
      "        [-0.8635, -4.4842],\n",
      "        [-0.5063, -3.1015],\n",
      "        [-0.0554, -1.3305],\n",
      "        [ 0.4400,  0.8078],\n",
      "        [ 0.7140,  2.2840],\n",
      "        [-0.6406, -5.1022],\n",
      "        [-0.2406, -3.8298],\n",
      "        [ 0.2447, -2.2672],\n",
      "        [ 0.7743, -0.2843],\n",
      "        [ 1.1054,  1.4878]], grad_fn=<AddmmBackward>)\n",
      "epoch: 50 Loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.8138, -2.1064],\n",
      "        [-1.5471, -0.2983],\n",
      "        [-1.0431,  1.6719],\n",
      "        [-0.6095,  3.0438],\n",
      "        [-0.3033,  3.9052],\n",
      "        [-1.4825, -2.9961],\n",
      "        [-1.2404, -1.2637],\n",
      "        [-0.7925,  0.8167],\n",
      "        [-0.3155,  2.4906],\n",
      "        [-0.0114,  3.4936],\n",
      "        [-1.1407, -3.8083],\n",
      "        [-0.8482, -2.2554],\n",
      "        [-0.4506, -0.2354],\n",
      "        [ 0.0390,  1.7679],\n",
      "        [ 0.3315,  2.9701],\n",
      "        [-0.8669, -4.5226],\n",
      "        [-0.5068, -3.1338],\n",
      "        [-0.0534, -1.3527],\n",
      "        [ 0.4442,  0.8067],\n",
      "        [ 0.7167,  2.3048],\n",
      "        [-0.6539, -5.1486],\n",
      "        [-0.2519, -3.8721],\n",
      "        [ 0.2353, -2.3037],\n",
      "        [ 0.7676, -0.3082],\n",
      "        [ 1.1028,  1.4900]], grad_fn=<AddmmBackward>)\n",
      "epoch: 51 Loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.7890e+00, -2.1058e+00],\n",
      "        [-1.5234e+00, -2.8682e-01],\n",
      "        [-1.0220e+00,  1.6961e+00],\n",
      "        [-5.9548e-01,  3.0746e+00],\n",
      "        [-2.9510e-01,  3.9427e+00],\n",
      "        [-1.4599e+00, -3.0071e+00],\n",
      "        [-1.2191e+00, -1.2681e+00],\n",
      "        [-7.7381e-01,  8.2463e-01],\n",
      "        [-3.0323e-01,  2.5095e+00],\n",
      "        [-4.8270e-03,  3.5218e+00],\n",
      "        [-1.1249e+00, -3.8271e+00],\n",
      "        [-8.3124e-01, -2.2727e+00],\n",
      "        [-4.3585e-01, -2.4612e-01],\n",
      "        [ 4.8855e-02,  1.7718e+00],\n",
      "        [ 3.3631e-01,  2.9869e+00],\n",
      "        [-8.5877e-01, -4.5474e+00],\n",
      "        [-4.9844e-01, -3.1592e+00],\n",
      "        [-4.5994e-02, -1.3777e+00],\n",
      "        [ 4.4987e-01,  7.9164e-01],\n",
      "        [ 7.1912e-01,  2.3079e+00],\n",
      "        [-6.5229e-01, -5.1785e+00],\n",
      "        [-2.5092e-01, -3.9037e+00],\n",
      "        [ 2.3484e-01, -2.3375e+00],\n",
      "        [ 7.6580e-01, -3.4111e-01],\n",
      "        [ 1.1026e+00,  1.4760e+00]], grad_fn=<AddmmBackward>)\n",
      "epoch: 52 Loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.7655e+00, -2.1000e+00],\n",
      "        [-1.5042e+00, -2.8054e-01],\n",
      "        [-1.0093e+00,  1.7057e+00],\n",
      "        [-5.9026e-01,  3.0880e+00],\n",
      "        [-2.9551e-01,  3.9608e+00],\n",
      "        [-1.4359e+00, -3.0082e+00],\n",
      "        [-1.1989e+00, -1.2721e+00],\n",
      "        [-7.6028e-01,  8.2114e-01],\n",
      "        [-2.9734e-01,  2.5125e+00],\n",
      "        [-4.6593e-03,  3.5314e+00],\n",
      "        [-1.1042e+00, -3.8326e+00],\n",
      "        [-8.1204e-01, -2.2843e+00],\n",
      "        [-4.2193e-01, -2.6276e-01],\n",
      "        [ 5.5544e-02,  1.7616e+00],\n",
      "        [ 3.3740e-01,  2.9862e+00],\n",
      "        [-8.4218e-01, -4.5558e+00],\n",
      "        [-4.8393e-01, -3.1745e+00],\n",
      "        [-3.5242e-02, -1.4020e+00],\n",
      "        [ 4.5589e-01,  7.6551e-01],\n",
      "        [ 7.2072e-01,  2.2949e+00],\n",
      "        [-6.3920e-01, -5.1893e+00],\n",
      "        [-2.4042e-01, -3.9217e+00],\n",
      "        [ 2.4143e-01, -2.3652e+00],\n",
      "        [ 7.6762e-01, -3.7918e-01],\n",
      "        [ 1.1043e+00,  1.4480e+00]], grad_fn=<AddmmBackward>)\n",
      "epoch: 53 Loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.7461, -2.0872],\n",
      "        [-1.4910, -0.2773],\n",
      "        [-1.0052,  1.7028],\n",
      "        [-0.5932,  3.0858],\n",
      "        [-0.3034,  3.9609],\n",
      "        [-1.4139, -2.9979],\n",
      "        [-1.1822, -1.2733],\n",
      "        [-0.7527,  0.8091],\n",
      "        [-0.2975,  2.5016],\n",
      "        [-0.0100,  3.5243],\n",
      "        [-1.0824, -3.8231],\n",
      "        [-0.7936, -2.2877],\n",
      "        [-0.4105, -0.2820],\n",
      "        [ 0.0587,  1.7400],\n",
      "        [ 0.3352,  2.9702],\n",
      "        [-0.8214, -4.5464],\n",
      "        [-0.4666, -3.1779],\n",
      "        [-0.0234, -1.4226],\n",
      "        [ 0.4613,  0.7320],\n",
      "        [ 0.7215,  2.2684],\n",
      "        [-0.6191, -5.1797],\n",
      "        [-0.2240, -3.9243],\n",
      "        [ 0.2525, -2.3841],\n",
      "        [ 0.7718, -0.4184],\n",
      "        [ 1.1071,  1.4097]], grad_fn=<AddmmBackward>)\n",
      "epoch: 54 Loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.7335, -2.0671],\n",
      "        [-1.4851, -0.2755],\n",
      "        [-1.0093,  1.6900],\n",
      "        [-0.6030,  3.0705],\n",
      "        [-0.3169,  3.9459],\n",
      "        [-1.3974, -2.9758],\n",
      "        [-1.1713, -1.2702],\n",
      "        [-0.7516,  0.7912],\n",
      "        [-0.3031,  2.4798],\n",
      "        [-0.0196,  3.5033],\n",
      "        [-1.0635, -3.7990],\n",
      "        [-0.7788, -2.2820],\n",
      "        [-0.4031, -0.3011],\n",
      "        [ 0.0583,  1.7103],\n",
      "        [ 0.3306,  2.9419],\n",
      "        [-0.8007, -4.5198],\n",
      "        [-0.4499, -3.1686],\n",
      "        [-0.0125, -1.4372],\n",
      "        [ 0.4652,  0.6946],\n",
      "        [ 0.7217,  2.2320],\n",
      "        [-0.5967, -5.1506],\n",
      "        [-0.2056, -3.9115],\n",
      "        [ 0.2652, -2.3929],\n",
      "        [ 0.7771, -0.4555],\n",
      "        [ 1.1110,  1.3647]], grad_fn=<AddmmBackward>)\n",
      "epoch: 55 Loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.7296e+00, -2.0406e+00],\n",
      "        [-1.4871e+00, -2.7438e-01],\n",
      "        [-1.0209e+00,  1.6697e+00],\n",
      "        [-6.1839e-01,  3.0454e+00],\n",
      "        [-3.3432e-01,  3.9192e+00],\n",
      "        [-1.3891e+00, -2.9435e+00],\n",
      "        [-1.1677e+00, -1.2627e+00],\n",
      "        [-7.5702e-01,  7.6976e-01],\n",
      "        [-3.1328e-01,  2.4500e+00],\n",
      "        [-3.1950e-02,  3.4719e+00],\n",
      "        [-1.0507e+00, -3.7620e+00],\n",
      "        [-7.6990e-01, -2.2677e+00],\n",
      "        [-4.0079e-01, -3.1821e-01],\n",
      "        [ 5.4545e-02,  1.6756e+00],\n",
      "        [ 3.2442e-01,  2.9050e+00],\n",
      "        [-7.8380e-01, -4.4784e+00],\n",
      "        [-4.3659e-01, -3.1479e+00],\n",
      "        [-4.4937e-03, -1.4451e+00],\n",
      "        [ 4.6737e-01,  6.5651e-01],\n",
      "        [ 7.2171e-01,  2.1892e+00],\n",
      "        [-5.7625e-01, -5.1047e+00],\n",
      "        [-1.8854e-01, -3.8851e+00],\n",
      "        [ 2.7740e-01, -2.3916e+00],\n",
      "        [ 7.8255e-01, -4.8787e-01],\n",
      "        [ 1.1156e+00,  1.3169e+00]], grad_fn=<AddmmBackward>)\n",
      "epoch: 56 Loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.7351e+00, -2.0101e+00],\n",
      "        [-1.4972e+00, -2.7410e-01],\n",
      "        [-1.0391e+00,  1.6438e+00],\n",
      "        [-6.3789e-01,  3.0133e+00],\n",
      "        [-3.5394e-01,  3.8845e+00],\n",
      "        [-1.3901e+00, -2.9041e+00],\n",
      "        [-1.1721e+00, -1.2519e+00],\n",
      "        [-7.6860e-01,  7.4626e-01],\n",
      "        [-3.2697e-01,  2.4153e+00],\n",
      "        [-4.5762e-02,  3.4338e+00],\n",
      "        [-1.0458e+00, -3.7160e+00],\n",
      "        [-7.6818e-01, -2.2467e+00],\n",
      "        [-4.0390e-01, -3.3289e-01],\n",
      "        [ 4.7927e-02,  1.6384e+00],\n",
      "        [ 3.1758e-01,  2.8629e+00],\n",
      "        [-7.7328e-01, -4.4263e+00],\n",
      "        [-4.2864e-01, -3.1185e+00],\n",
      "        [-3.6802e-04, -1.4470e+00],\n",
      "        [ 4.6746e-01,  6.1977e-01],\n",
      "        [ 7.2185e-01,  2.1433e+00],\n",
      "        [-5.6079e-01, -5.0467e+00],\n",
      "        [-1.7530e-01, -3.8481e+00],\n",
      "        [ 2.8723e-01, -2.3818e+00],\n",
      "        [ 7.8728e-01, -5.1465e-01],\n",
      "        [ 1.1208e+00,  1.2692e+00]], grad_fn=<AddmmBackward>)\n",
      "epoch: 57 Loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.7496e+00, -1.9792e+00],\n",
      "        [-1.5145e+00, -2.7579e-01],\n",
      "        [-1.0627e+00,  1.6139e+00],\n",
      "        [-6.6018e-01,  2.9773e+00],\n",
      "        [-3.7445e-01,  3.8456e+00],\n",
      "        [-1.4003e+00, -2.8619e+00],\n",
      "        [-1.1838e+00, -1.2400e+00],\n",
      "        [-7.8550e-01,  7.2130e-01],\n",
      "        [-3.4320e-01,  2.3780e+00],\n",
      "        [-6.0032e-02,  3.3926e+00],\n",
      "        [-1.0492e+00, -3.6655e+00],\n",
      "        [-7.7362e-01, -2.2222e+00],\n",
      "        [-4.1212e-01, -3.4570e-01],\n",
      "        [ 3.9041e-02,  1.6009e+00],\n",
      "        [ 3.1069e-01,  2.8190e+00],\n",
      "        [-7.6993e-01, -4.3686e+00],\n",
      "        [-4.2660e-01, -3.0840e+00],\n",
      "        [-3.7503e-04, -1.4444e+00],\n",
      "        [ 4.6570e-01,  5.8559e-01],\n",
      "        [ 7.2238e-01,  2.0975e+00],\n",
      "        [-5.5162e-01, -4.9820e+00],\n",
      "        [-1.6695e-01, -3.8048e+00],\n",
      "        [ 2.9398e-01, -2.3658e+00],\n",
      "        [ 7.9102e-01, -5.3582e-01],\n",
      "        [ 1.1266e+00,  1.2241e+00]], grad_fn=<AddmmBackward>)\n",
      "epoch: 58 Loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.7711e+00, -1.9514e+00],\n",
      "        [-1.5374e+00, -2.8089e-01],\n",
      "        [-1.0902e+00,  1.5809e+00],\n",
      "        [-6.8403e-01,  2.9397e+00],\n",
      "        [-3.9491e-01,  3.8059e+00],\n",
      "        [-1.4180e+00, -2.8213e+00],\n",
      "        [-1.2015e+00, -1.2297e+00],\n",
      "        [-8.0639e-01,  6.9498e-01],\n",
      "        [-3.6094e-01,  2.3403e+00],\n",
      "        [-7.4065e-02,  3.3513e+00],\n",
      "        [-1.0598e+00, -3.6155e+00],\n",
      "        [-7.8498e-01, -2.1977e+00],\n",
      "        [-4.2437e-01, -3.5779e-01],\n",
      "        [ 2.8677e-02,  1.5643e+00],\n",
      "        [ 3.0419e-01,  2.7761e+00],\n",
      "        [-7.7305e-01, -4.3107e+00],\n",
      "        [-4.2978e-01, -3.0484e+00],\n",
      "        [-3.8825e-03, -1.4397e+00],\n",
      "        [ 4.6261e-01,  5.5446e-01],\n",
      "        [ 7.2346e-01,  2.0540e+00],\n",
      "        [-5.4840e-01, -4.9164e+00],\n",
      "        [-1.6323e-01, -3.7597e+00],\n",
      "        [ 2.9784e-01, -2.3468e+00],\n",
      "        [ 7.9392e-01, -5.5215e-01],\n",
      "        [ 1.1330e+00,  1.1833e+00]], grad_fn=<AddmmBackward>)\n",
      "epoch: 59 Loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.7970, -1.9302],\n",
      "        [-1.5638, -0.2907],\n",
      "        [-1.1199,  1.5459],\n",
      "        [-0.7083,  2.9029],\n",
      "        [-0.4147,  3.7684],\n",
      "        [-1.4402, -2.7865],\n",
      "        [-1.2228, -1.2234],\n",
      "        [-0.8295,  0.6673],\n",
      "        [-0.3792,  2.3039],\n",
      "        [-0.0874,  3.3127],\n",
      "        [-1.0750, -3.5707],\n",
      "        [-0.8000, -2.1764],\n",
      "        [-0.4390, -0.3704],\n",
      "        [ 0.0178,  1.5299],\n",
      "        [ 0.2984,  2.7366],\n",
      "        [-0.7806, -4.2574],\n",
      "        [-0.4364, -3.0156],\n",
      "        [-0.0095, -1.4349],\n",
      "        [ 0.4590,  0.5265],\n",
      "        [ 0.7252,  2.0148],\n",
      "        [-0.5495, -4.8550],\n",
      "        [-0.1628, -3.7170],\n",
      "        [ 0.2998, -2.3276],\n",
      "        [ 0.7965, -0.5646],\n",
      "        [ 1.1400,  1.1480]], grad_fn=<AddmmBackward>)\n",
      "epoch: 60 Loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.8241, -1.9180],\n",
      "        [-1.5912, -0.3059],\n",
      "        [-1.1499,  1.5097],\n",
      "        [-0.7319,  2.8685],\n",
      "        [-0.4334,  3.7355],\n",
      "        [-1.4637, -2.7607],\n",
      "        [-1.2449, -1.2228],\n",
      "        [-0.8529,  0.6384],\n",
      "        [-0.3968,  2.2702],\n",
      "        [-0.0998,  3.2791],\n",
      "        [-1.0918, -3.5345],\n",
      "        [-0.8161, -2.1608],\n",
      "        [-0.4539, -0.3844],\n",
      "        [ 0.0074,  1.4985],\n",
      "        [ 0.2934,  2.7025],\n",
      "        [-0.7898, -4.2125],\n",
      "        [-0.4443, -2.9885],\n",
      "        [-0.0156, -1.4319],\n",
      "        [ 0.4558,  0.5019],\n",
      "        [ 0.7276,  1.9815],\n",
      "        [-0.5523, -4.8020],\n",
      "        [-0.1635, -3.6798],\n",
      "        [ 0.3013, -2.3103],\n",
      "        [ 0.7996, -0.5740],\n",
      "        [ 1.1475,  1.1192]], grad_fn=<AddmmBackward>)\n",
      "epoch: 61 Loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.8494e+00, -1.9158e+00],\n",
      "        [-1.6171e+00, -3.2634e-01],\n",
      "        [-1.1783e+00,  1.4738e+00],\n",
      "        [-7.5387e-01,  2.8385e+00],\n",
      "        [-4.5067e-01,  3.7094e+00],\n",
      "        [-1.4851e+00, -2.7456e+00],\n",
      "        [-1.2653e+00, -1.2286e+00],\n",
      "        [-8.7452e-01,  6.0918e-01],\n",
      "        [-4.1281e-01,  2.2406e+00],\n",
      "        [-1.1089e-01,  3.2524e+00],\n",
      "        [-1.1070e+00, -3.5091e+00],\n",
      "        [-8.3034e-01, -2.1523e+00],\n",
      "        [-4.6700e-01, -3.9978e-01],\n",
      "        [-1.4547e-03,  1.4710e+00],\n",
      "        [ 2.8940e-01,  2.6753e+00],\n",
      "        [-7.9791e-01, -4.1785e+00],\n",
      "        [-4.5083e-01, -2.9686e+00],\n",
      "        [-2.0217e-02, -1.4312e+00],\n",
      "        [ 4.5410e-01,  4.8096e-01],\n",
      "        [ 7.3072e-01,  1.9552e+00],\n",
      "        [-5.5431e-01, -4.7598e+00],\n",
      "        [-1.6329e-01, -3.6502e+00],\n",
      "        [ 3.0388e-01, -2.2963e+00],\n",
      "        [ 8.0406e-01, -5.8067e-01],\n",
      "        [ 1.1558e+00,  1.0976e+00]], grad_fn=<AddmmBackward>)\n",
      "epoch: 62 Loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.8703, -1.9232],\n",
      "        [-1.6394, -0.3508],\n",
      "        [-1.2034,  1.4398],\n",
      "        [-0.7732,  2.8141],\n",
      "        [-0.4661,  3.6914],\n",
      "        [-1.5018, -2.7413],\n",
      "        [-1.2817, -1.2401],\n",
      "        [-0.8926,  0.5809],\n",
      "        [-0.4263,  2.2165],\n",
      "        [-0.1205,  3.2338],\n",
      "        [-1.1180, -3.4949],\n",
      "        [-0.8406, -2.1509],\n",
      "        [-0.4767, -0.4159],\n",
      "        [-0.0079,  1.4486],\n",
      "        [ 0.2866,  2.6562],\n",
      "        [-0.8025, -4.1560],\n",
      "        [-0.4542, -2.9564],\n",
      "        [-0.0219, -1.4329],\n",
      "        [ 0.4546,  0.4645],\n",
      "        [ 0.7347,  1.9370],\n",
      "        [-0.5533, -4.7296],\n",
      "        [-0.1603, -3.6289],\n",
      "        [ 0.3089, -2.2858],\n",
      "        [ 0.8105, -0.5844],\n",
      "        [ 1.1647,  1.0837]], grad_fn=<AddmmBackward>)\n",
      "epoch: 63 Loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.8853, -1.9386],\n",
      "        [-1.6568, -0.3775],\n",
      "        [-1.2238,  1.4096],\n",
      "        [-0.7890,  2.7969],\n",
      "        [-0.4792,  3.6827],\n",
      "        [-1.5123, -2.7464],\n",
      "        [-1.2928, -1.2559],\n",
      "        [-0.9060,  0.5552],\n",
      "        [-0.4364,  2.1992],\n",
      "        [-0.1282,  3.2243],\n",
      "        [-1.1233, -3.4911],\n",
      "        [-0.8457, -2.1554],\n",
      "        [-0.4818, -0.4314],\n",
      "        [-0.0113,  1.4324],\n",
      "        [ 0.2851,  2.6461],\n",
      "        [-0.8023, -4.1444],\n",
      "        [-0.4531, -2.9512],\n",
      "        [-0.0198, -1.4359],\n",
      "        [ 0.4577,  0.4535],\n",
      "        [ 0.7394,  1.9276],\n",
      "        [-0.5481, -4.7109],\n",
      "        [-0.1537, -3.6153],\n",
      "        [ 0.3169, -2.2782],\n",
      "        [ 0.8192, -0.5844],\n",
      "        [ 1.1741,  1.0783]], grad_fn=<AddmmBackward>)\n",
      "epoch: 64 Loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.8941, -1.9592],\n",
      "        [-1.6685, -0.4039],\n",
      "        [-1.2387,  1.3853],\n",
      "        [-0.8006,  2.7878],\n",
      "        [-0.4894,  3.6837],\n",
      "        [-1.5165, -2.7586],\n",
      "        [-1.2983, -1.2737],\n",
      "        [-0.9141,  0.5343],\n",
      "        [-0.4428,  2.1897],\n",
      "        [-0.1337,  3.2244],\n",
      "        [-1.1227, -3.4957],\n",
      "        [-0.8454, -2.1639],\n",
      "        [-0.4822, -0.4443],\n",
      "        [-0.0114,  1.4237],\n",
      "        [ 0.2851,  2.6455],\n",
      "        [-0.7972, -4.1420],\n",
      "        [-0.4478, -2.9512],\n",
      "        [-0.0140, -1.4388],\n",
      "        [ 0.4635,  0.4491],\n",
      "        [ 0.7448,  1.9275],\n",
      "        [-0.5388, -4.7021],\n",
      "        [-0.1434, -3.6081],\n",
      "        [ 0.3279, -2.2724],\n",
      "        [ 0.8300, -0.5799],\n",
      "        [ 1.1838,  1.0815]], grad_fn=<AddmmBackward>)\n",
      "epoch: 65 Loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.8974, -1.9824],\n",
      "        [-1.6748, -0.4276],\n",
      "        [-1.2480,  1.3686],\n",
      "        [-0.8078,  2.7874],\n",
      "        [-0.4964,  3.6945],\n",
      "        [-1.5152, -2.7753],\n",
      "        [-1.2989, -1.2910],\n",
      "        [-0.9170,  0.5198],\n",
      "        [-0.4454,  2.1887],\n",
      "        [-0.1367,  3.2341],\n",
      "        [-1.1174, -3.5060],\n",
      "        [-0.8407, -2.1741],\n",
      "        [-0.4783, -0.4530],\n",
      "        [-0.0084,  1.4230],\n",
      "        [ 0.2867,  2.6543],\n",
      "        [-0.7885, -4.1463],\n",
      "        [-0.4390, -2.9545],\n",
      "        [-0.0050, -1.4399],\n",
      "        [ 0.4716,  0.4521],\n",
      "        [ 0.7509,  1.9365],\n",
      "        [-0.5266, -4.7010],\n",
      "        [-0.1305, -3.6055],\n",
      "        [ 0.3409, -2.2671],\n",
      "        [ 0.8424, -0.5702],\n",
      "        [ 1.1935,  1.0933]], grad_fn=<AddmmBackward>)\n",
      "epoch: 66 Loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.8968e+00, -2.0052e+00],\n",
      "        [-1.6768e+00, -4.4662e-01],\n",
      "        [-1.2518e+00,  1.3605e+00],\n",
      "        [-8.1043e-01,  2.7959e+00],\n",
      "        [-4.9953e-01,  3.7143e+00],\n",
      "        [-1.5105e+00, -2.7935e+00],\n",
      "        [-1.2959e+00, -1.3058e+00],\n",
      "        [-9.1556e-01,  5.1285e-01],\n",
      "        [-4.4412e-01,  2.1963e+00],\n",
      "        [-1.3673e-01,  3.2527e+00],\n",
      "        [-1.1095e+00, -3.5194e+00],\n",
      "        [-8.3329e-01, -2.1840e+00],\n",
      "        [-4.7129e-01, -4.5618e-01],\n",
      "        [-2.7675e-03,  1.4308e+00],\n",
      "        [ 2.9014e-01,  2.6719e+00],\n",
      "        [-7.7823e-01, -4.1550e+00],\n",
      "        [-4.2855e-01, -2.9592e+00],\n",
      "        [ 5.6330e-03, -1.4381e+00],\n",
      "        [ 4.8118e-01,  4.6262e-01],\n",
      "        [ 7.5760e-01,  1.9541e+00],\n",
      "        [-5.1368e-01, -4.7055e+00],\n",
      "        [-1.1695e-01, -3.6058e+00],\n",
      "        [ 3.5455e-01, -2.2611e+00],\n",
      "        [ 8.5535e-01, -5.5506e-01],\n",
      "        [ 1.2030e+00,  1.1131e+00]], grad_fn=<AddmmBackward>)\n",
      "epoch: 67 Loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.8943, -2.0258],\n",
      "        [-1.6758, -0.4598],\n",
      "        [-1.2510,  1.3612],\n",
      "        [-0.8087,  2.8125],\n",
      "        [-0.4986,  3.7421],\n",
      "        [-1.5047, -2.8112],\n",
      "        [-1.2911, -1.3168],\n",
      "        [-0.9108,  0.5137],\n",
      "        [-0.4395,  2.2118],\n",
      "        [-0.1337,  3.2791],\n",
      "        [-1.1015, -3.5339],\n",
      "        [-0.8251, -2.1921],\n",
      "        [-0.4626, -0.4534],\n",
      "        [ 0.0049,  1.4462],\n",
      "        [ 0.2954,  2.6970],\n",
      "        [-0.7686, -4.1661],\n",
      "        [-0.4184, -2.9639],\n",
      "        [ 0.0165, -1.4328],\n",
      "        [ 0.4915,  0.4801],\n",
      "        [ 0.7649,  1.9790],\n",
      "        [-0.5023, -4.7136],\n",
      "        [-0.1047, -3.6076],\n",
      "        [ 0.3672, -2.2539],\n",
      "        [ 0.8679, -0.5351],\n",
      "        [ 1.2121,  1.1395]], grad_fn=<AddmmBackward>)\n",
      "epoch: 68 Loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.8917, -2.0429],\n",
      "        [-1.6732, -0.4671],\n",
      "        [-1.2465,  1.3697],\n",
      "        [-0.8029,  2.8359],\n",
      "        [-0.4934,  3.7760],\n",
      "        [-1.4999, -2.8271],\n",
      "        [-1.2861, -1.3236],\n",
      "        [-0.9038,  0.5216],\n",
      "        [-0.4321,  2.2339],\n",
      "        [-0.1275,  3.3113],\n",
      "        [-1.0954, -3.5480],\n",
      "        [-0.8181, -2.1978],\n",
      "        [-0.4536, -0.4454],\n",
      "        [ 0.0140,  1.4677],\n",
      "        [ 0.3026,  2.7277],\n",
      "        [-0.7619, -4.1783],\n",
      "        [-0.4105, -2.9680],\n",
      "        [ 0.0262, -1.4246],\n",
      "        [ 0.5017,  0.5028],\n",
      "        [ 0.7727,  2.0091],\n",
      "        [-0.4947, -4.7240],\n",
      "        [-0.0955, -3.6103],\n",
      "        [ 0.3776, -2.2456],\n",
      "        [ 0.8792, -0.5116],\n",
      "        [ 1.2206,  1.1704]], grad_fn=<AddmmBackward>)\n",
      "epoch: 69 Loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.8905, -2.0564],\n",
      "        [-1.6702, -0.4694],\n",
      "        [-1.2395,  1.3841],\n",
      "        [-0.7938,  2.8639],\n",
      "        [-0.4843,  3.8138],\n",
      "        [-1.4975, -2.8408],\n",
      "        [-1.2822, -1.3268],\n",
      "        [-0.8959,  0.5345],\n",
      "        [-0.4224,  2.2602],\n",
      "        [-0.1183,  3.3472],\n",
      "        [-1.0927, -3.5614],\n",
      "        [-0.8134, -2.2016],\n",
      "        [-0.4453, -0.4338],\n",
      "        [ 0.0238,  1.4930],\n",
      "        [ 0.3116,  2.7618],\n",
      "        [-0.7594, -4.1910],\n",
      "        [-0.4060, -2.9717],\n",
      "        [ 0.0336, -1.4146],\n",
      "        [ 0.5112,  0.5283],\n",
      "        [ 0.7810,  2.0420],\n",
      "        [-0.4921, -4.7360],\n",
      "        [-0.0907, -3.6139],\n",
      "        [ 0.3844, -2.2374],\n",
      "        [ 0.8883, -0.4869],\n",
      "        [ 1.2284,  1.2032]], grad_fn=<AddmmBackward>)\n",
      "epoch: 70 Loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.8911, -2.0670],\n",
      "        [-1.6674, -0.4683],\n",
      "        [-1.2309,  1.4018],\n",
      "        [-0.7821,  2.8940],\n",
      "        [-0.4720,  3.8531],\n",
      "        [-1.4982, -2.8528],\n",
      "        [-1.2800, -1.3277],\n",
      "        [-0.8879,  0.5498],\n",
      "        [-0.4113,  2.2882],\n",
      "        [-0.1066,  3.3841],\n",
      "        [-1.0940, -3.5741],\n",
      "        [-0.8117, -2.2044],\n",
      "        [-0.4386, -0.4209],\n",
      "        [ 0.0338,  1.5193],\n",
      "        [ 0.3221,  2.7964],\n",
      "        [-0.7616, -4.2041],\n",
      "        [-0.4053, -2.9756],\n",
      "        [ 0.0381, -1.4048],\n",
      "        [ 0.5195,  0.5537],\n",
      "        [ 0.7897,  2.0749],\n",
      "        [-0.4949, -4.7493],\n",
      "        [-0.0907, -3.6189],\n",
      "        [ 0.3875, -2.2304],\n",
      "        [ 0.8950, -0.4636],\n",
      "        [ 1.2355,  1.2350]], grad_fn=<AddmmBackward>)\n",
      "epoch: 71 Loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.8936, -2.0758],\n",
      "        [-1.6652, -0.4658],\n",
      "        [-1.2218,  1.4200],\n",
      "        [-0.7690,  2.9238],\n",
      "        [-0.4573,  3.8912],\n",
      "        [-1.5016, -2.8636],\n",
      "        [-1.2794, -1.3281],\n",
      "        [-0.8804,  0.5648],\n",
      "        [-0.3996,  2.3152],\n",
      "        [-0.0934,  3.4194],\n",
      "        [-1.0987, -3.5867],\n",
      "        [-0.8127, -2.2074],\n",
      "        [-0.4337, -0.4093],\n",
      "        [ 0.0434,  1.5437],\n",
      "        [ 0.3334,  2.8288],\n",
      "        [-0.7679, -4.2178],\n",
      "        [-0.4082, -2.9807],\n",
      "        [ 0.0399, -1.3971],\n",
      "        [ 0.5262,  0.5760],\n",
      "        [ 0.7984,  2.1049],\n",
      "        [-0.5024, -4.7640],\n",
      "        [-0.0950, -3.6257],\n",
      "        [ 0.3869, -2.2262],\n",
      "        [ 0.8991, -0.4444],\n",
      "        [ 1.2417,  1.2629]], grad_fn=<AddmmBackward>)\n",
      "epoch: 72 Loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.8971, -2.0837],\n",
      "        [-1.6636, -0.4636],\n",
      "        [-1.2128,  1.4362],\n",
      "        [-0.7554,  2.9507],\n",
      "        [-0.4419,  3.9259],\n",
      "        [-1.5067, -2.8741],\n",
      "        [-1.2801, -1.3294],\n",
      "        [-0.8738,  0.5769],\n",
      "        [-0.3880,  2.3386],\n",
      "        [-0.0797,  3.4509],\n",
      "        [-1.1057, -3.5993],\n",
      "        [-0.8158, -2.2119],\n",
      "        [-0.4305, -0.4012],\n",
      "        [ 0.0522,  1.5636],\n",
      "        [ 0.3447,  2.8569],\n",
      "        [-0.7768, -4.2322],\n",
      "        [-0.4137, -2.9877],\n",
      "        [ 0.0392, -1.3931],\n",
      "        [ 0.5313,  0.5927],\n",
      "        [ 0.8066,  2.1296],\n",
      "        [-0.5131, -4.7798],\n",
      "        [-0.1024, -3.6349],\n",
      "        [ 0.3833, -2.2260],\n",
      "        [ 0.9005, -0.4315],\n",
      "        [ 1.2469,  1.2845]], grad_fn=<AddmmBackward>)\n",
      "epoch: 73 Loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9008, -2.0910],\n",
      "        [-1.6623, -0.4630],\n",
      "        [-1.2048,  1.4486],\n",
      "        [-0.7427,  2.9730],\n",
      "        [-0.4270,  3.9553],\n",
      "        [-1.5122, -2.8842],\n",
      "        [-1.2813, -1.3324],\n",
      "        [-0.8685,  0.5846],\n",
      "        [-0.3776,  2.3568],\n",
      "        [-0.0668,  3.4766],\n",
      "        [-1.1133, -3.6120],\n",
      "        [-0.8197, -2.2181],\n",
      "        [-0.4287, -0.3980],\n",
      "        [ 0.0595,  1.5774],\n",
      "        [ 0.3550,  2.8787],\n",
      "        [-0.7866, -4.2469],\n",
      "        [-0.4204, -2.9966],\n",
      "        [ 0.0368, -1.3938],\n",
      "        [ 0.5345,  0.6022],\n",
      "        [ 0.8136,  2.1474],\n",
      "        [-0.5248, -4.7961],\n",
      "        [-0.1115, -3.6460],\n",
      "        [ 0.3777, -2.2301],\n",
      "        [ 0.8996, -0.4261],\n",
      "        [ 1.2505,  1.2983]], grad_fn=<AddmmBackward>)\n",
      "epoch: 74 Loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9035, -2.0974],\n",
      "        [-1.6610, -0.4640],\n",
      "        [-1.1981,  1.4564],\n",
      "        [-0.7320,  2.9896],\n",
      "        [-0.4144,  3.9782],\n",
      "        [-1.5167, -2.8934],\n",
      "        [-1.2824, -1.3369],\n",
      "        [-0.8644,  0.5872],\n",
      "        [-0.3691,  2.3687],\n",
      "        [-0.0561,  3.4956],\n",
      "        [-1.1199, -3.6238],\n",
      "        [-0.8234, -2.2257],\n",
      "        [-0.4282, -0.3997],\n",
      "        [ 0.0650,  1.5842],\n",
      "        [ 0.3631,  2.8933],\n",
      "        [-0.7953, -4.2609],\n",
      "        [-0.4269, -3.0067],\n",
      "        [ 0.0334, -1.3990],\n",
      "        [ 0.5358,  0.6041],\n",
      "        [ 0.8188,  2.1574],\n",
      "        [-0.5355, -4.8118],\n",
      "        [-0.1203, -3.6583],\n",
      "        [ 0.3712, -2.2381],\n",
      "        [ 0.8966, -0.4283],\n",
      "        [ 1.2522,  1.3037]], grad_fn=<AddmmBackward>)\n",
      "epoch: 75 Loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9047, -2.1019],\n",
      "        [-1.6593, -0.4660],\n",
      "        [-1.1932,  1.4597],\n",
      "        [-0.7241,  3.0003],\n",
      "        [-0.4052,  3.9942],\n",
      "        [-1.5193, -2.9005],\n",
      "        [-1.2827, -1.3420],\n",
      "        [-0.8617,  0.5853],\n",
      "        [-0.3632,  2.3744],\n",
      "        [-0.0487,  3.5075],\n",
      "        [-1.1241, -3.6333],\n",
      "        [-0.8261, -2.2334],\n",
      "        [-0.4284, -0.4055],\n",
      "        [ 0.0681,  1.5843],\n",
      "        [ 0.3684,  2.9006],\n",
      "        [-0.8014, -4.2725],\n",
      "        [-0.4321, -3.0167],\n",
      "        [ 0.0296, -1.4073],\n",
      "        [ 0.5351,  0.5989],\n",
      "        [ 0.8214,  2.1596],\n",
      "        [-0.5432, -4.8251],\n",
      "        [-0.1276, -3.6702],\n",
      "        [ 0.3647, -2.2485],\n",
      "        [ 0.8918, -0.4370],\n",
      "        [ 1.2516,  1.3009]], grad_fn=<AddmmBackward>)\n",
      "epoch: 76 Loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9038, -2.1031],\n",
      "        [-1.6572, -0.4675],\n",
      "        [-1.1901,  1.4596],\n",
      "        [-0.7195,  3.0055],\n",
      "        [-0.4001,  4.0033],\n",
      "        [-1.5193, -2.9039],\n",
      "        [-1.2820, -1.3461],\n",
      "        [-0.8602,  0.5805],\n",
      "        [-0.3603,  2.3746],\n",
      "        [-0.0451,  3.5126],\n",
      "        [-1.1253, -3.6390],\n",
      "        [-0.8272, -2.2396],\n",
      "        [-0.4292, -0.4135],\n",
      "        [ 0.0688,  1.5789],\n",
      "        [ 0.3701,  2.9010],\n",
      "        [-0.8038, -4.2801],\n",
      "        [-0.4351, -3.0248],\n",
      "        [ 0.0261, -1.4171],\n",
      "        [ 0.5324,  0.5883],\n",
      "        [ 0.8211,  2.1549],\n",
      "        [-0.5468, -4.8343],\n",
      "        [-0.1322, -3.6799],\n",
      "        [ 0.3590, -2.2596],\n",
      "        [ 0.8857, -0.4505],\n",
      "        [ 1.2485,  1.2911]], grad_fn=<AddmmBackward>)\n",
      "epoch: 77 Loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9010, -2.0996],\n",
      "        [-1.6546, -0.4673],\n",
      "        [-1.1887,  1.4574],\n",
      "        [-0.7182,  3.0060],\n",
      "        [-0.3993,  4.0064],\n",
      "        [-1.5169, -2.9022],\n",
      "        [-1.2803, -1.3476],\n",
      "        [-0.8598,  0.5743],\n",
      "        [-0.3604,  2.3705],\n",
      "        [-0.0455,  3.5118],\n",
      "        [-1.1233, -3.6394],\n",
      "        [-0.8267, -2.2426],\n",
      "        [-0.4303, -0.4219],\n",
      "        [ 0.0670,  1.5695],\n",
      "        [ 0.3683,  2.8957],\n",
      "        [-0.8024, -4.2824],\n",
      "        [-0.4358, -3.0294],\n",
      "        [ 0.0229, -1.4262],\n",
      "        [ 0.5279,  0.5743],\n",
      "        [ 0.8178,  2.1446],\n",
      "        [-0.5460, -4.8379],\n",
      "        [-0.1339, -3.6859],\n",
      "        [ 0.3546, -2.2693],\n",
      "        [ 0.8786, -0.4663],\n",
      "        [ 1.2431,  1.2762]], grad_fn=<AddmmBackward>)\n",
      "epoch: 78 Loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.8968, -2.0909],\n",
      "        [-1.6517, -0.4644],\n",
      "        [-1.1889,  1.4544],\n",
      "        [-0.7200,  3.0030],\n",
      "        [-0.4024,  4.0044],\n",
      "        [-1.5127, -2.8946],\n",
      "        [-1.2779, -1.3455],\n",
      "        [-0.8604,  0.5684],\n",
      "        [-0.3632,  2.3633],\n",
      "        [-0.0495,  3.5062],\n",
      "        [-1.1188, -3.6337],\n",
      "        [-0.8250, -2.2414],\n",
      "        [-0.4319, -0.4290],\n",
      "        [ 0.0630,  1.5577],\n",
      "        [ 0.3634,  2.8860],\n",
      "        [-0.7977, -4.2784],\n",
      "        [-0.4344, -3.0294],\n",
      "        [ 0.0202, -1.4331],\n",
      "        [ 0.5219,  0.5588],\n",
      "        [ 0.8118,  2.1305],\n",
      "        [-0.5414, -4.8352],\n",
      "        [-0.1328, -3.6870],\n",
      "        [ 0.3513, -2.2763],\n",
      "        [ 0.8708, -0.4824],\n",
      "        [ 1.2355,  1.2580]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 79 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.8920, -2.0771],\n",
      "        [-1.6489, -0.4584],\n",
      "        [-1.1903,  1.4514],\n",
      "        [-0.7242,  2.9975],\n",
      "        [-0.4084,  3.9985],\n",
      "        [-1.5074, -2.8815],\n",
      "        [-1.2753, -1.3395],\n",
      "        [-0.8619,  0.5637],\n",
      "        [-0.3680,  2.3544],\n",
      "        [-0.0562,  3.4971],\n",
      "        [-1.1127, -3.6221],\n",
      "        [-0.8226, -2.2356],\n",
      "        [-0.4338, -0.4337],\n",
      "        [ 0.0573,  1.5450],\n",
      "        [ 0.3560,  2.8734],\n",
      "        [-0.7908, -4.2684],\n",
      "        [-0.4317, -3.0246],\n",
      "        [ 0.0178, -1.4369],\n",
      "        [ 0.5147,  0.5434],\n",
      "        [ 0.8039,  2.1141],\n",
      "        [-0.5340, -4.8265],\n",
      "        [-0.1298, -3.6832],\n",
      "        [ 0.3490, -2.2797],\n",
      "        [ 0.8625, -0.4973],\n",
      "        [ 1.2263,  1.2383]], grad_fn=<AddmmBackward>)\n",
      "epoch: 80 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.8873, -2.0596],\n",
      "        [-1.6463, -0.4502],\n",
      "        [-1.1926,  1.4486],\n",
      "        [-0.7298,  2.9905],\n",
      "        [-0.4160,  3.9899],\n",
      "        [-1.5021, -2.8641],\n",
      "        [-1.2729, -1.3304],\n",
      "        [-0.8640,  0.5602],\n",
      "        [-0.3742,  2.3445],\n",
      "        [-0.0645,  3.4858],\n",
      "        [-1.1062, -3.6060],\n",
      "        [-0.8202, -2.2260],\n",
      "        [-0.4362, -0.4361],\n",
      "        [ 0.0505,  1.5323],\n",
      "        [ 0.3472,  2.8591],\n",
      "        [-0.7830, -4.2537],\n",
      "        [-0.4285, -3.0157],\n",
      "        [ 0.0153, -1.4376],\n",
      "        [ 0.5068,  0.5291],\n",
      "        [ 0.7947,  2.0966],\n",
      "        [-0.5253, -4.8128],\n",
      "        [-0.1259, -3.6751],\n",
      "        [ 0.3470, -2.2797],\n",
      "        [ 0.8541, -0.5100],\n",
      "        [ 1.2162,  1.2184]], grad_fn=<AddmmBackward>)\n",
      "epoch: 81 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.8832, -2.0405],\n",
      "        [-1.6443, -0.4409],\n",
      "        [-1.1954,  1.4457],\n",
      "        [-0.7358,  2.9824],\n",
      "        [-0.4240,  3.9797],\n",
      "        [-1.4975, -2.8445],\n",
      "        [-1.2711, -1.3197],\n",
      "        [-0.8665,  0.5576],\n",
      "        [-0.3806,  2.3342],\n",
      "        [-0.0730,  3.4734],\n",
      "        [-1.1002, -3.5873],\n",
      "        [-0.8184, -2.2142],\n",
      "        [-0.4389, -0.4368],\n",
      "        [ 0.0434,  1.5199],\n",
      "        [ 0.3382,  2.8441],\n",
      "        [-0.7756, -4.2363],\n",
      "        [-0.4256, -3.0043],\n",
      "        [ 0.0125, -1.4360],\n",
      "        [ 0.4987,  0.5160],\n",
      "        [ 0.7853,  2.0791],\n",
      "        [-0.5167, -4.7962],\n",
      "        [-0.1220, -3.6643],\n",
      "        [ 0.3451, -2.2771],\n",
      "        [ 0.8457, -0.5206],\n",
      "        [ 1.2059,  1.1994]], grad_fn=<AddmmBackward>)\n",
      "epoch: 82 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.8801, -2.0221],\n",
      "        [-1.6428, -0.4325],\n",
      "        [-1.1982,  1.4422],\n",
      "        [-0.7413,  2.9737],\n",
      "        [-0.4311,  3.9689],\n",
      "        [-1.4941, -2.8252],\n",
      "        [-1.2700, -1.3091],\n",
      "        [-0.8690,  0.5549],\n",
      "        [-0.3867,  2.3238],\n",
      "        [-0.0807,  3.4606],\n",
      "        [-1.0956, -3.5686],\n",
      "        [-0.8174, -2.2022],\n",
      "        [-0.4419, -0.4370],\n",
      "        [ 0.0367,  1.5079],\n",
      "        [ 0.3299,  2.8293],\n",
      "        [-0.7695, -4.2186],\n",
      "        [-0.4236, -2.9923],\n",
      "        [ 0.0095, -1.4335],\n",
      "        [ 0.4908,  0.5042],\n",
      "        [ 0.7766,  2.0623],\n",
      "        [-0.5095, -4.7791],\n",
      "        [-0.1191, -3.6526],\n",
      "        [ 0.3428, -2.2731],\n",
      "        [ 0.8374, -0.5293],\n",
      "        [ 1.1960,  1.1818]], grad_fn=<AddmmBackward>)\n",
      "epoch: 83 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.8782, -2.0067],\n",
      "        [-1.6419, -0.4263],\n",
      "        [-1.2007,  1.4373],\n",
      "        [-0.7457,  2.9649],\n",
      "        [-0.4365,  3.9585],\n",
      "        [-1.4921, -2.8087],\n",
      "        [-1.2695, -1.3006],\n",
      "        [-0.8714,  0.5511],\n",
      "        [-0.3916,  2.3134],\n",
      "        [-0.0867,  3.4484],\n",
      "        [-1.0927, -3.5522],\n",
      "        [-0.8174, -2.1917],\n",
      "        [-0.4448, -0.4378],\n",
      "        [ 0.0310,  1.4964],\n",
      "        [ 0.3233,  2.8154],\n",
      "        [-0.7653, -4.2028],\n",
      "        [-0.4228, -2.9816],\n",
      "        [ 0.0061, -1.4311],\n",
      "        [ 0.4837,  0.4933],\n",
      "        [ 0.7692,  2.0469],\n",
      "        [-0.5044, -4.7638],\n",
      "        [-0.1175, -3.6419],\n",
      "        [ 0.3399, -2.2692],\n",
      "        [ 0.8296, -0.5367],\n",
      "        [ 1.1872,  1.1660]], grad_fn=<AddmmBackward>)\n",
      "epoch: 84 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.8772e+00, -1.9959e+00],\n",
      "        [-1.6412e+00, -4.2362e-01],\n",
      "        [-1.2025e+00,  1.4309e+00],\n",
      "        [-7.4824e-01,  2.9563e+00],\n",
      "        [-4.3959e-01,  3.9492e+00],\n",
      "        [-1.4913e+00, -2.7965e+00],\n",
      "        [-1.2695e+00, -1.2954e+00],\n",
      "        [-8.7329e-01,  5.4585e-01],\n",
      "        [-3.9484e-01,  2.3034e+00],\n",
      "        [-9.0421e-02,  3.4376e+00],\n",
      "        [-1.0914e+00, -3.5399e+00],\n",
      "        [-8.1812e-01, -2.1843e+00],\n",
      "        [-4.4748e-01, -4.4005e-01],\n",
      "        [ 2.6652e-02,  1.4853e+00],\n",
      "        [ 3.1867e-01,  2.8030e+00],\n",
      "        [-7.6320e-01, -4.1908e+00],\n",
      "        [-4.2320e-01, -2.9735e+00],\n",
      "        [ 2.6390e-03, -1.4299e+00],\n",
      "        [ 4.7758e-01,  4.8311e-01],\n",
      "        [ 7.6358e-01,  2.0333e+00],\n",
      "        [-5.0161e-01, -4.7520e+00],\n",
      "        [-1.1747e-01, -3.6336e+00],\n",
      "        [ 3.3657e-01, -2.2662e+00],\n",
      "        [ 8.2253e-01, -5.4319e-01],\n",
      "        [ 1.1798e+00,  1.1525e+00]], grad_fn=<AddmmBackward>)\n",
      "epoch: 85 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.8769e+00, -1.9905e+00],\n",
      "        [-1.6408e+00, -4.2459e-01],\n",
      "        [-1.2034e+00,  1.4232e+00],\n",
      "        [-7.4891e-01,  2.9485e+00],\n",
      "        [-4.4018e-01,  3.9419e+00],\n",
      "        [-1.4914e+00, -2.7897e+00],\n",
      "        [-1.2697e+00, -1.2939e+00],\n",
      "        [-8.7443e-01,  5.3912e-01],\n",
      "        [-3.9627e-01,  2.2942e+00],\n",
      "        [-9.1749e-02,  3.4288e+00],\n",
      "        [-1.0915e+00, -3.5325e+00],\n",
      "        [-8.1934e-01, -2.1805e+00],\n",
      "        [-4.4959e-01, -4.4382e-01],\n",
      "        [ 2.3992e-02,  1.4752e+00],\n",
      "        [ 3.1630e-01,  2.7929e+00],\n",
      "        [-7.6288e-01, -4.1835e+00],\n",
      "        [-4.2457e-01, -2.9688e+00],\n",
      "        [-7.3095e-04, -1.4302e+00],\n",
      "        [ 4.7280e-01,  4.7398e-01],\n",
      "        [ 7.5991e-01,  2.0222e+00],\n",
      "        [-5.0095e-01, -4.7447e+00],\n",
      "        [-1.1875e-01, -3.6284e+00],\n",
      "        [ 3.3293e-01, -2.2646e+00],\n",
      "        [ 8.1634e-01, -5.4863e-01],\n",
      "        [ 1.1740e+00,  1.1418e+00]], grad_fn=<AddmmBackward>)\n",
      "epoch: 86 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.8772e+00, -1.9902e+00],\n",
      "        [-1.6403e+00, -4.2871e-01],\n",
      "        [-1.2034e+00,  1.4149e+00],\n",
      "        [-7.4774e-01,  2.9422e+00],\n",
      "        [-4.3851e-01,  3.9372e+00],\n",
      "        [-1.4922e+00, -2.7879e+00],\n",
      "        [-1.2700e+00, -1.2957e+00],\n",
      "        [-8.7471e-01,  5.3160e-01],\n",
      "        [-3.9593e-01,  2.2865e+00],\n",
      "        [-9.0872e-02,  3.4228e+00],\n",
      "        [-1.0925e+00, -3.5301e+00],\n",
      "        [-8.2076e-01, -2.1801e+00],\n",
      "        [-4.5099e-01, -4.4858e-01],\n",
      "        [ 2.2979e-02,  1.4666e+00],\n",
      "        [ 3.1600e-01,  2.7856e+00],\n",
      "        [-7.6394e-01, -4.1809e+00],\n",
      "        [-4.2657e-01, -2.9672e+00],\n",
      "        [-3.7362e-03, -1.4316e+00],\n",
      "        [ 4.6943e-01,  4.6648e-01],\n",
      "        [ 7.5807e-01,  2.0141e+00],\n",
      "        [-5.0195e-01, -4.7420e+00],\n",
      "        [-1.2093e-01, -3.6264e+00],\n",
      "        [ 3.2930e-01, -2.2643e+00],\n",
      "        [ 8.1125e-01, -5.5264e-01],\n",
      "        [ 1.1699e+00,  1.1343e+00]], grad_fn=<AddmmBackward>)\n",
      "epoch: 87 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.8777, -1.9938],\n",
      "        [-1.6398, -0.4348],\n",
      "        [-1.2025,  1.4071],\n",
      "        [-0.7450,  2.9382],\n",
      "        [-0.4351,  3.9358],\n",
      "        [-1.4933, -2.7902],\n",
      "        [-1.2701, -1.2998],\n",
      "        [-0.8741,  0.5244],\n",
      "        [-0.3941,  2.2812],\n",
      "        [-0.0882,  3.4200],\n",
      "        [-1.0942, -3.5318],\n",
      "        [-0.8221, -2.1822],\n",
      "        [-0.4516, -0.4533],\n",
      "        [ 0.0234,  1.4603],\n",
      "        [ 0.3174,  2.7817],\n",
      "        [-0.7658, -4.1824],\n",
      "        [-0.4288, -2.9682],\n",
      "        [-0.0062, -1.4332],\n",
      "        [ 0.4674,  0.4614],\n",
      "        [ 0.7578,  2.0096],\n",
      "        [-0.5040, -4.7433],\n",
      "        [-0.1235, -3.6269],\n",
      "        [ 0.3260, -2.2644],\n",
      "        [ 0.8073, -0.5545],\n",
      "        [ 1.1672,  1.1306]], grad_fn=<AddmmBackward>)\n",
      "epoch: 88 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.8785, -2.0000],\n",
      "        [-1.6391, -0.4415],\n",
      "        [-1.2008,  1.4009],\n",
      "        [-0.7413,  2.9370],\n",
      "        [-0.4304,  3.9379],\n",
      "        [-1.4946, -2.7953],\n",
      "        [-1.2701, -1.3047],\n",
      "        [-0.8728,  0.5187],\n",
      "        [-0.3911,  2.2788],\n",
      "        [-0.0844,  3.4210],\n",
      "        [-1.0960, -3.5364],\n",
      "        [-0.8233, -2.1855],\n",
      "        [-0.4514, -0.4569],\n",
      "        [ 0.0251,  1.4573],\n",
      "        [ 0.3199,  2.7817],\n",
      "        [-0.7680, -4.1868],\n",
      "        [-0.4308, -2.9706],\n",
      "        [-0.0078, -1.4341],\n",
      "        [ 0.4667,  0.4596],\n",
      "        [ 0.7586,  2.0092],\n",
      "        [-0.5064, -4.7476],\n",
      "        [-0.1260, -3.6289],\n",
      "        [ 0.3234, -2.2642],\n",
      "        [ 0.8047, -0.5535],\n",
      "        [ 1.1656,  1.1311]], grad_fn=<AddmmBackward>)\n",
      "epoch: 89 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.8794, -2.0070],\n",
      "        [-1.6384, -0.4475],\n",
      "        [-1.1986,  1.3972],\n",
      "        [-0.7369,  2.9390],\n",
      "        [-0.4253,  3.9436],\n",
      "        [-1.4958, -2.8017],\n",
      "        [-1.2699, -1.3094],\n",
      "        [-0.8707,  0.5155],\n",
      "        [-0.3874,  2.2797],\n",
      "        [-0.0801,  3.4256],\n",
      "        [-1.0976, -3.5425],\n",
      "        [-0.8240, -2.1887],\n",
      "        [-0.4504, -0.4582],\n",
      "        [ 0.0275,  1.4577],\n",
      "        [ 0.3231,  2.7855],\n",
      "        [-0.7699, -4.1929],\n",
      "        [-0.4323, -2.9733],\n",
      "        [-0.0087, -1.4333],\n",
      "        [ 0.4670,  0.4614],\n",
      "        [ 0.7601,  2.0128],\n",
      "        [-0.5085, -4.7537],\n",
      "        [-0.1278, -3.6314],\n",
      "        [ 0.3217, -2.2628],\n",
      "        [ 0.8033, -0.5491],\n",
      "        [ 1.1650,  1.1358]], grad_fn=<AddmmBackward>)\n",
      "epoch: 90 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.8804, -2.0139],\n",
      "        [-1.6377, -0.4520],\n",
      "        [-1.1960,  1.3964],\n",
      "        [-0.7323,  2.9440],\n",
      "        [-0.4202,  3.9524],\n",
      "        [-1.4969, -2.8081],\n",
      "        [-1.2695, -1.3127],\n",
      "        [-0.8683,  0.5151],\n",
      "        [-0.3834,  2.2840],\n",
      "        [-0.0757,  3.4335],\n",
      "        [-1.0988, -3.5489],\n",
      "        [-0.8244, -2.1912],\n",
      "        [-0.4488, -0.4570],\n",
      "        [ 0.0304,  1.4618],\n",
      "        [ 0.3264,  2.7928],\n",
      "        [-0.7712, -4.1996],\n",
      "        [-0.4331, -2.9755],\n",
      "        [-0.0087, -1.4305],\n",
      "        [ 0.4682,  0.4669],\n",
      "        [ 0.7620,  2.0201],\n",
      "        [-0.5099, -4.7605],\n",
      "        [-0.1288, -3.6338],\n",
      "        [ 0.3210, -2.2599],\n",
      "        [ 0.8030, -0.5414],\n",
      "        [ 1.1651,  1.1442]], grad_fn=<AddmmBackward>)\n",
      "epoch: 91 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.8814, -2.0198],\n",
      "        [-1.6370, -0.4546],\n",
      "        [-1.1934,  1.3982],\n",
      "        [-0.7280,  2.9515],\n",
      "        [-0.4156,  3.9637],\n",
      "        [-1.4978, -2.8140],\n",
      "        [-1.2690, -1.3146],\n",
      "        [-0.8656,  0.5175],\n",
      "        [-0.3795,  2.2909],\n",
      "        [-0.0716,  3.4440],\n",
      "        [-1.0994, -3.5552],\n",
      "        [-0.8242, -2.1925],\n",
      "        [-0.4468, -0.4533],\n",
      "        [ 0.0336,  1.4687],\n",
      "        [ 0.3296,  2.8027],\n",
      "        [-0.7718, -4.2062],\n",
      "        [-0.4332, -2.9768],\n",
      "        [-0.0078, -1.4257],\n",
      "        [ 0.4700,  0.4754],\n",
      "        [ 0.7640,  2.0301],\n",
      "        [-0.5103, -4.7676],\n",
      "        [-0.1287, -3.6356],\n",
      "        [ 0.3214, -2.2554],\n",
      "        [ 0.8037, -0.5311],\n",
      "        [ 1.1657,  1.1555]], grad_fn=<AddmmBackward>)\n",
      "epoch: 92 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.8825, -2.0249],\n",
      "        [-1.6365, -0.4557],\n",
      "        [-1.1911,  1.4019],\n",
      "        [-0.7243,  2.9607],\n",
      "        [-0.4117,  3.9764],\n",
      "        [-1.4984, -2.8193],\n",
      "        [-1.2684, -1.3152],\n",
      "        [-0.8629,  0.5216],\n",
      "        [-0.3758,  2.2995],\n",
      "        [-0.0681,  3.4559],\n",
      "        [-1.0996, -3.5610],\n",
      "        [-0.8236, -2.1928],\n",
      "        [-0.4443, -0.4479],\n",
      "        [ 0.0368,  1.4774],\n",
      "        [ 0.3325,  2.8141],\n",
      "        [-0.7715, -4.2127],\n",
      "        [-0.4324, -2.9775],\n",
      "        [-0.0063, -1.4196],\n",
      "        [ 0.4723,  0.4856],\n",
      "        [ 0.7661,  2.0417],\n",
      "        [-0.5096, -4.7747],\n",
      "        [-0.1276, -3.6370],\n",
      "        [ 0.3228, -2.2500],\n",
      "        [ 0.8053, -0.5191],\n",
      "        [ 1.1667,  1.1682]], grad_fn=<AddmmBackward>)\n",
      "epoch: 93 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.8837e+00, -2.0294e+00],\n",
      "        [-1.6363e+00, -4.5623e-01],\n",
      "        [-1.1892e+00,  1.4061e+00],\n",
      "        [-7.2121e-01,  2.9702e+00],\n",
      "        [-4.0868e-01,  3.9895e+00],\n",
      "        [-1.4989e+00, -2.8241e+00],\n",
      "        [-1.2679e+00, -1.3152e+00],\n",
      "        [-8.6036e-01,  5.2641e-01],\n",
      "        [-3.7263e-01,  2.3085e+00],\n",
      "        [-6.5185e-02,  3.4681e+00],\n",
      "        [-1.0993e+00, -3.5665e+00],\n",
      "        [-8.2273e-01, -2.1928e+00],\n",
      "        [-4.4173e-01, -4.4208e-01],\n",
      "        [ 3.9914e-02,  1.4865e+00],\n",
      "        [ 3.3508e-01,  2.8257e+00],\n",
      "        [-7.7046e-01, -4.2192e+00],\n",
      "        [-4.3097e-01, -2.9781e+00],\n",
      "        [-4.2632e-03, -1.4132e+00],\n",
      "        [ 4.7490e-01,  4.9607e-01],\n",
      "        [ 7.6815e-01,  2.0533e+00],\n",
      "        [-5.0805e-01, -4.7818e+00],\n",
      "        [-1.2556e-01, -3.6383e+00],\n",
      "        [ 3.2496e-01, -2.2444e+00],\n",
      "        [ 8.0746e-01, -5.0705e-01],\n",
      "        [ 1.1681e+00,  1.1810e+00]], grad_fn=<AddmmBackward>)\n",
      "epoch: 94 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.8853e+00, -2.0337e+00],\n",
      "        [-1.6366e+00, -4.5685e-01],\n",
      "        [-1.1880e+00,  1.4099e+00],\n",
      "        [-7.1894e-01,  2.9791e+00],\n",
      "        [-4.0650e-01,  4.0017e+00],\n",
      "        [-1.4995e+00, -2.8289e+00],\n",
      "        [-1.2676e+00, -1.3155e+00],\n",
      "        [-8.5825e-01,  5.3052e-01],\n",
      "        [-3.6997e-01,  2.3166e+00],\n",
      "        [-6.2895e-02,  3.4793e+00],\n",
      "        [-1.0987e+00, -3.5722e+00],\n",
      "        [-8.2169e-01, -2.1931e+00],\n",
      "        [-4.3918e-01, -4.3698e-01],\n",
      "        [ 4.2799e-02,  1.4945e+00],\n",
      "        [ 3.3736e-01,  2.8362e+00],\n",
      "        [-7.6897e-01, -4.2257e+00],\n",
      "        [-4.2917e-01, -2.9790e+00],\n",
      "        [-1.9145e-03, -1.4075e+00],\n",
      "        [ 4.7762e-01,  5.0531e-01],\n",
      "        [ 7.7025e-01,  2.0636e+00],\n",
      "        [-5.0585e-01, -4.7891e+00],\n",
      "        [-1.2295e-01, -3.6401e+00],\n",
      "        [ 3.2764e-01, -2.2395e+00],\n",
      "        [ 8.1000e-01, -4.9618e-01],\n",
      "        [ 1.1698e+00,  1.1923e+00]], grad_fn=<AddmmBackward>)\n",
      "epoch: 95 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.8873e+00, -2.0381e+00],\n",
      "        [-1.6374e+00, -4.5825e-01],\n",
      "        [-1.1877e+00,  1.4121e+00],\n",
      "        [-7.1750e-01,  2.9863e+00],\n",
      "        [-4.0508e-01,  4.0121e+00],\n",
      "        [-1.5003e+00, -2.8338e+00],\n",
      "        [-1.2676e+00, -1.3165e+00],\n",
      "        [-8.5673e-01,  5.3300e-01],\n",
      "        [-3.6790e-01,  2.3229e+00],\n",
      "        [-6.1128e-02,  3.4886e+00],\n",
      "        [-1.0982e+00, -3.5780e+00],\n",
      "        [-8.2075e-01, -2.1942e+00],\n",
      "        [-4.3688e-01, -4.3355e-01],\n",
      "        [ 4.5393e-02,  1.5003e+00],\n",
      "        [ 3.3940e-01,  2.8445e+00],\n",
      "        [-7.6735e-01, -4.2325e+00],\n",
      "        [-4.2726e-01, -2.9806e+00],\n",
      "        [ 4.6978e-04, -1.4034e+00],\n",
      "        [ 4.8029e-01,  5.1215e-01],\n",
      "        [ 7.7244e-01,  2.0716e+00],\n",
      "        [-5.0340e-01, -4.7967e+00],\n",
      "        [-1.2011e-01, -3.6424e+00],\n",
      "        [ 3.3051e-01, -2.2360e+00],\n",
      "        [ 8.1265e-01, -4.8762e-01],\n",
      "        [ 1.1717e+00,  1.2010e+00]], grad_fn=<AddmmBackward>)\n",
      "epoch: 96 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.8899e+00, -2.0425e+00],\n",
      "        [-1.6389e+00, -4.6058e-01],\n",
      "        [-1.1883e+00,  1.4122e+00],\n",
      "        [-7.1687e-01,  2.9912e+00],\n",
      "        [-4.0433e-01,  4.0200e+00],\n",
      "        [-1.5017e+00, -2.8387e+00],\n",
      "        [-1.2681e+00, -1.3184e+00],\n",
      "        [-8.5593e-01,  5.3339e-01],\n",
      "        [-3.6644e-01,  2.3267e+00],\n",
      "        [-5.9811e-02,  3.4954e+00],\n",
      "        [-1.0980e+00, -3.5837e+00],\n",
      "        [-8.2013e-01, -2.1960e+00],\n",
      "        [-4.3503e-01, -4.3218e-01],\n",
      "        [ 4.7614e-02,  1.5033e+00],\n",
      "        [ 3.4125e-01,  2.8501e+00],\n",
      "        [-7.6593e-01, -4.2393e+00],\n",
      "        [-4.2555e-01, -2.9829e+00],\n",
      "        [ 2.6391e-03, -1.4011e+00],\n",
      "        [ 4.8273e-01,  5.1599e-01],\n",
      "        [ 7.7469e-01,  2.0764e+00],\n",
      "        [-5.0103e-01, -4.8041e+00],\n",
      "        [-1.1736e-01, -3.6454e+00],\n",
      "        [ 3.3330e-01, -2.2340e+00],\n",
      "        [ 8.1520e-01, -4.8193e-01],\n",
      "        [ 1.1737e+00,  1.2064e+00]], grad_fn=<AddmmBackward>)\n",
      "epoch: 97 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.8932e+00, -2.0464e+00],\n",
      "        [-1.6412e+00, -4.6352e-01],\n",
      "        [-1.1898e+00,  1.4104e+00],\n",
      "        [-7.1701e-01,  2.9937e+00],\n",
      "        [-4.0417e-01,  4.0253e+00],\n",
      "        [-1.5037e+00, -2.8429e+00],\n",
      "        [-1.2692e+00, -1.3208e+00],\n",
      "        [-8.5591e-01,  5.3183e-01],\n",
      "        [-3.6561e-01,  2.3279e+00],\n",
      "        [-5.8908e-02,  3.4992e+00],\n",
      "        [-1.0984e+00, -3.5889e+00],\n",
      "        [-8.2005e-01, -2.1982e+00],\n",
      "        [-4.3378e-01, -4.3265e-01],\n",
      "        [ 4.9380e-02,  1.5035e+00],\n",
      "        [ 3.4290e-01,  2.8525e+00],\n",
      "        [-7.6494e-01, -4.2454e+00],\n",
      "        [-4.2426e-01, -2.9854e+00],\n",
      "        [ 4.3929e-03, -1.4004e+00],\n",
      "        [ 4.8479e-01,  5.1681e-01],\n",
      "        [ 7.7694e-01,  2.0780e+00],\n",
      "        [-4.9903e-01, -4.8110e+00],\n",
      "        [-1.1497e-01, -3.6486e+00],\n",
      "        [ 3.3576e-01, -2.2332e+00],\n",
      "        [ 8.1743e-01, -4.7906e-01],\n",
      "        [ 1.1758e+00,  1.2084e+00]], grad_fn=<AddmmBackward>)\n",
      "epoch: 98 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.8972, -2.0490],\n",
      "        [-1.6441, -0.4664],\n",
      "        [-1.1921,  1.4072],\n",
      "        [-0.7179,  2.9941],\n",
      "        [-0.4046,  4.0279],\n",
      "        [-1.5064, -2.8458],\n",
      "        [-1.2710, -1.3229],\n",
      "        [-0.8566,  0.5289],\n",
      "        [-0.3654,  2.3268],\n",
      "        [-0.0584,  3.5003],\n",
      "        [-1.0995, -3.5927],\n",
      "        [-0.8206, -2.2001],\n",
      "        [-0.4332, -0.4343],\n",
      "        [ 0.0506,  1.5013],\n",
      "        [ 0.3443,  2.8521],\n",
      "        [-0.7645, -4.2502],\n",
      "        [-0.4235, -2.9876],\n",
      "        [ 0.0056, -1.4007],\n",
      "        [ 0.4864,  0.5151],\n",
      "        [ 0.7791,  2.0765],\n",
      "        [-0.4975, -4.8165],\n",
      "        [-0.1130, -3.6512],\n",
      "        [ 0.3378, -2.2332],\n",
      "        [ 0.8192, -0.4785],\n",
      "        [ 1.1778,  1.2072]], grad_fn=<AddmmBackward>)\n",
      "epoch: 99 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9018, -2.0495],\n",
      "        [-1.6475, -0.4684],\n",
      "        [-1.1951,  1.4034],\n",
      "        [-0.7194,  2.9927],\n",
      "        [-0.4055,  4.0282],\n",
      "        [-1.5098, -2.8466],\n",
      "        [-1.2734, -1.3241],\n",
      "        [-0.8580,  0.5255],\n",
      "        [-0.3658,  2.3240],\n",
      "        [-0.0584,  3.4990],\n",
      "        [-1.1012, -3.5943],\n",
      "        [-0.8218, -2.2008],\n",
      "        [-0.4332, -0.4363],\n",
      "        [ 0.0513,  1.4972],\n",
      "        [ 0.3453,  2.8493],\n",
      "        [-0.7646, -4.2530],\n",
      "        [-0.4233, -2.9885],\n",
      "        [ 0.0063, -1.4011],\n",
      "        [ 0.4874,  0.5117],\n",
      "        [ 0.7809,  2.0724],\n",
      "        [-0.4964, -4.8201],\n",
      "        [-0.1116, -3.6528],\n",
      "        [ 0.3393, -2.2332],\n",
      "        [ 0.8205, -0.4794],\n",
      "        [ 1.1794,  1.2035]], grad_fn=<AddmmBackward>)\n",
      "epoch: 100 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9067, -2.0477],\n",
      "        [-1.6511, -0.4689],\n",
      "        [-1.1984,  1.3995],\n",
      "        [-0.7214,  2.9902],\n",
      "        [-0.4070,  4.0266],\n",
      "        [-1.5136, -2.8449],\n",
      "        [-1.2761, -1.3236],\n",
      "        [-0.8598,  0.5224],\n",
      "        [-0.3667,  2.3201],\n",
      "        [-0.0589,  3.4959],\n",
      "        [-1.1032, -3.5935],\n",
      "        [-0.8233, -2.1998],\n",
      "        [-0.4336, -0.4379],\n",
      "        [ 0.0514,  1.4922],\n",
      "        [ 0.3459,  2.8446],\n",
      "        [-0.7649, -4.2533],\n",
      "        [-0.4233, -2.9879],\n",
      "        [ 0.0066, -1.4009],\n",
      "        [ 0.4879,  0.5074],\n",
      "        [ 0.7823,  2.0666],\n",
      "        [-0.4955, -4.8213],\n",
      "        [-0.1104, -3.6527],\n",
      "        [ 0.3405, -2.2325],\n",
      "        [ 0.8212, -0.4811],\n",
      "        [ 1.1806,  1.1981]], grad_fn=<AddmmBackward>)\n",
      "epoch: 101 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9115, -2.0433],\n",
      "        [-1.6546, -0.4678],\n",
      "        [-1.2018,  1.3963],\n",
      "        [-0.7238,  2.9872],\n",
      "        [-0.4089,  4.0239],\n",
      "        [-1.5173, -2.8406],\n",
      "        [-1.2788, -1.3214],\n",
      "        [-0.8617,  0.5199],\n",
      "        [-0.3681,  2.3157],\n",
      "        [-0.0598,  3.4916],\n",
      "        [-1.1052, -3.5902],\n",
      "        [-0.8250, -2.1970],\n",
      "        [-0.4343, -0.4386],\n",
      "        [ 0.0512,  1.4867],\n",
      "        [ 0.3459,  2.8388],\n",
      "        [-0.7652, -4.2513],\n",
      "        [-0.4235, -2.9854],\n",
      "        [ 0.0066, -1.3998],\n",
      "        [ 0.4879,  0.5028],\n",
      "        [ 0.7832,  2.0596],\n",
      "        [-0.4945, -4.8203],\n",
      "        [-0.1092, -3.6509],\n",
      "        [ 0.3414, -2.2308],\n",
      "        [ 0.8215, -0.4828],\n",
      "        [ 1.1813,  1.1915]], grad_fn=<AddmmBackward>)\n",
      "epoch: 102 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9157, -2.0372],\n",
      "        [-1.6576, -0.4653],\n",
      "        [-1.2050,  1.3937],\n",
      "        [-0.7263,  2.9839],\n",
      "        [-0.4113,  4.0205],\n",
      "        [-1.5205, -2.8345],\n",
      "        [-1.2811, -1.3177],\n",
      "        [-0.8634,  0.5183],\n",
      "        [-0.3696,  2.3112],\n",
      "        [-0.0612,  3.4867],\n",
      "        [-1.1069, -3.5850],\n",
      "        [-0.8263, -2.1927],\n",
      "        [-0.4349, -0.4385],\n",
      "        [ 0.0506,  1.4812],\n",
      "        [ 0.3455,  2.8323],\n",
      "        [-0.7651, -4.2476],\n",
      "        [-0.4234, -2.9816],\n",
      "        [ 0.0066, -1.3978],\n",
      "        [ 0.4876,  0.4982],\n",
      "        [ 0.7836,  2.0520],\n",
      "        [-0.4931, -4.8176],\n",
      "        [-0.1079, -3.6478],\n",
      "        [ 0.3423, -2.2283],\n",
      "        [ 0.8214, -0.4844],\n",
      "        [ 1.1813,  1.1845]], grad_fn=<AddmmBackward>)\n",
      "epoch: 103 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9189, -2.0301],\n",
      "        [-1.6598, -0.4619],\n",
      "        [-1.2076,  1.3916],\n",
      "        [-0.7289,  2.9807],\n",
      "        [-0.4138,  4.0169],\n",
      "        [-1.5229, -2.8276],\n",
      "        [-1.2826, -1.3133],\n",
      "        [-0.8647,  0.5172],\n",
      "        [-0.3712,  2.3067],\n",
      "        [-0.0629,  3.4815],\n",
      "        [-1.1077, -3.5790],\n",
      "        [-0.8271, -2.1877],\n",
      "        [-0.4352, -0.4378],\n",
      "        [ 0.0499,  1.4759],\n",
      "        [ 0.3446,  2.8257],\n",
      "        [-0.7643, -4.2430],\n",
      "        [-0.4229, -2.9770],\n",
      "        [ 0.0068, -1.3954],\n",
      "        [ 0.4870,  0.4939],\n",
      "        [ 0.7835,  2.0443],\n",
      "        [-0.4912, -4.8141],\n",
      "        [-0.1062, -3.6440],\n",
      "        [ 0.3432, -2.2253],\n",
      "        [ 0.8211, -0.4858],\n",
      "        [ 1.1808,  1.1774]], grad_fn=<AddmmBackward>)\n",
      "epoch: 104 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9208, -2.0232],\n",
      "        [-1.6611, -0.4586],\n",
      "        [-1.2096,  1.3898],\n",
      "        [-0.7311,  2.9777],\n",
      "        [-0.4164,  4.0135],\n",
      "        [-1.5241, -2.8209],\n",
      "        [-1.2833, -1.3090],\n",
      "        [-0.8654,  0.5162],\n",
      "        [-0.3725,  2.3024],\n",
      "        [-0.0648,  3.4766],\n",
      "        [-1.1076, -3.5732],\n",
      "        [-0.8272, -2.1829],\n",
      "        [-0.4351, -0.4371],\n",
      "        [ 0.0492,  1.4707],\n",
      "        [ 0.3436,  2.8194],\n",
      "        [-0.7629, -4.2386],\n",
      "        [-0.4219, -2.9726],\n",
      "        [ 0.0072, -1.3929],\n",
      "        [ 0.4864,  0.4897],\n",
      "        [ 0.7830,  2.0369],\n",
      "        [-0.4887, -4.8109],\n",
      "        [-0.1042, -3.6404],\n",
      "        [ 0.3442, -2.2223],\n",
      "        [ 0.8206, -0.4871],\n",
      "        [ 1.1799,  1.1705]], grad_fn=<AddmmBackward>)\n",
      "epoch: 105 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9216, -2.0175],\n",
      "        [-1.6613, -0.4559],\n",
      "        [-1.2108,  1.3878],\n",
      "        [-0.7329,  2.9750],\n",
      "        [-0.4188,  4.0107],\n",
      "        [-1.5241, -2.8154],\n",
      "        [-1.2831, -1.3055],\n",
      "        [-0.8654,  0.5149],\n",
      "        [-0.3736,  2.2983],\n",
      "        [-0.0665,  3.4723],\n",
      "        [-1.1066, -3.5687],\n",
      "        [-0.8265, -2.1790],\n",
      "        [-0.4345, -0.4368],\n",
      "        [ 0.0487,  1.4656],\n",
      "        [ 0.3424,  2.8135],\n",
      "        [-0.7609, -4.2353],\n",
      "        [-0.4205, -2.9690],\n",
      "        [ 0.0078, -1.3909],\n",
      "        [ 0.4857,  0.4855],\n",
      "        [ 0.7822,  2.0299],\n",
      "        [-0.4859, -4.8087],\n",
      "        [-0.1020, -3.6377],\n",
      "        [ 0.3452, -2.2199],\n",
      "        [ 0.8198, -0.4885],\n",
      "        [ 1.1785,  1.1640]], grad_fn=<AddmmBackward>)\n",
      "epoch: 106 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9213, -2.0135],\n",
      "        [-1.6607, -0.4544],\n",
      "        [-1.2113,  1.3856],\n",
      "        [-0.7340,  2.9727],\n",
      "        [-0.4208,  4.0088],\n",
      "        [-1.5232, -2.8118],\n",
      "        [-1.2821, -1.3033],\n",
      "        [-0.8649,  0.5132],\n",
      "        [-0.3742,  2.2946],\n",
      "        [-0.0681,  3.4688],\n",
      "        [-1.1051, -3.5659],\n",
      "        [-0.8253, -2.1764],\n",
      "        [-0.4335, -0.4372],\n",
      "        [ 0.0485,  1.4608],\n",
      "        [ 0.3412,  2.8085],\n",
      "        [-0.7586, -4.2338],\n",
      "        [-0.4189, -2.9667],\n",
      "        [ 0.0085, -1.3897],\n",
      "        [ 0.4850,  0.4815],\n",
      "        [ 0.7812,  2.0238],\n",
      "        [-0.4832, -4.8083],\n",
      "        [-0.1000, -3.6362],\n",
      "        [ 0.3459, -2.2183],\n",
      "        [ 0.8188, -0.4899],\n",
      "        [ 1.1768,  1.1583]], grad_fn=<AddmmBackward>)\n",
      "epoch: 107 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9203, -2.0114],\n",
      "        [-1.6596, -0.4539],\n",
      "        [-1.2111,  1.3833],\n",
      "        [-0.7346,  2.9712],\n",
      "        [-0.4222,  4.0080],\n",
      "        [-1.5219, -2.8101],\n",
      "        [-1.2806, -1.3023],\n",
      "        [-0.8639,  0.5112],\n",
      "        [-0.3743,  2.2915],\n",
      "        [-0.0692,  3.4665],\n",
      "        [-1.1035, -3.5650],\n",
      "        [-0.8239, -2.1752],\n",
      "        [-0.4324, -0.4380],\n",
      "        [ 0.0484,  1.4565],\n",
      "        [ 0.3402,  2.8047],\n",
      "        [-0.7566, -4.2341],\n",
      "        [-0.4175, -2.9658],\n",
      "        [ 0.0090, -1.3890],\n",
      "        [ 0.4842,  0.4779],\n",
      "        [ 0.7801,  2.0188],\n",
      "        [-0.4810, -4.8097],\n",
      "        [-0.0984, -3.6361],\n",
      "        [ 0.3463, -2.2173],\n",
      "        [ 0.8175, -0.4911],\n",
      "        [ 1.1748,  1.1536]], grad_fn=<AddmmBackward>)\n",
      "epoch: 108 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9191, -2.0108],\n",
      "        [-1.6581, -0.4542],\n",
      "        [-1.2105,  1.3811],\n",
      "        [-0.7344,  2.9705],\n",
      "        [-0.4230,  4.0087],\n",
      "        [-1.5205, -2.8101],\n",
      "        [-1.2791, -1.3023],\n",
      "        [-0.8626,  0.5092],\n",
      "        [-0.3741,  2.2892],\n",
      "        [-0.0700,  3.4656],\n",
      "        [-1.1021, -3.5658],\n",
      "        [-0.8227, -2.1750],\n",
      "        [-0.4313, -0.4389],\n",
      "        [ 0.0484,  1.4531],\n",
      "        [ 0.3393,  2.8023],\n",
      "        [-0.7553, -4.2361],\n",
      "        [-0.4167, -2.9660],\n",
      "        [ 0.0092, -1.3887],\n",
      "        [ 0.4832,  0.4751],\n",
      "        [ 0.7790,  2.0153],\n",
      "        [-0.4797, -4.8128],\n",
      "        [-0.0977, -3.6372],\n",
      "        [ 0.3460, -2.2167],\n",
      "        [ 0.8159, -0.4918],\n",
      "        [ 1.1725,  1.1503]], grad_fn=<AddmmBackward>)\n",
      "epoch: 109 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9181, -2.0112],\n",
      "        [-1.6565, -0.4548],\n",
      "        [-1.2094,  1.3796],\n",
      "        [-0.7337,  2.9710],\n",
      "        [-0.4231,  4.0108],\n",
      "        [-1.5196, -2.8111],\n",
      "        [-1.2777, -1.3027],\n",
      "        [-0.8612,  0.5077],\n",
      "        [-0.3734,  2.2881],\n",
      "        [-0.0702,  3.4662],\n",
      "        [-1.1015, -3.5677],\n",
      "        [-0.8220, -2.1753],\n",
      "        [-0.4304, -0.4395],\n",
      "        [ 0.0486,  1.4509],\n",
      "        [ 0.3387,  2.8015],\n",
      "        [-0.7549, -4.2392],\n",
      "        [-0.4166, -2.9667],\n",
      "        [ 0.0088, -1.3881],\n",
      "        [ 0.4821,  0.4734],\n",
      "        [ 0.7778,  2.0133],\n",
      "        [-0.4797, -4.8170],\n",
      "        [-0.0980, -3.6388],\n",
      "        [ 0.3450, -2.2161],\n",
      "        [ 0.8138, -0.4915],\n",
      "        [ 1.1701,  1.1487]], grad_fn=<AddmmBackward>)\n",
      "epoch: 110 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9175, -2.0121],\n",
      "        [-1.6551, -0.4553],\n",
      "        [-1.2080,  1.3788],\n",
      "        [-0.7325,  2.9727],\n",
      "        [-0.4226,  4.0144],\n",
      "        [-1.5192, -2.8127],\n",
      "        [-1.2768, -1.3031],\n",
      "        [-0.8598,  0.5070],\n",
      "        [-0.3725,  2.2883],\n",
      "        [-0.0700,  3.4683],\n",
      "        [-1.1017, -3.5701],\n",
      "        [-0.8220, -2.1756],\n",
      "        [-0.4298, -0.4394],\n",
      "        [ 0.0487,  1.4500],\n",
      "        [ 0.3383,  2.8022],\n",
      "        [-0.7556, -4.2429],\n",
      "        [-0.4173, -2.9674],\n",
      "        [ 0.0080, -1.3869],\n",
      "        [ 0.4809,  0.4731],\n",
      "        [ 0.7766,  2.0131],\n",
      "        [-0.4809, -4.8218],\n",
      "        [-0.0992, -3.6406],\n",
      "        [ 0.3433, -2.2151],\n",
      "        [ 0.8114, -0.4900],\n",
      "        [ 1.1675,  1.1487]], grad_fn=<AddmmBackward>)\n",
      "epoch: 111 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9173, -2.0131],\n",
      "        [-1.6538, -0.4554],\n",
      "        [-1.2064,  1.3790],\n",
      "        [-0.7309,  2.9755],\n",
      "        [-0.4216,  4.0191],\n",
      "        [-1.5194, -2.8144],\n",
      "        [-1.2761, -1.3031],\n",
      "        [-0.8585,  0.5072],\n",
      "        [-0.3713,  2.2897],\n",
      "        [-0.0695,  3.4716],\n",
      "        [-1.1027, -3.5726],\n",
      "        [-0.8224, -2.1757],\n",
      "        [-0.4295, -0.4384],\n",
      "        [ 0.0490,  1.4504],\n",
      "        [ 0.3381,  2.8043],\n",
      "        [-0.7572, -4.2467],\n",
      "        [-0.4188, -2.9680],\n",
      "        [ 0.0068, -1.3850],\n",
      "        [ 0.4795,  0.4742],\n",
      "        [ 0.7755,  2.0143],\n",
      "        [-0.4831, -4.8268],\n",
      "        [-0.1013, -3.6423],\n",
      "        [ 0.3411, -2.2134],\n",
      "        [ 0.8087, -0.4872],\n",
      "        [ 1.1649,  1.1502]], grad_fn=<AddmmBackward>)\n",
      "epoch: 112 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9172, -2.0140],\n",
      "        [-1.6526, -0.4552],\n",
      "        [-1.2047,  1.3798],\n",
      "        [-0.7290,  2.9791],\n",
      "        [-0.4202,  4.0247],\n",
      "        [-1.5200, -2.8160],\n",
      "        [-1.2756, -1.3028],\n",
      "        [-0.8570,  0.5081],\n",
      "        [-0.3699,  2.2919],\n",
      "        [-0.0687,  3.4759],\n",
      "        [-1.1041, -3.5751],\n",
      "        [-0.8231, -2.1754],\n",
      "        [-0.4292, -0.4366],\n",
      "        [ 0.0493,  1.4518],\n",
      "        [ 0.3381,  2.8074],\n",
      "        [-0.7594, -4.2504],\n",
      "        [-0.4206, -2.9682],\n",
      "        [ 0.0054, -1.3824],\n",
      "        [ 0.4783,  0.4763],\n",
      "        [ 0.7745,  2.0166],\n",
      "        [-0.4858, -4.8318],\n",
      "        [-0.1038, -3.6437],\n",
      "        [ 0.3386, -2.2110],\n",
      "        [ 0.8061, -0.4835],\n",
      "        [ 1.1624,  1.1528]], grad_fn=<AddmmBackward>)\n",
      "epoch: 113 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9172e+00, -2.0150e+00],\n",
      "        [-1.6513e+00, -4.5479e-01],\n",
      "        [-1.2028e+00,  1.3809e+00],\n",
      "        [-7.2691e-01,  2.9830e+00],\n",
      "        [-4.1869e-01,  4.0307e+00],\n",
      "        [-1.5206e+00, -2.8176e+00],\n",
      "        [-1.2751e+00, -1.3023e+00],\n",
      "        [-8.5546e-01,  5.0943e-01],\n",
      "        [-3.6838e-01,  2.2945e+00],\n",
      "        [-6.7645e-02,  3.4806e+00],\n",
      "        [-1.1055e+00, -3.5774e+00],\n",
      "        [-8.2384e-01, -2.1748e+00],\n",
      "        [-4.2873e-01, -4.3444e-01],\n",
      "        [ 4.9871e-02,  1.4537e+00],\n",
      "        [ 3.3831e-01,  2.8109e+00],\n",
      "        [-7.6155e-01, -4.2540e+00],\n",
      "        [-4.2232e-01, -2.9682e+00],\n",
      "        [ 4.1259e-03, -1.3794e+00],\n",
      "        [ 4.7718e-01,  4.7893e-01],\n",
      "        [ 7.7364e-01,  2.0194e+00],\n",
      "        [-4.8865e-01, -4.8366e+00],\n",
      "        [-1.0630e-01, -3.6449e+00],\n",
      "        [ 3.3626e-01, -2.2083e+00],\n",
      "        [ 8.0369e-01, -4.7920e-01],\n",
      "        [ 1.1601e+00,  1.1560e+00]], grad_fn=<AddmmBackward>)\n",
      "epoch: 114 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9170e+00, -2.0160e+00],\n",
      "        [-1.6498e+00, -4.5458e-01],\n",
      "        [-1.2008e+00,  1.3818e+00],\n",
      "        [-7.2480e-01,  2.9867e+00],\n",
      "        [-4.1715e-01,  4.0366e+00],\n",
      "        [-1.5208e+00, -2.8193e+00],\n",
      "        [-1.2743e+00, -1.3019e+00],\n",
      "        [-8.5368e-01,  5.1059e-01],\n",
      "        [-3.6669e-01,  2.2970e+00],\n",
      "        [-6.6549e-02,  3.4851e+00],\n",
      "        [-1.1066e+00, -3.5798e+00],\n",
      "        [-8.2419e-01, -2.1744e+00],\n",
      "        [-4.2797e-01, -4.3237e-01],\n",
      "        [ 5.0636e-02,  1.4555e+00],\n",
      "        [ 3.3867e-01,  2.8143e+00],\n",
      "        [-7.6335e-01, -4.2576e+00],\n",
      "        [-4.2371e-01, -2.9682e+00],\n",
      "        [ 3.2359e-03, -1.3763e+00],\n",
      "        [ 4.7642e-01,  4.8153e-01],\n",
      "        [ 7.7306e-01,  2.0221e+00],\n",
      "        [-4.9108e-01, -4.8413e+00],\n",
      "        [-1.0837e-01, -3.6459e+00],\n",
      "        [ 3.3429e-01, -2.2055e+00],\n",
      "        [ 8.0163e-01, -4.7486e-01],\n",
      "        [ 1.1581e+00,  1.1592e+00]], grad_fn=<AddmmBackward>)\n",
      "epoch: 115 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9163e+00, -2.0174e+00],\n",
      "        [-1.6482e+00, -4.5479e-01],\n",
      "        [-1.1989e+00,  1.3822e+00],\n",
      "        [-7.2279e-01,  2.9898e+00],\n",
      "        [-4.1577e-01,  4.0419e+00],\n",
      "        [-1.5206e+00, -2.8212e+00],\n",
      "        [-1.2731e+00, -1.3019e+00],\n",
      "        [-8.5169e-01,  5.1119e-01],\n",
      "        [-3.6495e-01,  2.2988e+00],\n",
      "        [-6.5471e-02,  3.4891e+00],\n",
      "        [-1.1071e+00, -3.5823e+00],\n",
      "        [-8.2402e-01, -2.1742e+00],\n",
      "        [-4.2681e-01, -4.3078e-01],\n",
      "        [ 5.1633e-02,  1.4566e+00],\n",
      "        [ 3.3918e-01,  2.8172e+00],\n",
      "        [-7.6450e-01, -4.2612e+00],\n",
      "        [-4.2450e-01, -2.9683e+00],\n",
      "        [ 2.8588e-03, -1.3736e+00],\n",
      "        [ 4.7603e-01,  4.8358e-01],\n",
      "        [ 7.7275e-01,  2.0242e+00],\n",
      "        [-4.9279e-01, -4.8460e+00],\n",
      "        [-1.0977e-01, -3.6470e+00],\n",
      "        [ 3.3290e-01, -2.2028e+00],\n",
      "        [ 8.0004e-01, -4.7095e-01],\n",
      "        [ 1.1564e+00,  1.1619e+00]], grad_fn=<AddmmBackward>)\n",
      "epoch: 116 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9154e+00, -2.0189e+00],\n",
      "        [-1.6464e+00, -4.5549e-01],\n",
      "        [-1.1970e+00,  1.3817e+00],\n",
      "        [-7.2103e-01,  2.9922e+00],\n",
      "        [-4.1467e-01,  4.0464e+00],\n",
      "        [-1.5199e+00, -2.8232e+00],\n",
      "        [-1.2716e+00, -1.3023e+00],\n",
      "        [-8.4959e-01,  5.1105e-01],\n",
      "        [-3.6324e-01,  2.2998e+00],\n",
      "        [-6.4514e-02,  3.4922e+00],\n",
      "        [-1.1070e+00, -3.5848e+00],\n",
      "        [-8.2331e-01, -2.1743e+00],\n",
      "        [-4.2529e-01, -4.2985e-01],\n",
      "        [ 5.2798e-02,  1.4568e+00],\n",
      "        [ 3.3976e-01,  2.8191e+00],\n",
      "        [-7.6491e-01, -4.2646e+00],\n",
      "        [-4.2464e-01, -2.9685e+00],\n",
      "        [ 3.0034e-03, -1.3714e+00],\n",
      "        [ 4.7598e-01,  4.8477e-01],\n",
      "        [ 7.7271e-01,  2.0254e+00],\n",
      "        [-4.9367e-01, -4.8505e+00],\n",
      "        [-1.1042e-01, -3.6481e+00],\n",
      "        [ 3.3214e-01, -2.2005e+00],\n",
      "        [ 7.9893e-01, -4.6774e-01],\n",
      "        [ 1.1552e+00,  1.1636e+00]], grad_fn=<AddmmBackward>)\n",
      "epoch: 117 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9143e+00, -2.0204e+00],\n",
      "        [-1.6447e+00, -4.5653e-01],\n",
      "        [-1.1954e+00,  1.3804e+00],\n",
      "        [-7.1964e-01,  2.9936e+00],\n",
      "        [-4.1398e-01,  4.0500e+00],\n",
      "        [-1.5188e+00, -2.8250e+00],\n",
      "        [-1.2699e+00, -1.3029e+00],\n",
      "        [-8.4755e-01,  5.1020e-01],\n",
      "        [-3.6172e-01,  2.2998e+00],\n",
      "        [-6.3773e-02,  3.4944e+00],\n",
      "        [-1.1064e+00, -3.5871e+00],\n",
      "        [-8.2225e-01, -2.1745e+00],\n",
      "        [-4.2356e-01, -4.2953e-01],\n",
      "        [ 5.4014e-02,  1.4561e+00],\n",
      "        [ 3.4033e-01,  2.8200e+00],\n",
      "        [-7.6473e-01, -4.2678e+00],\n",
      "        [-4.2425e-01, -2.9687e+00],\n",
      "        [ 3.5541e-03, -1.3696e+00],\n",
      "        [ 4.7618e-01,  4.8503e-01],\n",
      "        [ 7.7287e-01,  2.0254e+00],\n",
      "        [-4.9382e-01, -4.8546e+00],\n",
      "        [-1.1040e-01, -3.6491e+00],\n",
      "        [ 3.3194e-01, -2.1984e+00],\n",
      "        [ 7.9824e-01, -4.6530e-01],\n",
      "        [ 1.1542e+00,  1.1642e+00]], grad_fn=<AddmmBackward>)\n",
      "epoch: 118 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9135e+00, -2.0215e+00],\n",
      "        [-1.6432e+00, -4.5762e-01],\n",
      "        [-1.1943e+00,  1.3785e+00],\n",
      "        [-7.1876e-01,  2.9941e+00],\n",
      "        [-4.1377e-01,  4.0526e+00],\n",
      "        [-1.5178e+00, -2.8264e+00],\n",
      "        [-1.2684e+00, -1.3034e+00],\n",
      "        [-8.4576e-01,  5.0886e-01],\n",
      "        [-3.6051e-01,  2.2989e+00],\n",
      "        [-6.3332e-02,  3.4955e+00],\n",
      "        [-1.1056e+00, -3.5888e+00],\n",
      "        [-8.2110e-01, -2.1746e+00],\n",
      "        [-4.2184e-01, -4.2959e-01],\n",
      "        [ 5.5132e-02,  1.4545e+00],\n",
      "        [ 3.4082e-01,  2.8198e+00],\n",
      "        [-7.6420e-01, -4.2704e+00],\n",
      "        [-4.2358e-01, -2.9687e+00],\n",
      "        [ 4.3153e-03, -1.3681e+00],\n",
      "        [ 4.7649e-01,  4.8450e-01],\n",
      "        [ 7.7315e-01,  2.0244e+00],\n",
      "        [-4.9348e-01, -4.8581e+00],\n",
      "        [-1.0994e-01, -3.6497e+00],\n",
      "        [ 3.3212e-01, -2.1964e+00],\n",
      "        [ 7.9784e-01, -4.6353e-01],\n",
      "        [ 1.1536e+00,  1.1639e+00]], grad_fn=<AddmmBackward>)\n",
      "epoch: 119 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9131, -2.0218],\n",
      "        [-1.6423, -0.4584],\n",
      "        [-1.1938,  1.3764],\n",
      "        [-0.7185,  2.9941],\n",
      "        [-0.4141,  4.0544],\n",
      "        [-1.5172, -2.8268],\n",
      "        [-1.2672, -1.3036],\n",
      "        [-0.8444,  0.5073],\n",
      "        [-0.3597,  2.2975],\n",
      "        [-0.0632,  3.4959],\n",
      "        [-1.1051, -3.5896],\n",
      "        [-0.8202, -2.1741],\n",
      "        [-0.4204, -0.4297],\n",
      "        [ 0.0560,  1.4522],\n",
      "        [ 0.3411,  2.8188],\n",
      "        [-0.7636, -4.2721],\n",
      "        [-0.4229, -2.9681],\n",
      "        [ 0.0051, -1.3666],\n",
      "        [ 0.4768,  0.4834],\n",
      "        [ 0.7735,  2.0225],\n",
      "        [-0.4929, -4.8606],\n",
      "        [-0.1093, -3.6498],\n",
      "        [ 0.3325, -2.1943],\n",
      "        [ 0.7976, -0.4622],\n",
      "        [ 1.1530,  1.1627]], grad_fn=<AddmmBackward>)\n",
      "epoch: 120 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9134, -2.0212],\n",
      "        [-1.6420, -0.4587],\n",
      "        [-1.1939,  1.3742],\n",
      "        [-0.7188,  2.9936],\n",
      "        [-0.4149,  4.0556],\n",
      "        [-1.5172, -2.8263],\n",
      "        [-1.2666, -1.3031],\n",
      "        [-0.8436,  0.5059],\n",
      "        [-0.3594,  2.2956],\n",
      "        [-0.0635,  3.4956],\n",
      "        [-1.1049, -3.5894],\n",
      "        [-0.8196, -2.1730],\n",
      "        [-0.4193, -0.4297],\n",
      "        [ 0.0566,  1.4496],\n",
      "        [ 0.3413,  2.8172],\n",
      "        [-0.7633, -4.2728],\n",
      "        [-0.4224, -2.9669],\n",
      "        [ 0.0057, -1.3648],\n",
      "        [ 0.4769,  0.4820],\n",
      "        [ 0.7737,  2.0200],\n",
      "        [-0.4924, -4.8622],\n",
      "        [-0.1086, -3.6492],\n",
      "        [ 0.3328, -2.1919],\n",
      "        [ 0.7974, -0.4611],\n",
      "        [ 1.1526,  1.1608]], grad_fn=<AddmmBackward>)\n",
      "epoch: 121 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9144, -2.0196],\n",
      "        [-1.6424, -0.4584],\n",
      "        [-1.1947,  1.3721],\n",
      "        [-0.7196,  2.9929],\n",
      "        [-0.4161,  4.0564],\n",
      "        [-1.5179, -2.8247],\n",
      "        [-1.2666, -1.3020],\n",
      "        [-0.8434,  0.5046],\n",
      "        [-0.3596,  2.2935],\n",
      "        [-0.0642,  3.4949],\n",
      "        [-1.1053, -3.5882],\n",
      "        [-0.8196, -2.1712],\n",
      "        [-0.4186, -0.4295],\n",
      "        [ 0.0568,  1.4468],\n",
      "        [ 0.3411,  2.8151],\n",
      "        [-0.7632, -4.2726],\n",
      "        [-0.4222, -2.9651],\n",
      "        [ 0.0060, -1.3628],\n",
      "        [ 0.4769,  0.4804],\n",
      "        [ 0.7739,  2.0169],\n",
      "        [-0.4921, -4.8630],\n",
      "        [-0.1081, -3.6480],\n",
      "        [ 0.3331, -2.1892],\n",
      "        [ 0.7971, -0.4602],\n",
      "        [ 1.1523,  1.1584]], grad_fn=<AddmmBackward>)\n",
      "epoch: 122 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9161, -2.0173],\n",
      "        [-1.6434, -0.4577],\n",
      "        [-1.1960,  1.3700],\n",
      "        [-0.7209,  2.9920],\n",
      "        [-0.4177,  4.0569],\n",
      "        [-1.5192, -2.8225],\n",
      "        [-1.2672, -1.3005],\n",
      "        [-0.8437,  0.5035],\n",
      "        [-0.3602,  2.2913],\n",
      "        [-0.0651,  3.4939],\n",
      "        [-1.1060, -3.5865],\n",
      "        [-0.8200, -2.1690],\n",
      "        [-0.4183, -0.4291],\n",
      "        [ 0.0567,  1.4438],\n",
      "        [ 0.3409,  2.8127],\n",
      "        [-0.7635, -4.2719],\n",
      "        [-0.4222, -2.9628],\n",
      "        [ 0.0062, -1.3607],\n",
      "        [ 0.4767,  0.4786],\n",
      "        [ 0.7740,  2.0135],\n",
      "        [-0.4919, -4.8633],\n",
      "        [-0.1077, -3.6465],\n",
      "        [ 0.3333, -2.1864],\n",
      "        [ 0.7969, -0.4595],\n",
      "        [ 1.1519,  1.1557]], grad_fn=<AddmmBackward>)\n",
      "epoch: 123 Loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9181, -2.0149],\n",
      "        [-1.6447, -0.4569],\n",
      "        [-1.1977,  1.3680],\n",
      "        [-0.7226,  2.9911],\n",
      "        [-0.4196,  4.0574],\n",
      "        [-1.5208, -2.8201],\n",
      "        [-1.2680, -1.2989],\n",
      "        [-0.8443,  0.5023],\n",
      "        [-0.3610,  2.2890],\n",
      "        [-0.0662,  3.4929],\n",
      "        [-1.1071, -3.5846],\n",
      "        [-0.8206, -2.1668],\n",
      "        [-0.4183, -0.4287],\n",
      "        [ 0.0564,  1.4407],\n",
      "        [ 0.3404,  2.8102],\n",
      "        [-0.7639, -4.2710],\n",
      "        [-0.4224, -2.9605],\n",
      "        [ 0.0062, -1.3586],\n",
      "        [ 0.4764,  0.4767],\n",
      "        [ 0.7741,  2.0100],\n",
      "        [-0.4918, -4.8634],\n",
      "        [-0.1074, -3.6450],\n",
      "        [ 0.3335, -2.1837],\n",
      "        [ 0.7966, -0.4589],\n",
      "        [ 1.1516,  1.1527]], grad_fn=<AddmmBackward>)\n",
      "epoch: 124 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9202, -2.0126],\n",
      "        [-1.6462, -0.4562],\n",
      "        [-1.1995,  1.3659],\n",
      "        [-0.7243,  2.9902],\n",
      "        [-0.4216,  4.0581],\n",
      "        [-1.5224, -2.8179],\n",
      "        [-1.2689, -1.2974],\n",
      "        [-0.8449,  0.5010],\n",
      "        [-0.3619,  2.2866],\n",
      "        [-0.0674,  3.4919],\n",
      "        [-1.1080, -3.5829],\n",
      "        [-0.8212, -2.1647],\n",
      "        [-0.4182, -0.4286],\n",
      "        [ 0.0561,  1.4375],\n",
      "        [ 0.3400,  2.8076],\n",
      "        [-0.7642, -4.2704],\n",
      "        [-0.4225, -2.9585],\n",
      "        [ 0.0062, -1.3569],\n",
      "        [ 0.4761,  0.4745],\n",
      "        [ 0.7742,  2.0063],\n",
      "        [-0.4916, -4.8639],\n",
      "        [-0.1070, -3.6438],\n",
      "        [ 0.3337, -2.1812],\n",
      "        [ 0.7964, -0.4587],\n",
      "        [ 1.1514,  1.1495]], grad_fn=<AddmmBackward>)\n",
      "epoch: 125 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9221, -2.0108],\n",
      "        [-1.6475, -0.4558],\n",
      "        [-1.2013,  1.3637],\n",
      "        [-0.7261,  2.9894],\n",
      "        [-0.4236,  4.0589],\n",
      "        [-1.5237, -2.8162],\n",
      "        [-1.2697, -1.2964],\n",
      "        [-0.8455,  0.4995],\n",
      "        [-0.3628,  2.2843],\n",
      "        [-0.0686,  3.4911],\n",
      "        [-1.1088, -3.5819],\n",
      "        [-0.8217, -2.1632],\n",
      "        [-0.4181, -0.4288],\n",
      "        [ 0.0559,  1.4342],\n",
      "        [ 0.3396,  2.8052],\n",
      "        [-0.7643, -4.2704],\n",
      "        [-0.4225, -2.9570],\n",
      "        [ 0.0064, -1.3555],\n",
      "        [ 0.4760,  0.4723],\n",
      "        [ 0.7744,  2.0027],\n",
      "        [-0.4912, -4.8650],\n",
      "        [-0.1064, -3.6431],\n",
      "        [ 0.3341, -2.1792],\n",
      "        [ 0.7963, -0.4586],\n",
      "        [ 1.1513,  1.1464]], grad_fn=<AddmmBackward>)\n",
      "epoch: 126 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9237, -2.0096],\n",
      "        [-1.6486, -0.4558],\n",
      "        [-1.2028,  1.3614],\n",
      "        [-0.7277,  2.9889],\n",
      "        [-0.4255,  4.0601],\n",
      "        [-1.5247, -2.8152],\n",
      "        [-1.2701, -1.2958],\n",
      "        [-0.8459,  0.4979],\n",
      "        [-0.3635,  2.2821],\n",
      "        [-0.0697,  3.4907],\n",
      "        [-1.1091, -3.5815],\n",
      "        [-0.8218, -2.1621],\n",
      "        [-0.4177, -0.4292],\n",
      "        [ 0.0558,  1.4310],\n",
      "        [ 0.3393,  2.8031],\n",
      "        [-0.7641, -4.2711],\n",
      "        [-0.4222, -2.9560],\n",
      "        [ 0.0068, -1.3544],\n",
      "        [ 0.4760,  0.4700],\n",
      "        [ 0.7747,  1.9994],\n",
      "        [-0.4905, -4.8668],\n",
      "        [-0.1056, -3.6429],\n",
      "        [ 0.3347, -2.1776],\n",
      "        [ 0.7964, -0.4587],\n",
      "        [ 1.1513,  1.1434]], grad_fn=<AddmmBackward>)\n",
      "epoch: 127 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9248, -2.0088],\n",
      "        [-1.6493, -0.4560],\n",
      "        [-1.2040,  1.3593],\n",
      "        [-0.7289,  2.9886],\n",
      "        [-0.4271,  4.0619],\n",
      "        [-1.5253, -2.8147],\n",
      "        [-1.2702, -1.2955],\n",
      "        [-0.8459,  0.4964],\n",
      "        [-0.3639,  2.2802],\n",
      "        [-0.0706,  3.4907],\n",
      "        [-1.1092, -3.5817],\n",
      "        [-0.8216, -2.1614],\n",
      "        [-0.4170, -0.4296],\n",
      "        [ 0.0560,  1.4280],\n",
      "        [ 0.3392,  2.8015],\n",
      "        [-0.7636, -4.2723],\n",
      "        [-0.4216, -2.9554],\n",
      "        [ 0.0075, -1.3534],\n",
      "        [ 0.4762,  0.4680],\n",
      "        [ 0.7751,  1.9965],\n",
      "        [-0.4897, -4.8691],\n",
      "        [-0.1047, -3.6431],\n",
      "        [ 0.3354, -2.1761],\n",
      "        [ 0.7966, -0.4586],\n",
      "        [ 1.1514,  1.1409]], grad_fn=<AddmmBackward>)\n",
      "epoch: 128 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9256, -2.0083],\n",
      "        [-1.6497, -0.4561],\n",
      "        [-1.2047,  1.3576],\n",
      "        [-0.7299,  2.9889],\n",
      "        [-0.4285,  4.0643],\n",
      "        [-1.5256, -2.8146],\n",
      "        [-1.2700, -1.2952],\n",
      "        [-0.8456,  0.4951],\n",
      "        [-0.3641,  2.2788],\n",
      "        [-0.0712,  3.4914],\n",
      "        [-1.1090, -3.5823],\n",
      "        [-0.8211, -2.1608],\n",
      "        [-0.4161, -0.4298],\n",
      "        [ 0.0564,  1.4256],\n",
      "        [ 0.3392,  2.8005],\n",
      "        [-0.7631, -4.2739],\n",
      "        [-0.4209, -2.9550],\n",
      "        [ 0.0082, -1.3523],\n",
      "        [ 0.4765,  0.4665],\n",
      "        [ 0.7756,  1.9942],\n",
      "        [-0.4888, -4.8718],\n",
      "        [-0.1037, -3.6436],\n",
      "        [ 0.3361, -2.1745],\n",
      "        [ 0.7969, -0.4582],\n",
      "        [ 1.1515,  1.1389]], grad_fn=<AddmmBackward>)\n",
      "epoch: 129 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9261, -2.0079],\n",
      "        [-1.6497, -0.4560],\n",
      "        [-1.2051,  1.3563],\n",
      "        [-0.7304,  2.9898],\n",
      "        [-0.4294,  4.0673],\n",
      "        [-1.5257, -2.8146],\n",
      "        [-1.2696, -1.2948],\n",
      "        [-0.8450,  0.4943],\n",
      "        [-0.3639,  2.2780],\n",
      "        [-0.0716,  3.4927],\n",
      "        [-1.1088, -3.5830],\n",
      "        [-0.8206, -2.1602],\n",
      "        [-0.4150, -0.4296],\n",
      "        [ 0.0569,  1.4238],\n",
      "        [ 0.3394,  2.8001],\n",
      "        [-0.7626, -4.2757],\n",
      "        [-0.4203, -2.9545],\n",
      "        [ 0.0090, -1.3508],\n",
      "        [ 0.4770,  0.4655],\n",
      "        [ 0.7761,  1.9926],\n",
      "        [-0.4881, -4.8748],\n",
      "        [-0.1028, -3.6440],\n",
      "        [ 0.3368, -2.1727],\n",
      "        [ 0.7972, -0.4573],\n",
      "        [ 1.1517,  1.1376]], grad_fn=<AddmmBackward>)\n",
      "epoch: 130 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9266, -2.0075],\n",
      "        [-1.6496, -0.4557],\n",
      "        [-1.2052,  1.3555],\n",
      "        [-0.7306,  2.9911],\n",
      "        [-0.4300,  4.0708],\n",
      "        [-1.5258, -2.8145],\n",
      "        [-1.2691, -1.2942],\n",
      "        [-0.8443,  0.4940],\n",
      "        [-0.3635,  2.2778],\n",
      "        [-0.0716,  3.4946],\n",
      "        [-1.1086, -3.5837],\n",
      "        [-0.8201, -2.1593],\n",
      "        [-0.4139, -0.4290],\n",
      "        [ 0.0576,  1.4226],\n",
      "        [ 0.3398,  2.8004],\n",
      "        [-0.7623, -4.2775],\n",
      "        [-0.4198, -2.9539],\n",
      "        [ 0.0097, -1.3491],\n",
      "        [ 0.4774,  0.4652],\n",
      "        [ 0.7767,  1.9918],\n",
      "        [-0.4877, -4.8777],\n",
      "        [-0.1022, -3.6444],\n",
      "        [ 0.3373, -2.1706],\n",
      "        [ 0.7974, -0.4558],\n",
      "        [ 1.1518,  1.1371]], grad_fn=<AddmmBackward>)\n",
      "epoch: 131 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9270, -2.0071],\n",
      "        [-1.6494, -0.4553],\n",
      "        [-1.2050,  1.3550],\n",
      "        [-0.7304,  2.9928],\n",
      "        [-0.4302,  4.0747],\n",
      "        [-1.5260, -2.8145],\n",
      "        [-1.2686, -1.2935],\n",
      "        [-0.8434,  0.4940],\n",
      "        [-0.3628,  2.2779],\n",
      "        [-0.0714,  3.4969],\n",
      "        [-1.1087, -3.5845],\n",
      "        [-0.8198, -2.1584],\n",
      "        [-0.4128, -0.4281],\n",
      "        [ 0.0584,  1.4219],\n",
      "        [ 0.3404,  2.8012],\n",
      "        [-0.7623, -4.2793],\n",
      "        [-0.4195, -2.9532],\n",
      "        [ 0.0103, -1.3470],\n",
      "        [ 0.4778,  0.4654],\n",
      "        [ 0.7773,  1.9914],\n",
      "        [-0.4876, -4.8808],\n",
      "        [-0.1019, -3.6446],\n",
      "        [ 0.3375, -2.1683],\n",
      "        [ 0.7974, -0.4538],\n",
      "        [ 1.1518,  1.1370]], grad_fn=<AddmmBackward>)\n",
      "epoch: 132 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9274, -2.0069],\n",
      "        [-1.6490, -0.4549],\n",
      "        [-1.2046,  1.3546],\n",
      "        [-0.7300,  2.9947],\n",
      "        [-0.4301,  4.0789],\n",
      "        [-1.5263, -2.8146],\n",
      "        [-1.2682, -1.2928],\n",
      "        [-0.8424,  0.4941],\n",
      "        [-0.3620,  2.2782],\n",
      "        [-0.0710,  3.4994],\n",
      "        [-1.1091, -3.5853],\n",
      "        [-0.8196, -2.1574],\n",
      "        [-0.4118, -0.4270],\n",
      "        [ 0.0592,  1.4214],\n",
      "        [ 0.3411,  2.8022],\n",
      "        [-0.7627, -4.2812],\n",
      "        [-0.4196, -2.9525],\n",
      "        [ 0.0106, -1.3448],\n",
      "        [ 0.4781,  0.4658],\n",
      "        [ 0.7780,  1.9914],\n",
      "        [-0.4880, -4.8838],\n",
      "        [-0.1020, -3.6449],\n",
      "        [ 0.3375, -2.1658],\n",
      "        [ 0.7973, -0.4517],\n",
      "        [ 1.1518,  1.1374]], grad_fn=<AddmmBackward>)\n",
      "epoch: 133 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9277, -2.0069],\n",
      "        [-1.6487, -0.4547],\n",
      "        [-1.2041,  1.3540],\n",
      "        [-0.7294,  2.9964],\n",
      "        [-0.4297,  4.0830],\n",
      "        [-1.5267, -2.8150],\n",
      "        [-1.2677, -1.2923],\n",
      "        [-0.8414,  0.4940],\n",
      "        [-0.3611,  2.2784],\n",
      "        [-0.0703,  3.5020],\n",
      "        [-1.1096, -3.5863],\n",
      "        [-0.8196, -2.1566],\n",
      "        [-0.4109, -0.4261],\n",
      "        [ 0.0600,  1.4208],\n",
      "        [ 0.3418,  2.8033],\n",
      "        [-0.7634, -4.2833],\n",
      "        [-0.4199, -2.9519],\n",
      "        [ 0.0108, -1.3427],\n",
      "        [ 0.4783,  0.4662],\n",
      "        [ 0.7786,  1.9914],\n",
      "        [-0.4888, -4.8871],\n",
      "        [-0.1024, -3.6453],\n",
      "        [ 0.3371, -2.1634],\n",
      "        [ 0.7970, -0.4496],\n",
      "        [ 1.1517,  1.1378]], grad_fn=<AddmmBackward>)\n",
      "epoch: 134 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9280, -2.0072],\n",
      "        [-1.6482, -0.4549],\n",
      "        [-1.2036,  1.3530],\n",
      "        [-0.7287,  2.9979],\n",
      "        [-0.4292,  4.0869],\n",
      "        [-1.5270, -2.8156],\n",
      "        [-1.2673, -1.2922],\n",
      "        [-0.8404,  0.4936],\n",
      "        [-0.3602,  2.2784],\n",
      "        [-0.0696,  3.5044],\n",
      "        [-1.1102, -3.5876],\n",
      "        [-0.8196, -2.1561],\n",
      "        [-0.4100, -0.4255],\n",
      "        [ 0.0607,  1.4200],\n",
      "        [ 0.3426,  2.8042],\n",
      "        [-0.7642, -4.2854],\n",
      "        [-0.4203, -2.9515],\n",
      "        [ 0.0108, -1.3409],\n",
      "        [ 0.4784,  0.4664],\n",
      "        [ 0.7792,  1.9913],\n",
      "        [-0.4897, -4.8904],\n",
      "        [-0.1030, -3.6458],\n",
      "        [ 0.3366, -2.1612],\n",
      "        [ 0.7965, -0.4477],\n",
      "        [ 1.1514,  1.1380]], grad_fn=<AddmmBackward>)\n",
      "epoch: 135 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9283, -2.0077],\n",
      "        [-1.6477, -0.4554],\n",
      "        [-1.2030,  1.3516],\n",
      "        [-0.7281,  2.9990],\n",
      "        [-0.4287,  4.0906],\n",
      "        [-1.5273, -2.8163],\n",
      "        [-1.2669, -1.2922],\n",
      "        [-0.8395,  0.4928],\n",
      "        [-0.3593,  2.2780],\n",
      "        [-0.0689,  3.5064],\n",
      "        [-1.1108, -3.5889],\n",
      "        [-0.8197, -2.1557],\n",
      "        [-0.4092, -0.4252],\n",
      "        [ 0.0614,  1.4189],\n",
      "        [ 0.3433,  2.8048],\n",
      "        [-0.7650, -4.2877],\n",
      "        [-0.4208, -2.9513],\n",
      "        [ 0.0107, -1.3393],\n",
      "        [ 0.4784,  0.4663],\n",
      "        [ 0.7797,  1.9909],\n",
      "        [-0.4907, -4.8938],\n",
      "        [-0.1037, -3.6464],\n",
      "        [ 0.3360, -2.1591],\n",
      "        [ 0.7959, -0.4460],\n",
      "        [ 1.1510,  1.1381]], grad_fn=<AddmmBackward>)\n",
      "epoch: 136 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9283, -2.0083],\n",
      "        [-1.6472, -0.4560],\n",
      "        [-1.2025,  1.3499],\n",
      "        [-0.7275,  2.9997],\n",
      "        [-0.4283,  4.0938],\n",
      "        [-1.5275, -2.8171],\n",
      "        [-1.2663, -1.2924],\n",
      "        [-0.8386,  0.4917],\n",
      "        [-0.3585,  2.2772],\n",
      "        [-0.0684,  3.5082],\n",
      "        [-1.1112, -3.5902],\n",
      "        [-0.8197, -2.1554],\n",
      "        [-0.4085, -0.4251],\n",
      "        [ 0.0619,  1.4174],\n",
      "        [ 0.3439,  2.8051],\n",
      "        [-0.7657, -4.2898],\n",
      "        [-0.4212, -2.9511],\n",
      "        [ 0.0106, -1.3379],\n",
      "        [ 0.4782,  0.4659],\n",
      "        [ 0.7800,  1.9902],\n",
      "        [-0.4916, -4.8971],\n",
      "        [-0.1044, -3.6470],\n",
      "        [ 0.3353, -2.1572],\n",
      "        [ 0.7952, -0.4446],\n",
      "        [ 1.1505,  1.1378]], grad_fn=<AddmmBackward>)\n",
      "epoch: 137 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9283, -2.0087],\n",
      "        [-1.6466, -0.4566],\n",
      "        [-1.2021,  1.3480],\n",
      "        [-0.7271,  3.0002],\n",
      "        [-0.4281,  4.0968],\n",
      "        [-1.5275, -2.8175],\n",
      "        [-1.2658, -1.2925],\n",
      "        [-0.8378,  0.4906],\n",
      "        [-0.3580,  2.2761],\n",
      "        [-0.0680,  3.5096],\n",
      "        [-1.1115, -3.5912],\n",
      "        [-0.8197, -2.1549],\n",
      "        [-0.4079, -0.4250],\n",
      "        [ 0.0622,  1.4157],\n",
      "        [ 0.3443,  2.8050],\n",
      "        [-0.7662, -4.2916],\n",
      "        [-0.4215, -2.9506],\n",
      "        [ 0.0104, -1.3364],\n",
      "        [ 0.4779,  0.4653],\n",
      "        [ 0.7801,  1.9892],\n",
      "        [-0.4922, -4.9000],\n",
      "        [-0.1049, -3.6474],\n",
      "        [ 0.3346, -2.1552],\n",
      "        [ 0.7944, -0.4433],\n",
      "        [ 1.1499,  1.1373]], grad_fn=<AddmmBackward>)\n",
      "epoch: 138 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9281, -2.0086],\n",
      "        [-1.6461, -0.4570],\n",
      "        [-1.2018,  1.3461],\n",
      "        [-0.7270,  3.0004],\n",
      "        [-0.4282,  4.0994],\n",
      "        [-1.5274, -2.8175],\n",
      "        [-1.2652, -1.2923],\n",
      "        [-0.8371,  0.4895],\n",
      "        [-0.3576,  2.2748],\n",
      "        [-0.0679,  3.5107],\n",
      "        [-1.1116, -3.5917],\n",
      "        [-0.8196, -2.1541],\n",
      "        [-0.4073, -0.4248],\n",
      "        [ 0.0624,  1.4139],\n",
      "        [ 0.3445,  2.8047],\n",
      "        [-0.7665, -4.2930],\n",
      "        [-0.4218, -2.9499],\n",
      "        [ 0.0103, -1.3348],\n",
      "        [ 0.4775,  0.4646],\n",
      "        [ 0.7801,  1.9880],\n",
      "        [-0.4925, -4.9025],\n",
      "        [-0.1053, -3.6474],\n",
      "        [ 0.3340, -2.1530],\n",
      "        [ 0.7935, -0.4421],\n",
      "        [ 1.1490,  1.1365]], grad_fn=<AddmmBackward>)\n",
      "epoch: 139 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9279, -2.0081],\n",
      "        [-1.6455, -0.4570],\n",
      "        [-1.2017,  1.3443],\n",
      "        [-0.7271,  3.0004],\n",
      "        [-0.4287,  4.1018],\n",
      "        [-1.5272, -2.8170],\n",
      "        [-1.2646, -1.2917],\n",
      "        [-0.8365,  0.4886],\n",
      "        [-0.3574,  2.2735],\n",
      "        [-0.0681,  3.5116],\n",
      "        [-1.1115, -3.5917],\n",
      "        [-0.8194, -2.1529],\n",
      "        [-0.4067, -0.4245],\n",
      "        [ 0.0624,  1.4120],\n",
      "        [ 0.3444,  2.8042],\n",
      "        [-0.7666, -4.2938],\n",
      "        [-0.4218, -2.9488],\n",
      "        [ 0.0102, -1.3331],\n",
      "        [ 0.4769,  0.4639],\n",
      "        [ 0.7799,  1.9866],\n",
      "        [-0.4926, -4.9044],\n",
      "        [-0.1054, -3.6471],\n",
      "        [ 0.3335, -2.1507],\n",
      "        [ 0.7926, -0.4409],\n",
      "        [ 1.1481,  1.1356]], grad_fn=<AddmmBackward>)\n",
      "epoch: 140 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9276, -2.0071],\n",
      "        [-1.6450, -0.4568],\n",
      "        [-1.2017,  1.3426],\n",
      "        [-0.7274,  3.0004],\n",
      "        [-0.4293,  4.1040],\n",
      "        [-1.5270, -2.8160],\n",
      "        [-1.2640, -1.2909],\n",
      "        [-0.8360,  0.4877],\n",
      "        [-0.3574,  2.2720],\n",
      "        [-0.0685,  3.5123],\n",
      "        [-1.1114, -3.5913],\n",
      "        [-0.8192, -2.1515],\n",
      "        [-0.4063, -0.4241],\n",
      "        [ 0.0623,  1.4100],\n",
      "        [ 0.3442,  2.8035],\n",
      "        [-0.7664, -4.2943],\n",
      "        [-0.4218, -2.9474],\n",
      "        [ 0.0101, -1.3312],\n",
      "        [ 0.4763,  0.4631],\n",
      "        [ 0.7795,  1.9850],\n",
      "        [-0.4924, -4.9060],\n",
      "        [-0.1054, -3.6465],\n",
      "        [ 0.3331, -2.1482],\n",
      "        [ 0.7917, -0.4397],\n",
      "        [ 1.1471,  1.1345]], grad_fn=<AddmmBackward>)\n",
      "epoch: 141 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9274, -2.0059],\n",
      "        [-1.6446, -0.4564],\n",
      "        [-1.2018,  1.3408],\n",
      "        [-0.7279,  3.0002],\n",
      "        [-0.4301,  4.1060],\n",
      "        [-1.5268, -2.8148],\n",
      "        [-1.2634, -1.2899],\n",
      "        [-0.8356,  0.4869],\n",
      "        [-0.3576,  2.2703],\n",
      "        [-0.0690,  3.5128],\n",
      "        [-1.1111, -3.5907],\n",
      "        [-0.8190, -2.1499],\n",
      "        [-0.4058, -0.4237],\n",
      "        [ 0.0620,  1.4079],\n",
      "        [ 0.3439,  2.8026],\n",
      "        [-0.7662, -4.2946],\n",
      "        [-0.4217, -2.9460],\n",
      "        [ 0.0100, -1.3294],\n",
      "        [ 0.4757,  0.4622],\n",
      "        [ 0.7791,  1.9832],\n",
      "        [-0.4920, -4.9075],\n",
      "        [-0.1053, -3.6459],\n",
      "        [ 0.3327, -2.1458],\n",
      "        [ 0.7908, -0.4388],\n",
      "        [ 1.1461,  1.1331]], grad_fn=<AddmmBackward>)\n",
      "epoch: 142 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9273, -2.0047],\n",
      "        [-1.6442, -0.4561],\n",
      "        [-1.2020,  1.3390],\n",
      "        [-0.7284,  2.9999],\n",
      "        [-0.4310,  4.1080],\n",
      "        [-1.5265, -2.8136],\n",
      "        [-1.2629, -1.2890],\n",
      "        [-0.8353,  0.4859],\n",
      "        [-0.3578,  2.2686],\n",
      "        [-0.0696,  3.5132],\n",
      "        [-1.1109, -3.5901],\n",
      "        [-0.8188, -2.1484],\n",
      "        [-0.4055, -0.4234],\n",
      "        [ 0.0618,  1.4057],\n",
      "        [ 0.3435,  2.8015],\n",
      "        [-0.7659, -4.2949],\n",
      "        [-0.4216, -2.9446],\n",
      "        [ 0.0099, -1.3277],\n",
      "        [ 0.4750,  0.4612],\n",
      "        [ 0.7787,  1.9812],\n",
      "        [-0.4916, -4.9090],\n",
      "        [-0.1051, -3.6453],\n",
      "        [ 0.3324, -2.1435],\n",
      "        [ 0.7899, -0.4380],\n",
      "        [ 1.1451,  1.1316]], grad_fn=<AddmmBackward>)\n",
      "epoch: 143 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9272, -2.0037],\n",
      "        [-1.6440, -0.4559],\n",
      "        [-1.2023,  1.3371],\n",
      "        [-0.7290,  2.9996],\n",
      "        [-0.4319,  4.1099],\n",
      "        [-1.5264, -2.8126],\n",
      "        [-1.2625, -1.2882],\n",
      "        [-0.8350,  0.4848],\n",
      "        [-0.3580,  2.2667],\n",
      "        [-0.0701,  3.5135],\n",
      "        [-1.1107, -3.5897],\n",
      "        [-0.8186, -2.1471],\n",
      "        [-0.4051, -0.4232],\n",
      "        [ 0.0615,  1.4033],\n",
      "        [ 0.3433,  2.8004],\n",
      "        [-0.7656, -4.2954],\n",
      "        [-0.4215, -2.9435],\n",
      "        [ 0.0098, -1.3263],\n",
      "        [ 0.4744,  0.4599],\n",
      "        [ 0.7784,  1.9791],\n",
      "        [-0.4912, -4.9108],\n",
      "        [-0.1049, -3.6450],\n",
      "        [ 0.3321, -2.1416],\n",
      "        [ 0.7891, -0.4375],\n",
      "        [ 1.1442,  1.1299]], grad_fn=<AddmmBackward>)\n",
      "epoch: 144 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9273, -2.0027],\n",
      "        [-1.6438, -0.4557],\n",
      "        [-1.2026,  1.3351],\n",
      "        [-0.7296,  2.9992],\n",
      "        [-0.4326,  4.1118],\n",
      "        [-1.5264, -2.8117],\n",
      "        [-1.2621, -1.2876],\n",
      "        [-0.8348,  0.4837],\n",
      "        [-0.3582,  2.2647],\n",
      "        [-0.0705,  3.5139],\n",
      "        [-1.1107, -3.5895],\n",
      "        [-0.8185, -2.1460],\n",
      "        [-0.4048, -0.4233],\n",
      "        [ 0.0613,  1.4009],\n",
      "        [ 0.3431,  2.7992],\n",
      "        [-0.7655, -4.2962],\n",
      "        [-0.4215, -2.9426],\n",
      "        [ 0.0097, -1.3250],\n",
      "        [ 0.4739,  0.4585],\n",
      "        [ 0.7782,  1.9770],\n",
      "        [-0.4909, -4.9128],\n",
      "        [-0.1048, -3.6450],\n",
      "        [ 0.3318, -2.1398],\n",
      "        [ 0.7883, -0.4371],\n",
      "        [ 1.1435,  1.1281]], grad_fn=<AddmmBackward>)\n",
      "epoch: 145 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9275, -2.0019],\n",
      "        [-1.6437, -0.4557],\n",
      "        [-1.2029,  1.3332],\n",
      "        [-0.7301,  2.9989],\n",
      "        [-0.4333,  4.1139],\n",
      "        [-1.5266, -2.8110],\n",
      "        [-1.2619, -1.2871],\n",
      "        [-0.8346,  0.4825],\n",
      "        [-0.3583,  2.2629],\n",
      "        [-0.0708,  3.5144],\n",
      "        [-1.1107, -3.5896],\n",
      "        [-0.8185, -2.1450],\n",
      "        [-0.4045, -0.4233],\n",
      "        [ 0.0611,  1.3985],\n",
      "        [ 0.3431,  2.7981],\n",
      "        [-0.7654, -4.2972],\n",
      "        [-0.4215, -2.9418],\n",
      "        [ 0.0096, -1.3239],\n",
      "        [ 0.4734,  0.4572],\n",
      "        [ 0.7782,  1.9749],\n",
      "        [-0.4908, -4.9151],\n",
      "        [-0.1047, -3.6451],\n",
      "        [ 0.3316, -2.1382],\n",
      "        [ 0.7877, -0.4368],\n",
      "        [ 1.1429,  1.1263]], grad_fn=<AddmmBackward>)\n",
      "epoch: 146 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9278, -2.0011],\n",
      "        [-1.6437, -0.4555],\n",
      "        [-1.2032,  1.3314],\n",
      "        [-0.7305,  2.9988],\n",
      "        [-0.4337,  4.1162],\n",
      "        [-1.5268, -2.8103],\n",
      "        [-1.2617, -1.2865],\n",
      "        [-0.8344,  0.4815],\n",
      "        [-0.3583,  2.2612],\n",
      "        [-0.0710,  3.5151],\n",
      "        [-1.1109, -3.5897],\n",
      "        [-0.8186, -2.1440],\n",
      "        [-0.4042, -0.4233],\n",
      "        [ 0.0610,  1.3963],\n",
      "        [ 0.3432,  2.7973],\n",
      "        [-0.7655, -4.2984],\n",
      "        [-0.4216, -2.9412],\n",
      "        [ 0.0095, -1.3227],\n",
      "        [ 0.4730,  0.4560],\n",
      "        [ 0.7783,  1.9731],\n",
      "        [-0.4907, -4.9175],\n",
      "        [-0.1048, -3.6454],\n",
      "        [ 0.3313, -2.1366],\n",
      "        [ 0.7871, -0.4364],\n",
      "        [ 1.1425,  1.1248]], grad_fn=<AddmmBackward>)\n",
      "epoch: 147 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9282, -2.0003],\n",
      "        [-1.6437, -0.4553],\n",
      "        [-1.2035,  1.3299],\n",
      "        [-0.7308,  2.9989],\n",
      "        [-0.4341,  4.1188],\n",
      "        [-1.5272, -2.8096],\n",
      "        [-1.2616, -1.2858],\n",
      "        [-0.8341,  0.4807],\n",
      "        [-0.3582,  2.2597],\n",
      "        [-0.0709,  3.5160],\n",
      "        [-1.1112, -3.5898],\n",
      "        [-0.8186, -2.1430],\n",
      "        [-0.4038, -0.4231],\n",
      "        [ 0.0611,  1.3944],\n",
      "        [ 0.3435,  2.7967],\n",
      "        [-0.7657, -4.2996],\n",
      "        [-0.4217, -2.9405],\n",
      "        [ 0.0095, -1.3213],\n",
      "        [ 0.4728,  0.4550],\n",
      "        [ 0.7785,  1.9715],\n",
      "        [-0.4908, -4.9201],\n",
      "        [-0.1048, -3.6457],\n",
      "        [ 0.3310, -2.1350],\n",
      "        [ 0.7867, -0.4358],\n",
      "        [ 1.1422,  1.1235]], grad_fn=<AddmmBackward>)\n",
      "epoch: 148 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9287, -1.9995],\n",
      "        [-1.6437, -0.4548],\n",
      "        [-1.2036,  1.3286],\n",
      "        [-0.7309,  2.9993],\n",
      "        [-0.4342,  4.1216],\n",
      "        [-1.5276, -2.8089],\n",
      "        [-1.2614, -1.2850],\n",
      "        [-0.8338,  0.4801],\n",
      "        [-0.3580,  2.2585],\n",
      "        [-0.0708,  3.5173],\n",
      "        [-1.1115, -3.5900],\n",
      "        [-0.8187, -2.1419],\n",
      "        [-0.4034, -0.4226],\n",
      "        [ 0.0612,  1.3927],\n",
      "        [ 0.3439,  2.7964],\n",
      "        [-0.7659, -4.3009],\n",
      "        [-0.4218, -2.9397],\n",
      "        [ 0.0095, -1.3198],\n",
      "        [ 0.4726,  0.4544],\n",
      "        [ 0.7789,  1.9703],\n",
      "        [-0.4909, -4.9227],\n",
      "        [-0.1049, -3.6459],\n",
      "        [ 0.3308, -2.1332],\n",
      "        [ 0.7863, -0.4349],\n",
      "        [ 1.1420,  1.1225]], grad_fn=<AddmmBackward>)\n",
      "epoch: 149 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9291, -1.9987],\n",
      "        [-1.6437, -0.4544],\n",
      "        [-1.2036,  1.3274],\n",
      "        [-0.7310,  2.9999],\n",
      "        [-0.4343,  4.1247],\n",
      "        [-1.5280, -2.8083],\n",
      "        [-1.2612, -1.2842],\n",
      "        [-0.8333,  0.4797],\n",
      "        [-0.3577,  2.2576],\n",
      "        [-0.0705,  3.5187],\n",
      "        [-1.1118, -3.5902],\n",
      "        [-0.8188, -2.1407],\n",
      "        [-0.4029, -0.4220],\n",
      "        [ 0.0614,  1.3914],\n",
      "        [ 0.3444,  2.7963],\n",
      "        [-0.7661, -4.3022],\n",
      "        [-0.4219, -2.9390],\n",
      "        [ 0.0096, -1.3182],\n",
      "        [ 0.4726,  0.4540],\n",
      "        [ 0.7793,  1.9693],\n",
      "        [-0.4910, -4.9253],\n",
      "        [-0.1049, -3.6462],\n",
      "        [ 0.3307, -2.1313],\n",
      "        [ 0.7861, -0.4338],\n",
      "        [ 1.1420,  1.1219]], grad_fn=<AddmmBackward>)\n",
      "epoch: 150 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9294, -1.9980],\n",
      "        [-1.6436, -0.4540],\n",
      "        [-1.2036,  1.3263],\n",
      "        [-0.7310,  3.0005],\n",
      "        [-0.4343,  4.1278],\n",
      "        [-1.5282, -2.8078],\n",
      "        [-1.2609, -1.2834],\n",
      "        [-0.8328,  0.4794],\n",
      "        [-0.3574,  2.2567],\n",
      "        [-0.0702,  3.5203],\n",
      "        [-1.1120, -3.5906],\n",
      "        [-0.8187, -2.1396],\n",
      "        [-0.4024, -0.4214],\n",
      "        [ 0.0618,  1.3901],\n",
      "        [ 0.3450,  2.7964],\n",
      "        [-0.7663, -4.3036],\n",
      "        [-0.4219, -2.9383],\n",
      "        [ 0.0098, -1.3166],\n",
      "        [ 0.4726,  0.4537],\n",
      "        [ 0.7799,  1.9685],\n",
      "        [-0.4910, -4.9281],\n",
      "        [-0.1048, -3.6465],\n",
      "        [ 0.3307, -2.1294],\n",
      "        [ 0.7859, -0.4327],\n",
      "        [ 1.1420,  1.1214]], grad_fn=<AddmmBackward>)\n",
      "epoch: 151 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9296, -1.9975],\n",
      "        [-1.6434, -0.4537],\n",
      "        [-1.2035,  1.3251],\n",
      "        [-0.7309,  3.0011],\n",
      "        [-0.4343,  4.1310],\n",
      "        [-1.5284, -2.8075],\n",
      "        [-1.2606, -1.2828],\n",
      "        [-0.8323,  0.4789],\n",
      "        [-0.3569,  2.2557],\n",
      "        [-0.0698,  3.5219],\n",
      "        [-1.1122, -3.5911],\n",
      "        [-0.8186, -2.1386],\n",
      "        [-0.4017, -0.4209],\n",
      "        [ 0.0621,  1.3889],\n",
      "        [ 0.3456,  2.7965],\n",
      "        [-0.7663, -4.3052],\n",
      "        [-0.4219, -2.9377],\n",
      "        [ 0.0100, -1.3149],\n",
      "        [ 0.4727,  0.4535],\n",
      "        [ 0.7804,  1.9678],\n",
      "        [-0.4909, -4.9310],\n",
      "        [-0.1047, -3.6469],\n",
      "        [ 0.3307, -2.1276],\n",
      "        [ 0.7859, -0.4314],\n",
      "        [ 1.1421,  1.1210]], grad_fn=<AddmmBackward>)\n",
      "epoch: 152 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9298, -1.9973],\n",
      "        [-1.6432, -0.4537],\n",
      "        [-1.2034,  1.3238],\n",
      "        [-0.7309,  3.0015],\n",
      "        [-0.4342,  4.1341],\n",
      "        [-1.5285, -2.8073],\n",
      "        [-1.2602, -1.2823],\n",
      "        [-0.8317,  0.4784],\n",
      "        [-0.3565,  2.2547],\n",
      "        [-0.0694,  3.5235],\n",
      "        [-1.1122, -3.5917],\n",
      "        [-0.8184, -2.1378],\n",
      "        [-0.4011, -0.4204],\n",
      "        [ 0.0625,  1.3876],\n",
      "        [ 0.3463,  2.7967],\n",
      "        [-0.7663, -4.3069],\n",
      "        [-0.4217, -2.9372],\n",
      "        [ 0.0103, -1.3134],\n",
      "        [ 0.4728,  0.4533],\n",
      "        [ 0.7810,  1.9671],\n",
      "        [-0.4908, -4.9340],\n",
      "        [-0.1045, -3.6473],\n",
      "        [ 0.3308, -2.1258],\n",
      "        [ 0.7858, -0.4302],\n",
      "        [ 1.1422,  1.1207]], grad_fn=<AddmmBackward>)\n",
      "epoch: 153 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9300, -1.9971],\n",
      "        [-1.6430, -0.4538],\n",
      "        [-1.2034,  1.3222],\n",
      "        [-0.7308,  3.0018],\n",
      "        [-0.4342,  4.1371],\n",
      "        [-1.5286, -2.8073],\n",
      "        [-1.2598, -1.2819],\n",
      "        [-0.8312,  0.4777],\n",
      "        [-0.3561,  2.2535],\n",
      "        [-0.0691,  3.5250],\n",
      "        [-1.1123, -3.5924],\n",
      "        [-0.8182, -2.1370],\n",
      "        [-0.4005, -0.4200],\n",
      "        [ 0.0628,  1.3862],\n",
      "        [ 0.3469,  2.7967],\n",
      "        [-0.7663, -4.3086],\n",
      "        [-0.4216, -2.9368],\n",
      "        [ 0.0105, -1.3119],\n",
      "        [ 0.4728,  0.4530],\n",
      "        [ 0.7815,  1.9664],\n",
      "        [-0.4907, -4.9370],\n",
      "        [-0.1043, -3.6478],\n",
      "        [ 0.3308, -2.1240],\n",
      "        [ 0.7857, -0.4290],\n",
      "        [ 1.1422,  1.1203]], grad_fn=<AddmmBackward>)\n",
      "epoch: 154 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9301, -1.9970],\n",
      "        [-1.6428, -0.4539],\n",
      "        [-1.2034,  1.3206],\n",
      "        [-0.7309,  3.0020],\n",
      "        [-0.4342,  4.1401],\n",
      "        [-1.5287, -2.8072],\n",
      "        [-1.2594, -1.2816],\n",
      "        [-0.8307,  0.4769],\n",
      "        [-0.3558,  2.2523],\n",
      "        [-0.0688,  3.5264],\n",
      "        [-1.1124, -3.5931],\n",
      "        [-0.8181, -2.1362],\n",
      "        [-0.4000, -0.4196],\n",
      "        [ 0.0630,  1.3848],\n",
      "        [ 0.3474,  2.7967],\n",
      "        [-0.7663, -4.3103],\n",
      "        [-0.4216, -2.9363],\n",
      "        [ 0.0107, -1.3104],\n",
      "        [ 0.4728,  0.4527],\n",
      "        [ 0.7820,  1.9657],\n",
      "        [-0.4906, -4.9399],\n",
      "        [-0.1042, -3.6482],\n",
      "        [ 0.3308, -2.1222],\n",
      "        [ 0.7856, -0.4278],\n",
      "        [ 1.1422,  1.1200]], grad_fn=<AddmmBackward>)\n",
      "epoch: 155 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9304, -1.9968],\n",
      "        [-1.6427, -0.4540],\n",
      "        [-1.2035,  1.3189],\n",
      "        [-0.7310,  3.0021],\n",
      "        [-0.4344,  4.1428],\n",
      "        [-1.5289, -2.8071],\n",
      "        [-1.2592, -1.2812],\n",
      "        [-0.8303,  0.4762],\n",
      "        [-0.3556,  2.2509],\n",
      "        [-0.0686,  3.5277],\n",
      "        [-1.1125, -3.5936],\n",
      "        [-0.8181, -2.1353],\n",
      "        [-0.3996, -0.4193],\n",
      "        [ 0.0631,  1.3834],\n",
      "        [ 0.3479,  2.7966],\n",
      "        [-0.7664, -4.3118],\n",
      "        [-0.4216, -2.9356],\n",
      "        [ 0.0108, -1.3089],\n",
      "        [ 0.4727,  0.4524],\n",
      "        [ 0.7823,  1.9649],\n",
      "        [-0.4905, -4.9426],\n",
      "        [-0.1041, -3.6485],\n",
      "        [ 0.3308, -2.1203],\n",
      "        [ 0.7854, -0.4266],\n",
      "        [ 1.1422,  1.1196]], grad_fn=<AddmmBackward>)\n",
      "epoch: 156 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9307, -1.9965],\n",
      "        [-1.6427, -0.4541],\n",
      "        [-1.2037,  1.3172],\n",
      "        [-0.7313,  3.0020],\n",
      "        [-0.4346,  4.1455],\n",
      "        [-1.5291, -2.8067],\n",
      "        [-1.2590, -1.2806],\n",
      "        [-0.8301,  0.4754],\n",
      "        [-0.3555,  2.2494],\n",
      "        [-0.0685,  3.5289],\n",
      "        [-1.1127, -3.5939],\n",
      "        [-0.8181, -2.1343],\n",
      "        [-0.3992, -0.4188],\n",
      "        [ 0.0631,  1.3819],\n",
      "        [ 0.3482,  2.7964],\n",
      "        [-0.7665, -4.3130],\n",
      "        [-0.4217, -2.9348],\n",
      "        [ 0.0108, -1.3072],\n",
      "        [ 0.4725,  0.4521],\n",
      "        [ 0.7826,  1.9641],\n",
      "        [-0.4905, -4.9451],\n",
      "        [-0.1041, -3.6486],\n",
      "        [ 0.3307, -2.1183],\n",
      "        [ 0.7851, -0.4254],\n",
      "        [ 1.1420,  1.1192]], grad_fn=<AddmmBackward>)\n",
      "epoch: 157 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9310, -1.9960],\n",
      "        [-1.6428, -0.4541],\n",
      "        [-1.2039,  1.3155],\n",
      "        [-0.7316,  3.0018],\n",
      "        [-0.4349,  4.1480],\n",
      "        [-1.5294, -2.8061],\n",
      "        [-1.2588, -1.2800],\n",
      "        [-0.8299,  0.4747],\n",
      "        [-0.3555,  2.2478],\n",
      "        [-0.0685,  3.5300],\n",
      "        [-1.1130, -3.5939],\n",
      "        [-0.8183, -2.1331],\n",
      "        [-0.3990, -0.4183],\n",
      "        [ 0.0630,  1.3804],\n",
      "        [ 0.3485,  2.7961],\n",
      "        [-0.7667, -4.3141],\n",
      "        [-0.4218, -2.9339],\n",
      "        [ 0.0108, -1.3055],\n",
      "        [ 0.4722,  0.4518],\n",
      "        [ 0.7828,  1.9632],\n",
      "        [-0.4905, -4.9475],\n",
      "        [-0.1041, -3.6486],\n",
      "        [ 0.3305, -2.1163],\n",
      "        [ 0.7848, -0.4242],\n",
      "        [ 1.1418,  1.1188]], grad_fn=<AddmmBackward>)\n",
      "epoch: 158 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9313, -1.9954],\n",
      "        [-1.6428, -0.4540],\n",
      "        [-1.2042,  1.3137],\n",
      "        [-0.7320,  3.0015],\n",
      "        [-0.4352,  4.1504],\n",
      "        [-1.5297, -2.8055],\n",
      "        [-1.2587, -1.2793],\n",
      "        [-0.8297,  0.4740],\n",
      "        [-0.3555,  2.2461],\n",
      "        [-0.0685,  3.5309],\n",
      "        [-1.1133, -3.5939],\n",
      "        [-0.8184, -2.1319],\n",
      "        [-0.3988, -0.4179],\n",
      "        [ 0.0629,  1.3788],\n",
      "        [ 0.3487,  2.7957],\n",
      "        [-0.7668, -4.3150],\n",
      "        [-0.4219, -2.9329],\n",
      "        [ 0.0107, -1.3039],\n",
      "        [ 0.4719,  0.4514],\n",
      "        [ 0.7829,  1.9621],\n",
      "        [-0.4904, -4.9496],\n",
      "        [-0.1041, -3.6485],\n",
      "        [ 0.3303, -2.1143],\n",
      "        [ 0.7844, -0.4231],\n",
      "        [ 1.1415,  1.1182]], grad_fn=<AddmmBackward>)\n",
      "epoch: 159 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9315, -1.9948],\n",
      "        [-1.6428, -0.4540],\n",
      "        [-1.2045,  1.3119],\n",
      "        [-0.7324,  3.0010],\n",
      "        [-0.4356,  4.1526],\n",
      "        [-1.5299, -2.8048],\n",
      "        [-1.2585, -1.2786],\n",
      "        [-0.8296,  0.4731],\n",
      "        [-0.3556,  2.2443],\n",
      "        [-0.0686,  3.5317],\n",
      "        [-1.1134, -3.5938],\n",
      "        [-0.8184, -2.1307],\n",
      "        [-0.3987, -0.4175],\n",
      "        [ 0.0627,  1.3770],\n",
      "        [ 0.3489,  2.7952],\n",
      "        [-0.7669, -4.3159],\n",
      "        [-0.4220, -2.9319],\n",
      "        [ 0.0106, -1.3023],\n",
      "        [ 0.4715,  0.4509],\n",
      "        [ 0.7830,  1.9610],\n",
      "        [-0.4903, -4.9518],\n",
      "        [-0.1040, -3.6484],\n",
      "        [ 0.3301, -2.1123],\n",
      "        [ 0.7840, -0.4220],\n",
      "        [ 1.1412,  1.1176]], grad_fn=<AddmmBackward>)\n",
      "epoch: 160 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9316, -1.9942],\n",
      "        [-1.6427, -0.4540],\n",
      "        [-1.2048,  1.3100],\n",
      "        [-0.7329,  3.0005],\n",
      "        [-0.4360,  4.1548],\n",
      "        [-1.5300, -2.8041],\n",
      "        [-1.2583, -1.2780],\n",
      "        [-0.8294,  0.4723],\n",
      "        [-0.3557,  2.2423],\n",
      "        [-0.0687,  3.5324],\n",
      "        [-1.1135, -3.5937],\n",
      "        [-0.8184, -2.1295],\n",
      "        [-0.3984, -0.4171],\n",
      "        [ 0.0625,  1.3752],\n",
      "        [ 0.3491,  2.7945],\n",
      "        [-0.7668, -4.3168],\n",
      "        [-0.4220, -2.9310],\n",
      "        [ 0.0106, -1.3007],\n",
      "        [ 0.4711,  0.4503],\n",
      "        [ 0.7831,  1.9597],\n",
      "        [-0.4901, -4.9540],\n",
      "        [-0.1039, -3.6483],\n",
      "        [ 0.3300, -2.1104],\n",
      "        [ 0.7836, -0.4212],\n",
      "        [ 1.1409,  1.1168]], grad_fn=<AddmmBackward>)\n",
      "epoch: 161 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9317, -1.9936],\n",
      "        [-1.6425, -0.4540],\n",
      "        [-1.2049,  1.3081],\n",
      "        [-0.7332,  2.9999],\n",
      "        [-0.4364,  4.1569],\n",
      "        [-1.5300, -2.8035],\n",
      "        [-1.2580, -1.2773],\n",
      "        [-0.8291,  0.4713],\n",
      "        [-0.3557,  2.2403],\n",
      "        [-0.0687,  3.5331],\n",
      "        [-1.1136, -3.5937],\n",
      "        [-0.8183, -2.1284],\n",
      "        [-0.3982, -0.4169],\n",
      "        [ 0.0623,  1.3733],\n",
      "        [ 0.3493,  2.7938],\n",
      "        [-0.7667, -4.3177],\n",
      "        [-0.4220, -2.9301],\n",
      "        [ 0.0106, -1.2993],\n",
      "        [ 0.4708,  0.4496],\n",
      "        [ 0.7831,  1.9584],\n",
      "        [-0.4899, -4.9562],\n",
      "        [-0.1038, -3.6484],\n",
      "        [ 0.3299, -2.1087],\n",
      "        [ 0.7832, -0.4204],\n",
      "        [ 1.1406,  1.1159]], grad_fn=<AddmmBackward>)\n",
      "epoch: 162 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9316, -1.9929],\n",
      "        [-1.6423, -0.4540],\n",
      "        [-1.2051,  1.3063],\n",
      "        [-0.7336,  2.9993],\n",
      "        [-0.4367,  4.1591],\n",
      "        [-1.5299, -2.8028],\n",
      "        [-1.2576, -1.2767],\n",
      "        [-0.8288,  0.4705],\n",
      "        [-0.3557,  2.2382],\n",
      "        [-0.0688,  3.5338],\n",
      "        [-1.1135, -3.5936],\n",
      "        [-0.8182, -2.1273],\n",
      "        [-0.3979, -0.4166],\n",
      "        [ 0.0621,  1.3714],\n",
      "        [ 0.3495,  2.7930],\n",
      "        [-0.7666, -4.3187],\n",
      "        [-0.4220, -2.9293],\n",
      "        [ 0.0106, -1.2979],\n",
      "        [ 0.4705,  0.4489],\n",
      "        [ 0.7832,  1.9571],\n",
      "        [-0.4897, -4.9585],\n",
      "        [-0.1036, -3.6485],\n",
      "        [ 0.3298, -2.1070],\n",
      "        [ 0.7828, -0.4197],\n",
      "        [ 1.1403,  1.1149]], grad_fn=<AddmmBackward>)\n",
      "epoch: 163 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9316, -1.9922],\n",
      "        [-1.6421, -0.4538],\n",
      "        [-1.2052,  1.3046],\n",
      "        [-0.7339,  2.9989],\n",
      "        [-0.4370,  4.1614],\n",
      "        [-1.5298, -2.8022],\n",
      "        [-1.2572, -1.2760],\n",
      "        [-0.8285,  0.4697],\n",
      "        [-0.3557,  2.2363],\n",
      "        [-0.0688,  3.5346],\n",
      "        [-1.1135, -3.5936],\n",
      "        [-0.8181, -2.1261],\n",
      "        [-0.3976, -0.4163],\n",
      "        [ 0.0620,  1.3697],\n",
      "        [ 0.3498,  2.7924],\n",
      "        [-0.7665, -4.3197],\n",
      "        [-0.4219, -2.9284],\n",
      "        [ 0.0106, -1.2965],\n",
      "        [ 0.4701,  0.4483],\n",
      "        [ 0.7834,  1.9558],\n",
      "        [-0.4894, -4.9608],\n",
      "        [-0.1035, -3.6486],\n",
      "        [ 0.3297, -2.1054],\n",
      "        [ 0.7825, -0.4190],\n",
      "        [ 1.1401,  1.1140]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 164 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9316, -1.9915],\n",
      "        [-1.6419, -0.4535],\n",
      "        [-1.2052,  1.3031],\n",
      "        [-0.7342,  2.9985],\n",
      "        [-0.4373,  4.1638],\n",
      "        [-1.5298, -2.8014],\n",
      "        [-1.2569, -1.2752],\n",
      "        [-0.8282,  0.4690],\n",
      "        [-0.3556,  2.2345],\n",
      "        [-0.0687,  3.5355],\n",
      "        [-1.1136, -3.5935],\n",
      "        [-0.8180, -2.1249],\n",
      "        [-0.3973, -0.4159],\n",
      "        [ 0.0618,  1.3680],\n",
      "        [ 0.3500,  2.7918],\n",
      "        [-0.7665, -4.3207],\n",
      "        [-0.4219, -2.9276],\n",
      "        [ 0.0106, -1.2951],\n",
      "        [ 0.4698,  0.4477],\n",
      "        [ 0.7835,  1.9546],\n",
      "        [-0.4893, -4.9632],\n",
      "        [-0.1034, -3.6488],\n",
      "        [ 0.3296, -2.1037],\n",
      "        [ 0.7821, -0.4182],\n",
      "        [ 1.1398,  1.1132]], grad_fn=<AddmmBackward>)\n",
      "epoch: 165 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9316, -1.9906],\n",
      "        [-1.6416, -0.4532],\n",
      "        [-1.2053,  1.3017],\n",
      "        [-0.7344,  2.9983],\n",
      "        [-0.4374,  4.1663],\n",
      "        [-1.5298, -2.8007],\n",
      "        [-1.2565, -1.2743],\n",
      "        [-0.8279,  0.4685],\n",
      "        [-0.3556,  2.2328],\n",
      "        [-0.0686,  3.5365],\n",
      "        [-1.1137, -3.5934],\n",
      "        [-0.8180, -2.1237],\n",
      "        [-0.3971, -0.4154],\n",
      "        [ 0.0617,  1.3664],\n",
      "        [ 0.3503,  2.7914],\n",
      "        [-0.7666, -4.3218],\n",
      "        [-0.4220, -2.9267],\n",
      "        [ 0.0106, -1.2936],\n",
      "        [ 0.4695,  0.4472],\n",
      "        [ 0.7836,  1.9536],\n",
      "        [-0.4892, -4.9656],\n",
      "        [-0.1033, -3.6490],\n",
      "        [ 0.3294, -2.1021],\n",
      "        [ 0.7818, -0.4174],\n",
      "        [ 1.1396,  1.1125]], grad_fn=<AddmmBackward>)\n",
      "epoch: 166 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9316, -1.9899],\n",
      "        [-1.6414, -0.4528],\n",
      "        [-1.2053,  1.3005],\n",
      "        [-0.7346,  2.9982],\n",
      "        [-0.4376,  4.1690],\n",
      "        [-1.5299, -2.8000],\n",
      "        [-1.2562, -1.2735],\n",
      "        [-0.8276,  0.4680],\n",
      "        [-0.3555,  2.2312],\n",
      "        [-0.0685,  3.5376],\n",
      "        [-1.1138, -3.5934],\n",
      "        [-0.8180, -2.1225],\n",
      "        [-0.3969, -0.4149],\n",
      "        [ 0.0616,  1.3650],\n",
      "        [ 0.3507,  2.7910],\n",
      "        [-0.7667, -4.3229],\n",
      "        [-0.4221, -2.9259],\n",
      "        [ 0.0105, -1.2922],\n",
      "        [ 0.4692,  0.4468],\n",
      "        [ 0.7838,  1.9527],\n",
      "        [-0.4893, -4.9681],\n",
      "        [-0.1034, -3.6493],\n",
      "        [ 0.3292, -2.1005],\n",
      "        [ 0.7814, -0.4166],\n",
      "        [ 1.1394,  1.1119]], grad_fn=<AddmmBackward>)\n",
      "epoch: 167 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9317, -1.9892],\n",
      "        [-1.6412, -0.4524],\n",
      "        [-1.2053,  1.2992],\n",
      "        [-0.7347,  2.9981],\n",
      "        [-0.4377,  4.1717],\n",
      "        [-1.5300, -2.7994],\n",
      "        [-1.2559, -1.2727],\n",
      "        [-0.8273,  0.4676],\n",
      "        [-0.3554,  2.2297],\n",
      "        [-0.0683,  3.5388],\n",
      "        [-1.1141, -3.5935],\n",
      "        [-0.8180, -2.1214],\n",
      "        [-0.3966, -0.4143],\n",
      "        [ 0.0614,  1.3636],\n",
      "        [ 0.3511,  2.7908],\n",
      "        [-0.7668, -4.3241],\n",
      "        [-0.4222, -2.9252],\n",
      "        [ 0.0105, -1.2908],\n",
      "        [ 0.4689,  0.4464],\n",
      "        [ 0.7840,  1.9518],\n",
      "        [-0.4894, -4.9708],\n",
      "        [-0.1035, -3.6496],\n",
      "        [ 0.3290, -2.0990],\n",
      "        [ 0.7810, -0.4158],\n",
      "        [ 1.1392,  1.1113]], grad_fn=<AddmmBackward>)\n",
      "epoch: 168 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9317, -1.9886],\n",
      "        [-1.6410, -0.4522],\n",
      "        [-1.2053,  1.2979],\n",
      "        [-0.7349,  2.9980],\n",
      "        [-0.4377,  4.1745],\n",
      "        [-1.5301, -2.7989],\n",
      "        [-1.2556, -1.2719],\n",
      "        [-0.8269,  0.4671],\n",
      "        [-0.3553,  2.2282],\n",
      "        [-0.0681,  3.5401],\n",
      "        [-1.1143, -3.5937],\n",
      "        [-0.8180, -2.1204],\n",
      "        [-0.3964, -0.4139],\n",
      "        [ 0.0613,  1.3621],\n",
      "        [ 0.3515,  2.7906],\n",
      "        [-0.7670, -4.3255],\n",
      "        [-0.4224, -2.9246],\n",
      "        [ 0.0104, -1.2894],\n",
      "        [ 0.4686,  0.4461],\n",
      "        [ 0.7842,  1.9510],\n",
      "        [-0.4895, -4.9735],\n",
      "        [-0.1036, -3.6501],\n",
      "        [ 0.3288, -2.0976],\n",
      "        [ 0.7807, -0.4150],\n",
      "        [ 1.1391,  1.1107]], grad_fn=<AddmmBackward>)\n",
      "epoch: 169 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9317, -1.9881],\n",
      "        [-1.6408, -0.4520],\n",
      "        [-1.2053,  1.2966],\n",
      "        [-0.7350,  2.9979],\n",
      "        [-0.4378,  4.1773],\n",
      "        [-1.5301, -2.7985],\n",
      "        [-1.2553, -1.2713],\n",
      "        [-0.8266,  0.4666],\n",
      "        [-0.3552,  2.2266],\n",
      "        [-0.0679,  3.5413],\n",
      "        [-1.1145, -3.5940],\n",
      "        [-0.8180, -2.1194],\n",
      "        [-0.3962, -0.4135],\n",
      "        [ 0.0612,  1.3607],\n",
      "        [ 0.3519,  2.7903],\n",
      "        [-0.7672, -4.3269],\n",
      "        [-0.4225, -2.9240],\n",
      "        [ 0.0104, -1.2881],\n",
      "        [ 0.4683,  0.4457],\n",
      "        [ 0.7844,  1.9502],\n",
      "        [-0.4896, -4.9763],\n",
      "        [-0.1036, -3.6506],\n",
      "        [ 0.3286, -2.0961],\n",
      "        [ 0.7804, -0.4143],\n",
      "        [ 1.1390,  1.1102]], grad_fn=<AddmmBackward>)\n",
      "epoch: 170 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9317, -1.9876],\n",
      "        [-1.6405, -0.4518],\n",
      "        [-1.2053,  1.2952],\n",
      "        [-0.7351,  2.9977],\n",
      "        [-0.4378,  4.1801],\n",
      "        [-1.5301, -2.7981],\n",
      "        [-1.2550, -1.2707],\n",
      "        [-0.8262,  0.4660],\n",
      "        [-0.3551,  2.2250],\n",
      "        [-0.0677,  3.5426],\n",
      "        [-1.1146, -3.5943],\n",
      "        [-0.8180, -2.1184],\n",
      "        [-0.3959, -0.4131],\n",
      "        [ 0.0611,  1.3593],\n",
      "        [ 0.3523,  2.7901],\n",
      "        [-0.7674, -4.3283],\n",
      "        [-0.4226, -2.9235],\n",
      "        [ 0.0103, -1.2868],\n",
      "        [ 0.4681,  0.4453],\n",
      "        [ 0.7846,  1.9495],\n",
      "        [-0.4897, -4.9791],\n",
      "        [-0.1037, -3.6511],\n",
      "        [ 0.3285, -2.0947],\n",
      "        [ 0.7801, -0.4135],\n",
      "        [ 1.1389,  1.1098]], grad_fn=<AddmmBackward>)\n",
      "epoch: 171 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9317, -1.9872],\n",
      "        [-1.6402, -0.4517],\n",
      "        [-1.2052,  1.2939],\n",
      "        [-0.7352,  2.9975],\n",
      "        [-0.4378,  4.1829],\n",
      "        [-1.5301, -2.7978],\n",
      "        [-1.2546, -1.2700],\n",
      "        [-0.8259,  0.4655],\n",
      "        [-0.3550,  2.2235],\n",
      "        [-0.0675,  3.5439],\n",
      "        [-1.1148, -3.5945],\n",
      "        [-0.8179, -2.1174],\n",
      "        [-0.3957, -0.4126],\n",
      "        [ 0.0610,  1.3580],\n",
      "        [ 0.3527,  2.7899],\n",
      "        [-0.7675, -4.3296],\n",
      "        [-0.4227, -2.9228],\n",
      "        [ 0.0103, -1.2855],\n",
      "        [ 0.4679,  0.4450],\n",
      "        [ 0.7849,  1.9488],\n",
      "        [-0.4898, -4.9818],\n",
      "        [-0.1037, -3.6515],\n",
      "        [ 0.3283, -2.0932],\n",
      "        [ 0.7799, -0.4127],\n",
      "        [ 1.1388,  1.1093]], grad_fn=<AddmmBackward>)\n",
      "epoch: 172 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9316, -1.9867],\n",
      "        [-1.6400, -0.4515],\n",
      "        [-1.2052,  1.2925],\n",
      "        [-0.7354,  2.9972],\n",
      "        [-0.4379,  4.1856],\n",
      "        [-1.5301, -2.7973],\n",
      "        [-1.2543, -1.2694],\n",
      "        [-0.8256,  0.4649],\n",
      "        [-0.3549,  2.2219],\n",
      "        [-0.0673,  3.5451],\n",
      "        [-1.1149, -3.5946],\n",
      "        [-0.8179, -2.1164],\n",
      "        [-0.3954, -0.4121],\n",
      "        [ 0.0609,  1.3566],\n",
      "        [ 0.3531,  2.7897],\n",
      "        [-0.7676, -4.3309],\n",
      "        [-0.4228, -2.9221],\n",
      "        [ 0.0104, -1.2841],\n",
      "        [ 0.4676,  0.4447],\n",
      "        [ 0.7851,  1.9481],\n",
      "        [-0.4898, -4.9843],\n",
      "        [-0.1037, -3.6518],\n",
      "        [ 0.3282, -2.0917],\n",
      "        [ 0.7796, -0.4118],\n",
      "        [ 1.1387,  1.1089]], grad_fn=<AddmmBackward>)\n",
      "epoch: 173 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9315, -1.9862],\n",
      "        [-1.6397, -0.4514],\n",
      "        [-1.2052,  1.2912],\n",
      "        [-0.7356,  2.9969],\n",
      "        [-0.4380,  4.1882],\n",
      "        [-1.5300, -2.7968],\n",
      "        [-1.2539, -1.2686],\n",
      "        [-0.8252,  0.4644],\n",
      "        [-0.3549,  2.2202],\n",
      "        [-0.0672,  3.5462],\n",
      "        [-1.1151, -3.5946],\n",
      "        [-0.8178, -2.1152],\n",
      "        [-0.3952, -0.4116],\n",
      "        [ 0.0608,  1.3553],\n",
      "        [ 0.3535,  2.7894],\n",
      "        [-0.7677, -4.3320],\n",
      "        [-0.4228, -2.9213],\n",
      "        [ 0.0104, -1.2826],\n",
      "        [ 0.4674,  0.4445],\n",
      "        [ 0.7853,  1.9474],\n",
      "        [-0.4898, -4.9868],\n",
      "        [-0.1037, -3.6520],\n",
      "        [ 0.3281, -2.0901],\n",
      "        [ 0.7794, -0.4109],\n",
      "        [ 1.1386,  1.1086]], grad_fn=<AddmmBackward>)\n",
      "epoch: 174 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9315, -1.9857],\n",
      "        [-1.6395, -0.4512],\n",
      "        [-1.2053,  1.2897],\n",
      "        [-0.7358,  2.9965],\n",
      "        [-0.4382,  4.1908],\n",
      "        [-1.5300, -2.7963],\n",
      "        [-1.2535, -1.2679],\n",
      "        [-0.8249,  0.4639],\n",
      "        [-0.3549,  2.2185],\n",
      "        [-0.0670,  3.5473],\n",
      "        [-1.1152, -3.5946],\n",
      "        [-0.8177, -2.1141],\n",
      "        [-0.3949, -0.4111],\n",
      "        [ 0.0606,  1.3539],\n",
      "        [ 0.3539,  2.7891],\n",
      "        [-0.7678, -4.3330],\n",
      "        [-0.4228, -2.9204],\n",
      "        [ 0.0104, -1.2811],\n",
      "        [ 0.4671,  0.4442],\n",
      "        [ 0.7854,  1.9466],\n",
      "        [-0.4898, -4.9891],\n",
      "        [-0.1037, -3.6521],\n",
      "        [ 0.3281, -2.0884],\n",
      "        [ 0.7792, -0.4100],\n",
      "        [ 1.1386,  1.1082]], grad_fn=<AddmmBackward>)\n",
      "epoch: 175 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9315, -1.9852],\n",
      "        [-1.6393, -0.4511],\n",
      "        [-1.2054,  1.2883],\n",
      "        [-0.7361,  2.9959],\n",
      "        [-0.4384,  4.1933],\n",
      "        [-1.5300, -2.7957],\n",
      "        [-1.2532, -1.2672],\n",
      "        [-0.8247,  0.4633],\n",
      "        [-0.3549,  2.2168],\n",
      "        [-0.0669,  3.5483],\n",
      "        [-1.1153, -3.5945],\n",
      "        [-0.8177, -2.1129],\n",
      "        [-0.3947, -0.4106],\n",
      "        [ 0.0604,  1.3524],\n",
      "        [ 0.3542,  2.7887],\n",
      "        [-0.7679, -4.3340],\n",
      "        [-0.4229, -2.9195],\n",
      "        [ 0.0104, -1.2797],\n",
      "        [ 0.4669,  0.4439],\n",
      "        [ 0.7856,  1.9459],\n",
      "        [-0.4898, -4.9914],\n",
      "        [-0.1036, -3.6522],\n",
      "        [ 0.3280, -2.0867],\n",
      "        [ 0.7790, -0.4091],\n",
      "        [ 1.1385,  1.1077]], grad_fn=<AddmmBackward>)\n",
      "epoch: 176 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9315, -1.9847],\n",
      "        [-1.6391, -0.4511],\n",
      "        [-1.2055,  1.2867],\n",
      "        [-0.7364,  2.9953],\n",
      "        [-0.4386,  4.1957],\n",
      "        [-1.5300, -2.7952],\n",
      "        [-1.2529, -1.2666],\n",
      "        [-0.8245,  0.4626],\n",
      "        [-0.3550,  2.2149],\n",
      "        [-0.0669,  3.5492],\n",
      "        [-1.1155, -3.5944],\n",
      "        [-0.8177, -2.1118],\n",
      "        [-0.3946, -0.4102],\n",
      "        [ 0.0602,  1.3509],\n",
      "        [ 0.3546,  2.7882],\n",
      "        [-0.7680, -4.3349],\n",
      "        [-0.4230, -2.9186],\n",
      "        [ 0.0104, -1.2783],\n",
      "        [ 0.4666,  0.4436],\n",
      "        [ 0.7858,  1.9450],\n",
      "        [-0.4898, -4.9937],\n",
      "        [-0.1036, -3.6524],\n",
      "        [ 0.3280, -2.0851],\n",
      "        [ 0.7788, -0.4083],\n",
      "        [ 1.1385,  1.1072]], grad_fn=<AddmmBackward>)\n",
      "epoch: 177 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9315, -1.9843],\n",
      "        [-1.6390, -0.4511],\n",
      "        [-1.2057,  1.2851],\n",
      "        [-0.7367,  2.9946],\n",
      "        [-0.4388,  4.1980],\n",
      "        [-1.5300, -2.7947],\n",
      "        [-1.2526, -1.2660],\n",
      "        [-0.8243,  0.4619],\n",
      "        [-0.3551,  2.2130],\n",
      "        [-0.0668,  3.5501],\n",
      "        [-1.1157, -3.5944],\n",
      "        [-0.8176, -2.1107],\n",
      "        [-0.3944, -0.4098],\n",
      "        [ 0.0599,  1.3494],\n",
      "        [ 0.3549,  2.7876],\n",
      "        [-0.7681, -4.3359],\n",
      "        [-0.4230, -2.9178],\n",
      "        [ 0.0104, -1.2770],\n",
      "        [ 0.4663,  0.4432],\n",
      "        [ 0.7859,  1.9441],\n",
      "        [-0.4898, -4.9959],\n",
      "        [-0.1035, -3.6525],\n",
      "        [ 0.3279, -2.0836],\n",
      "        [ 0.7786, -0.4075],\n",
      "        [ 1.1384,  1.1067]], grad_fn=<AddmmBackward>)\n",
      "epoch: 178 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9315, -1.9839],\n",
      "        [-1.6389, -0.4511],\n",
      "        [-1.2058,  1.2835],\n",
      "        [-0.7371,  2.9938],\n",
      "        [-0.4391,  4.2004],\n",
      "        [-1.5300, -2.7942],\n",
      "        [-1.2524, -1.2654],\n",
      "        [-0.8241,  0.4612],\n",
      "        [-0.3552,  2.2110],\n",
      "        [-0.0668,  3.5510],\n",
      "        [-1.1158, -3.5943],\n",
      "        [-0.8176, -2.1096],\n",
      "        [-0.3943, -0.4095],\n",
      "        [ 0.0597,  1.3478],\n",
      "        [ 0.3552,  2.7871],\n",
      "        [-0.7682, -4.3369],\n",
      "        [-0.4231, -2.9169],\n",
      "        [ 0.0104, -1.2757],\n",
      "        [ 0.4660,  0.4427],\n",
      "        [ 0.7861,  1.9432],\n",
      "        [-0.4898, -4.9982],\n",
      "        [-0.1035, -3.6526],\n",
      "        [ 0.3279, -2.0820],\n",
      "        [ 0.7784, -0.4068],\n",
      "        [ 1.1384,  1.1061]], grad_fn=<AddmmBackward>)\n",
      "epoch: 179 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9315, -1.9834],\n",
      "        [-1.6387, -0.4510],\n",
      "        [-1.2060,  1.2820],\n",
      "        [-0.7375,  2.9931],\n",
      "        [-0.4394,  4.2028],\n",
      "        [-1.5301, -2.7937],\n",
      "        [-1.2521, -1.2648],\n",
      "        [-0.8239,  0.4606],\n",
      "        [-0.3554,  2.2091],\n",
      "        [-0.0667,  3.5519],\n",
      "        [-1.1160, -3.5942],\n",
      "        [-0.8176, -2.1085],\n",
      "        [-0.3941, -0.4091],\n",
      "        [ 0.0594,  1.3463],\n",
      "        [ 0.3556,  2.7865],\n",
      "        [-0.7683, -4.3378],\n",
      "        [-0.4232, -2.9160],\n",
      "        [ 0.0104, -1.2743],\n",
      "        [ 0.4657,  0.4423],\n",
      "        [ 0.7862,  1.9424],\n",
      "        [-0.4899, -5.0004],\n",
      "        [-0.1034, -3.6527],\n",
      "        [ 0.3278, -2.0805],\n",
      "        [ 0.7782, -0.4061],\n",
      "        [ 1.1383,  1.1056]], grad_fn=<AddmmBackward>)\n",
      "epoch: 180 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9316, -1.9829],\n",
      "        [-1.6386, -0.4509],\n",
      "        [-1.2062,  1.2805],\n",
      "        [-0.7379,  2.9924],\n",
      "        [-0.4396,  4.2052],\n",
      "        [-1.5301, -2.7931],\n",
      "        [-1.2519, -1.2641],\n",
      "        [-0.8238,  0.4600],\n",
      "        [-0.3556,  2.2073],\n",
      "        [-0.0667,  3.5528],\n",
      "        [-1.1162, -3.5941],\n",
      "        [-0.8176, -2.1074],\n",
      "        [-0.3940, -0.4087],\n",
      "        [ 0.0591,  1.3449],\n",
      "        [ 0.3559,  2.7860],\n",
      "        [-0.7684, -4.3387],\n",
      "        [-0.4232, -2.9151],\n",
      "        [ 0.0104, -1.2730],\n",
      "        [ 0.4654,  0.4420],\n",
      "        [ 0.7864,  1.9415],\n",
      "        [-0.4899, -5.0026],\n",
      "        [-0.1034, -3.6529],\n",
      "        [ 0.3278, -2.0790],\n",
      "        [ 0.7781, -0.4054],\n",
      "        [ 1.1383,  1.1051]], grad_fn=<AddmmBackward>)\n",
      "epoch: 181 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9316, -1.9823],\n",
      "        [-1.6385, -0.4507],\n",
      "        [-1.2064,  1.2792],\n",
      "        [-0.7383,  2.9918],\n",
      "        [-0.4399,  4.2077],\n",
      "        [-1.5301, -2.7925],\n",
      "        [-1.2516, -1.2633],\n",
      "        [-0.8236,  0.4594],\n",
      "        [-0.3557,  2.2055],\n",
      "        [-0.0666,  3.5538],\n",
      "        [-1.1164, -3.5939],\n",
      "        [-0.8176, -2.1062],\n",
      "        [-0.3939, -0.4082],\n",
      "        [ 0.0589,  1.3435],\n",
      "        [ 0.3562,  2.7856],\n",
      "        [-0.7685, -4.3396],\n",
      "        [-0.4233, -2.9143],\n",
      "        [ 0.0105, -1.2716],\n",
      "        [ 0.4652,  0.4417],\n",
      "        [ 0.7865,  1.9408],\n",
      "        [-0.4899, -5.0048],\n",
      "        [-0.1033, -3.6530],\n",
      "        [ 0.3278, -2.0775],\n",
      "        [ 0.7779, -0.4046],\n",
      "        [ 1.1383,  1.1046]], grad_fn=<AddmmBackward>)\n",
      "epoch: 182 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9316, -1.9818],\n",
      "        [-1.6384, -0.4506],\n",
      "        [-1.2065,  1.2779],\n",
      "        [-0.7386,  2.9912],\n",
      "        [-0.4401,  4.2103],\n",
      "        [-1.5301, -2.7920],\n",
      "        [-1.2513, -1.2626],\n",
      "        [-0.8234,  0.4589],\n",
      "        [-0.3559,  2.2038],\n",
      "        [-0.0665,  3.5548],\n",
      "        [-1.1166, -3.5938],\n",
      "        [-0.8175, -2.1051],\n",
      "        [-0.3937, -0.4077],\n",
      "        [ 0.0587,  1.3421],\n",
      "        [ 0.3566,  2.7852],\n",
      "        [-0.7686, -4.3406],\n",
      "        [-0.4233, -2.9134],\n",
      "        [ 0.0105, -1.2703],\n",
      "        [ 0.4649,  0.4413],\n",
      "        [ 0.7867,  1.9400],\n",
      "        [-0.4899, -5.0071],\n",
      "        [-0.1033, -3.6532],\n",
      "        [ 0.3278, -2.0760],\n",
      "        [ 0.7778, -0.4039],\n",
      "        [ 1.1384,  1.1041]], grad_fn=<AddmmBackward>)\n",
      "epoch: 183 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9316, -1.9813],\n",
      "        [-1.6382, -0.4504],\n",
      "        [-1.2066,  1.2766],\n",
      "        [-0.7389,  2.9906],\n",
      "        [-0.4403,  4.2129],\n",
      "        [-1.5301, -2.7914],\n",
      "        [-1.2510, -1.2619],\n",
      "        [-0.8232,  0.4585],\n",
      "        [-0.3560,  2.2021],\n",
      "        [-0.0664,  3.5559],\n",
      "        [-1.1167, -3.5937],\n",
      "        [-0.8174, -2.1039],\n",
      "        [-0.3936, -0.4073],\n",
      "        [ 0.0585,  1.3408],\n",
      "        [ 0.3569,  2.7848],\n",
      "        [-0.7687, -4.3416],\n",
      "        [-0.4233, -2.9126],\n",
      "        [ 0.0105, -1.2690],\n",
      "        [ 0.4647,  0.4410],\n",
      "        [ 0.7869,  1.9393],\n",
      "        [-0.4899, -5.0095],\n",
      "        [-0.1032, -3.6535],\n",
      "        [ 0.3278, -2.0746],\n",
      "        [ 0.7777, -0.4033],\n",
      "        [ 1.1384,  1.1037]], grad_fn=<AddmmBackward>)\n",
      "epoch: 184 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9315, -1.9808],\n",
      "        [-1.6380, -0.4502],\n",
      "        [-1.2067,  1.2753],\n",
      "        [-0.7392,  2.9901],\n",
      "        [-0.4404,  4.2155],\n",
      "        [-1.5301, -2.7910],\n",
      "        [-1.2507, -1.2613],\n",
      "        [-0.8230,  0.4580],\n",
      "        [-0.3561,  2.2004],\n",
      "        [-0.0663,  3.5570],\n",
      "        [-1.1169, -3.5937],\n",
      "        [-0.8174, -2.1029],\n",
      "        [-0.3934, -0.4069],\n",
      "        [ 0.0583,  1.3395],\n",
      "        [ 0.3573,  2.7845],\n",
      "        [-0.7688, -4.3427],\n",
      "        [-0.4234, -2.9118],\n",
      "        [ 0.0106, -1.2678],\n",
      "        [ 0.4645,  0.4407],\n",
      "        [ 0.7871,  1.9386],\n",
      "        [-0.4900, -5.0119],\n",
      "        [-0.1032, -3.6538],\n",
      "        [ 0.3278, -2.0732],\n",
      "        [ 0.7776, -0.4026],\n",
      "        [ 1.1385,  1.1032]], grad_fn=<AddmmBackward>)\n",
      "epoch: 185 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9314, -1.9804],\n",
      "        [-1.6378, -0.4500],\n",
      "        [-1.2068,  1.2741],\n",
      "        [-0.7395,  2.9895],\n",
      "        [-0.4406,  4.2181],\n",
      "        [-1.5300, -2.7905],\n",
      "        [-1.2503, -1.2606],\n",
      "        [-0.8227,  0.4575],\n",
      "        [-0.3562,  2.1987],\n",
      "        [-0.0662,  3.5581],\n",
      "        [-1.1170, -3.5937],\n",
      "        [-0.8173, -2.1018],\n",
      "        [-0.3932, -0.4064],\n",
      "        [ 0.0581,  1.3382],\n",
      "        [ 0.3577,  2.7841],\n",
      "        [-0.7689, -4.3438],\n",
      "        [-0.4234, -2.9111],\n",
      "        [ 0.0107, -1.2666],\n",
      "        [ 0.4643,  0.4404],\n",
      "        [ 0.7873,  1.9379],\n",
      "        [-0.4900, -5.0143],\n",
      "        [-0.1031, -3.6541],\n",
      "        [ 0.3278, -2.0719],\n",
      "        [ 0.7775, -0.4020],\n",
      "        [ 1.1386,  1.1028]], grad_fn=<AddmmBackward>)\n",
      "epoch: 186 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9314, -1.9800],\n",
      "        [-1.6375, -0.4499],\n",
      "        [-1.2069,  1.2729],\n",
      "        [-0.7397,  2.9889],\n",
      "        [-0.4406,  4.2208],\n",
      "        [-1.5300, -2.7901],\n",
      "        [-1.2500, -1.2600],\n",
      "        [-0.8225,  0.4570],\n",
      "        [-0.3563,  2.1971],\n",
      "        [-0.0660,  3.5593],\n",
      "        [-1.1172, -3.5938],\n",
      "        [-0.8172, -2.1008],\n",
      "        [-0.3930, -0.4060],\n",
      "        [ 0.0579,  1.3370],\n",
      "        [ 0.3581,  2.7838],\n",
      "        [-0.7691, -4.3449],\n",
      "        [-0.4234, -2.9104],\n",
      "        [ 0.0107, -1.2654],\n",
      "        [ 0.4640,  0.4401],\n",
      "        [ 0.7875,  1.9373],\n",
      "        [-0.4901, -5.0167],\n",
      "        [-0.1031, -3.6545],\n",
      "        [ 0.3278, -2.0706],\n",
      "        [ 0.7774, -0.4014],\n",
      "        [ 1.1387,  1.1023]], grad_fn=<AddmmBackward>)\n",
      "epoch: 187 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9313, -1.9795],\n",
      "        [-1.6373, -0.4497],\n",
      "        [-1.2069,  1.2717],\n",
      "        [-0.7400,  2.9884],\n",
      "        [-0.4407,  4.2235],\n",
      "        [-1.5299, -2.7897],\n",
      "        [-1.2497, -1.2593],\n",
      "        [-0.8223,  0.4566],\n",
      "        [-0.3564,  2.1954],\n",
      "        [-0.0658,  3.5604],\n",
      "        [-1.1174, -3.5937],\n",
      "        [-0.8172, -2.0998],\n",
      "        [-0.3929, -0.4056],\n",
      "        [ 0.0577,  1.3357],\n",
      "        [ 0.3585,  2.7835],\n",
      "        [-0.7693, -4.3460],\n",
      "        [-0.4235, -2.9096],\n",
      "        [ 0.0107, -1.2642],\n",
      "        [ 0.4638,  0.4398],\n",
      "        [ 0.7877,  1.9367],\n",
      "        [-0.4903, -5.0191],\n",
      "        [-0.1031, -3.6548],\n",
      "        [ 0.3278, -2.0693],\n",
      "        [ 0.7773, -0.4008],\n",
      "        [ 1.1387,  1.1019]], grad_fn=<AddmmBackward>)\n",
      "epoch: 188 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9313, -1.9791],\n",
      "        [-1.6371, -0.4495],\n",
      "        [-1.2070,  1.2706],\n",
      "        [-0.7402,  2.9878],\n",
      "        [-0.4408,  4.2261],\n",
      "        [-1.5299, -2.7892],\n",
      "        [-1.2494, -1.2586],\n",
      "        [-0.8220,  0.4562],\n",
      "        [-0.3566,  2.1938],\n",
      "        [-0.0656,  3.5615],\n",
      "        [-1.1176, -3.5937],\n",
      "        [-0.8171, -2.0987],\n",
      "        [-0.3928, -0.4051],\n",
      "        [ 0.0575,  1.3345],\n",
      "        [ 0.3589,  2.7832],\n",
      "        [-0.7695, -4.3470],\n",
      "        [-0.4236, -2.9088],\n",
      "        [ 0.0108, -1.2629],\n",
      "        [ 0.4636,  0.4396],\n",
      "        [ 0.7879,  1.9361],\n",
      "        [-0.4904, -5.0214],\n",
      "        [-0.1032, -3.6551],\n",
      "        [ 0.3278, -2.0680],\n",
      "        [ 0.7772, -0.4001],\n",
      "        [ 1.1388,  1.1016]], grad_fn=<AddmmBackward>)\n",
      "epoch: 189 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9312, -1.9786],\n",
      "        [-1.6369, -0.4493],\n",
      "        [-1.2070,  1.2694],\n",
      "        [-0.7405,  2.9871],\n",
      "        [-0.4409,  4.2288],\n",
      "        [-1.5299, -2.7887],\n",
      "        [-1.2491, -1.2579],\n",
      "        [-0.8218,  0.4557],\n",
      "        [-0.3567,  2.1922],\n",
      "        [-0.0654,  3.5626],\n",
      "        [-1.1179, -3.5936],\n",
      "        [-0.8171, -2.0976],\n",
      "        [-0.3927, -0.4046],\n",
      "        [ 0.0573,  1.3334],\n",
      "        [ 0.3593,  2.7829],\n",
      "        [-0.7697, -4.3480],\n",
      "        [-0.4237, -2.9080],\n",
      "        [ 0.0108, -1.2617],\n",
      "        [ 0.4633,  0.4393],\n",
      "        [ 0.7881,  1.9355],\n",
      "        [-0.4906, -5.0237],\n",
      "        [-0.1033, -3.6554],\n",
      "        [ 0.3277, -2.0666],\n",
      "        [ 0.7770, -0.3995],\n",
      "        [ 1.1389,  1.1012]], grad_fn=<AddmmBackward>)\n",
      "epoch: 190 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9311, -1.9782],\n",
      "        [-1.6367, -0.4491],\n",
      "        [-1.2071,  1.2682],\n",
      "        [-0.7407,  2.9864],\n",
      "        [-0.4409,  4.2313],\n",
      "        [-1.5299, -2.7883],\n",
      "        [-1.2487, -1.2573],\n",
      "        [-0.8216,  0.4553],\n",
      "        [-0.3569,  2.1905],\n",
      "        [-0.0652,  3.5637],\n",
      "        [-1.1181, -3.5935],\n",
      "        [-0.8170, -2.0965],\n",
      "        [-0.3926, -0.4042],\n",
      "        [ 0.0571,  1.3322],\n",
      "        [ 0.3597,  2.7826],\n",
      "        [-0.7699, -4.3489],\n",
      "        [-0.4238, -2.9072],\n",
      "        [ 0.0108, -1.2604],\n",
      "        [ 0.4630,  0.4391],\n",
      "        [ 0.7882,  1.9349],\n",
      "        [-0.4908, -5.0260],\n",
      "        [-0.1033, -3.6556],\n",
      "        [ 0.3277, -2.0652],\n",
      "        [ 0.7769, -0.3989],\n",
      "        [ 1.1389,  1.1008]], grad_fn=<AddmmBackward>)\n",
      "epoch: 191 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9310, -1.9778],\n",
      "        [-1.6364, -0.4490],\n",
      "        [-1.2071,  1.2670],\n",
      "        [-0.7410,  2.9857],\n",
      "        [-0.4410,  4.2339],\n",
      "        [-1.5298, -2.7878],\n",
      "        [-1.2484, -1.2566],\n",
      "        [-0.8214,  0.4548],\n",
      "        [-0.3570,  2.1889],\n",
      "        [-0.0651,  3.5647],\n",
      "        [-1.1182, -3.5934],\n",
      "        [-0.8170, -2.0954],\n",
      "        [-0.3924, -0.4037],\n",
      "        [ 0.0568,  1.3309],\n",
      "        [ 0.3601,  2.7823],\n",
      "        [-0.7700, -4.3498],\n",
      "        [-0.4239, -2.9063],\n",
      "        [ 0.0108, -1.2592],\n",
      "        [ 0.4628,  0.4388],\n",
      "        [ 0.7884,  1.9343],\n",
      "        [-0.4909, -5.0282],\n",
      "        [-0.1033, -3.6559],\n",
      "        [ 0.3276, -2.0639],\n",
      "        [ 0.7768, -0.3982],\n",
      "        [ 1.1390,  1.1005]], grad_fn=<AddmmBackward>)\n",
      "epoch: 192 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9309, -1.9774],\n",
      "        [-1.6362, -0.4489],\n",
      "        [-1.2072,  1.2658],\n",
      "        [-0.7413,  2.9848],\n",
      "        [-0.4411,  4.2363],\n",
      "        [-1.5297, -2.7874],\n",
      "        [-1.2481, -1.2560],\n",
      "        [-0.8212,  0.4543],\n",
      "        [-0.3572,  2.1872],\n",
      "        [-0.0649,  3.5657],\n",
      "        [-1.1184, -3.5933],\n",
      "        [-0.8169, -2.0943],\n",
      "        [-0.3923, -0.4033],\n",
      "        [ 0.0566,  1.3297],\n",
      "        [ 0.3604,  2.7819],\n",
      "        [-0.7702, -4.3508],\n",
      "        [-0.4239, -2.9055],\n",
      "        [ 0.0108, -1.2580],\n",
      "        [ 0.4625,  0.4385],\n",
      "        [ 0.7885,  1.9336],\n",
      "        [-0.4910, -5.0304],\n",
      "        [-0.1034, -3.6561],\n",
      "        [ 0.3276, -2.0626],\n",
      "        [ 0.7766, -0.3976],\n",
      "        [ 1.1390,  1.1001]], grad_fn=<AddmmBackward>)\n",
      "epoch: 193 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9307, -1.9771],\n",
      "        [-1.6359, -0.4488],\n",
      "        [-1.2073,  1.2646],\n",
      "        [-0.7416,  2.9840],\n",
      "        [-0.4412,  4.2388],\n",
      "        [-1.5296, -2.7869],\n",
      "        [-1.2477, -1.2554],\n",
      "        [-0.8211,  0.4538],\n",
      "        [-0.3575,  2.1854],\n",
      "        [-0.0648,  3.5666],\n",
      "        [-1.1185, -3.5931],\n",
      "        [-0.8168, -2.0933],\n",
      "        [-0.3922, -0.4029],\n",
      "        [ 0.0563,  1.3285],\n",
      "        [ 0.3607,  2.7815],\n",
      "        [-0.7703, -4.3516],\n",
      "        [-0.4240, -2.9047],\n",
      "        [ 0.0108, -1.2569],\n",
      "        [ 0.4622,  0.4382],\n",
      "        [ 0.7886,  1.9330],\n",
      "        [-0.4911, -5.0325],\n",
      "        [-0.1034, -3.6563],\n",
      "        [ 0.3276, -2.0613],\n",
      "        [ 0.7765, -0.3971],\n",
      "        [ 1.1390,  1.0997]], grad_fn=<AddmmBackward>)\n",
      "epoch: 194 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9306, -1.9767],\n",
      "        [-1.6357, -0.4487],\n",
      "        [-1.2074,  1.2633],\n",
      "        [-0.7419,  2.9831],\n",
      "        [-0.4413,  4.2412],\n",
      "        [-1.5295, -2.7865],\n",
      "        [-1.2474, -1.2548],\n",
      "        [-0.8209,  0.4533],\n",
      "        [-0.3577,  2.1837],\n",
      "        [-0.0647,  3.5676],\n",
      "        [-1.1187, -3.5930],\n",
      "        [-0.8167, -2.0922],\n",
      "        [-0.3922, -0.4025],\n",
      "        [ 0.0560,  1.3272],\n",
      "        [ 0.3610,  2.7812],\n",
      "        [-0.7704, -4.3525],\n",
      "        [-0.4240, -2.9038],\n",
      "        [ 0.0108, -1.2557],\n",
      "        [ 0.4619,  0.4379],\n",
      "        [ 0.7887,  1.9324],\n",
      "        [-0.4912, -5.0346],\n",
      "        [-0.1034, -3.6565],\n",
      "        [ 0.3276, -2.0599],\n",
      "        [ 0.7763, -0.3965],\n",
      "        [ 1.1390,  1.0993]], grad_fn=<AddmmBackward>)\n",
      "epoch: 195 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9304, -1.9763],\n",
      "        [-1.6355, -0.4486],\n",
      "        [-1.2074,  1.2621],\n",
      "        [-0.7423,  2.9822],\n",
      "        [-0.4415,  4.2437],\n",
      "        [-1.5294, -2.7860],\n",
      "        [-1.2470, -1.2542],\n",
      "        [-0.8207,  0.4528],\n",
      "        [-0.3580,  2.1821],\n",
      "        [-0.0645,  3.5685],\n",
      "        [-1.1188, -3.5928],\n",
      "        [-0.8166, -2.0911],\n",
      "        [-0.3921, -0.4021],\n",
      "        [ 0.0557,  1.3260],\n",
      "        [ 0.3613,  2.7808],\n",
      "        [-0.7705, -4.3534],\n",
      "        [-0.4240, -2.9030],\n",
      "        [ 0.0108, -1.2545],\n",
      "        [ 0.4616,  0.4377],\n",
      "        [ 0.7888,  1.9317],\n",
      "        [-0.4913, -5.0367],\n",
      "        [-0.1034, -3.6567],\n",
      "        [ 0.3276, -2.0586],\n",
      "        [ 0.7762, -0.3959],\n",
      "        [ 1.1391,  1.0989]], grad_fn=<AddmmBackward>)\n",
      "epoch: 196 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9303, -1.9760],\n",
      "        [-1.6352, -0.4485],\n",
      "        [-1.2076,  1.2610],\n",
      "        [-0.7426,  2.9813],\n",
      "        [-0.4416,  4.2461],\n",
      "        [-1.5293, -2.7856],\n",
      "        [-1.2467, -1.2535],\n",
      "        [-0.8206,  0.4524],\n",
      "        [-0.3583,  2.1804],\n",
      "        [-0.0644,  3.5695],\n",
      "        [-1.1190, -3.5926],\n",
      "        [-0.8166, -2.0900],\n",
      "        [-0.3920, -0.4017],\n",
      "        [ 0.0555,  1.3249],\n",
      "        [ 0.3616,  2.7805],\n",
      "        [-0.7707, -4.3542],\n",
      "        [-0.4241, -2.9021],\n",
      "        [ 0.0108, -1.2533],\n",
      "        [ 0.4613,  0.4374],\n",
      "        [ 0.7889,  1.9311],\n",
      "        [-0.4914, -5.0388],\n",
      "        [-0.1034, -3.6568],\n",
      "        [ 0.3276, -2.0573],\n",
      "        [ 0.7761, -0.3954],\n",
      "        [ 1.1391,  1.0985]], grad_fn=<AddmmBackward>)\n",
      "epoch: 197 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9302, -1.9756],\n",
      "        [-1.6350, -0.4483],\n",
      "        [-1.2077,  1.2598],\n",
      "        [-0.7429,  2.9804],\n",
      "        [-0.4417,  4.2485],\n",
      "        [-1.5293, -2.7851],\n",
      "        [-1.2464, -1.2529],\n",
      "        [-0.8204,  0.4519],\n",
      "        [-0.3585,  2.1788],\n",
      "        [-0.0643,  3.5704],\n",
      "        [-1.1191, -3.5925],\n",
      "        [-0.8165, -2.0889],\n",
      "        [-0.3920, -0.4013],\n",
      "        [ 0.0552,  1.3237],\n",
      "        [ 0.3619,  2.7802],\n",
      "        [-0.7708, -4.3550],\n",
      "        [-0.4242, -2.9013],\n",
      "        [ 0.0108, -1.2522],\n",
      "        [ 0.4610,  0.4372],\n",
      "        [ 0.7890,  1.9306],\n",
      "        [-0.4915, -5.0408],\n",
      "        [-0.1034, -3.6570],\n",
      "        [ 0.3276, -2.0560],\n",
      "        [ 0.7760, -0.3948],\n",
      "        [ 1.1392,  1.0982]], grad_fn=<AddmmBackward>)\n",
      "epoch: 198 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9301, -1.9752],\n",
      "        [-1.6348, -0.4482],\n",
      "        [-1.2078,  1.2587],\n",
      "        [-0.7433,  2.9795],\n",
      "        [-0.4418,  4.2510],\n",
      "        [-1.5292, -2.7846],\n",
      "        [-1.2461, -1.2522],\n",
      "        [-0.8203,  0.4515],\n",
      "        [-0.3588,  2.1772],\n",
      "        [-0.0642,  3.5713],\n",
      "        [-1.1193, -3.5923],\n",
      "        [-0.8164, -2.0879],\n",
      "        [-0.3919, -0.4009],\n",
      "        [ 0.0549,  1.3226],\n",
      "        [ 0.3622,  2.7799],\n",
      "        [-0.7710, -4.3559],\n",
      "        [-0.4242, -2.9004],\n",
      "        [ 0.0108, -1.2510],\n",
      "        [ 0.4607,  0.4369],\n",
      "        [ 0.7891,  1.9300],\n",
      "        [-0.4916, -5.0429],\n",
      "        [-0.1034, -3.6572],\n",
      "        [ 0.3276, -2.0548],\n",
      "        [ 0.7759, -0.3943],\n",
      "        [ 1.1393,  1.0978]], grad_fn=<AddmmBackward>)\n",
      "epoch: 199 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9300, -1.9749],\n",
      "        [-1.6346, -0.4481],\n",
      "        [-1.2079,  1.2576],\n",
      "        [-0.7436,  2.9786],\n",
      "        [-0.4419,  4.2534],\n",
      "        [-1.5292, -2.7842],\n",
      "        [-1.2458, -1.2516],\n",
      "        [-0.8202,  0.4510],\n",
      "        [-0.3591,  2.1756],\n",
      "        [-0.0640,  3.5723],\n",
      "        [-1.1195, -3.5922],\n",
      "        [-0.8164, -2.0868],\n",
      "        [-0.3918, -0.4005],\n",
      "        [ 0.0546,  1.3215],\n",
      "        [ 0.3625,  2.7796],\n",
      "        [-0.7711, -4.3567],\n",
      "        [-0.4243, -2.8996],\n",
      "        [ 0.0109, -1.2499],\n",
      "        [ 0.4604,  0.4367],\n",
      "        [ 0.7892,  1.9294],\n",
      "        [-0.4918, -5.0450],\n",
      "        [-0.1034, -3.6575],\n",
      "        [ 0.3276, -2.0535],\n",
      "        [ 0.7758, -0.3938],\n",
      "        [ 1.1394,  1.0974]], grad_fn=<AddmmBackward>)\n",
      "epoch: 200 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9299, -1.9746],\n",
      "        [-1.6344, -0.4480],\n",
      "        [-1.2080,  1.2566],\n",
      "        [-0.7439,  2.9777],\n",
      "        [-0.4419,  4.2559],\n",
      "        [-1.5291, -2.7838],\n",
      "        [-1.2454, -1.2510],\n",
      "        [-0.8200,  0.4506],\n",
      "        [-0.3594,  2.1740],\n",
      "        [-0.0638,  3.5732],\n",
      "        [-1.1197, -3.5921],\n",
      "        [-0.8163, -2.0858],\n",
      "        [-0.3918, -0.4001],\n",
      "        [ 0.0544,  1.3203],\n",
      "        [ 0.3628,  2.7794],\n",
      "        [-0.7713, -4.3576],\n",
      "        [-0.4243, -2.8988],\n",
      "        [ 0.0109, -1.2488],\n",
      "        [ 0.4602,  0.4364],\n",
      "        [ 0.7893,  1.9288],\n",
      "        [-0.4919, -5.0471],\n",
      "        [-0.1034, -3.6577],\n",
      "        [ 0.3276, -2.0524],\n",
      "        [ 0.7757, -0.3933],\n",
      "        [ 1.1395,  1.0971]], grad_fn=<AddmmBackward>)\n",
      "epoch: 201 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9298, -1.9742],\n",
      "        [-1.6342, -0.4478],\n",
      "        [-1.2081,  1.2555],\n",
      "        [-0.7442,  2.9768],\n",
      "        [-0.4419,  4.2583],\n",
      "        [-1.5290, -2.7834],\n",
      "        [-1.2451, -1.2504],\n",
      "        [-0.8199,  0.4502],\n",
      "        [-0.3596,  2.1725],\n",
      "        [-0.0636,  3.5742],\n",
      "        [-1.1199, -3.5919],\n",
      "        [-0.8162, -2.0848],\n",
      "        [-0.3917, -0.3997],\n",
      "        [ 0.0541,  1.3193],\n",
      "        [ 0.3631,  2.7791],\n",
      "        [-0.7714, -4.3585],\n",
      "        [-0.4244, -2.8981],\n",
      "        [ 0.0109, -1.2478],\n",
      "        [ 0.4599,  0.4361],\n",
      "        [ 0.7895,  1.9283],\n",
      "        [-0.4921, -5.0492],\n",
      "        [-0.1035, -3.6580],\n",
      "        [ 0.3277, -2.0512],\n",
      "        [ 0.7757, -0.3928],\n",
      "        [ 1.1396,  1.0967]], grad_fn=<AddmmBackward>)\n",
      "epoch: 202 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9297, -1.9739],\n",
      "        [-1.6340, -0.4477],\n",
      "        [-1.2082,  1.2545],\n",
      "        [-0.7445,  2.9759],\n",
      "        [-0.4420,  4.2608],\n",
      "        [-1.5290, -2.7830],\n",
      "        [-1.2448, -1.2498],\n",
      "        [-0.8197,  0.4498],\n",
      "        [-0.3599,  2.1710],\n",
      "        [-0.0634,  3.5752],\n",
      "        [-1.1200, -3.5918],\n",
      "        [-0.8161, -2.0838],\n",
      "        [-0.3916, -0.3993],\n",
      "        [ 0.0539,  1.3182],\n",
      "        [ 0.3635,  2.7789],\n",
      "        [-0.7716, -4.3594],\n",
      "        [-0.4244, -2.8973],\n",
      "        [ 0.0110, -1.2467],\n",
      "        [ 0.4597,  0.4359],\n",
      "        [ 0.7897,  1.9277],\n",
      "        [-0.4922, -5.0513],\n",
      "        [-0.1035, -3.6583],\n",
      "        [ 0.3277, -2.0500],\n",
      "        [ 0.7757, -0.3923],\n",
      "        [ 1.1398,  1.0964]], grad_fn=<AddmmBackward>)\n",
      "epoch: 203 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9296, -1.9736],\n",
      "        [-1.6338, -0.4475],\n",
      "        [-1.2082,  1.2535],\n",
      "        [-0.7448,  2.9750],\n",
      "        [-0.4420,  4.2632],\n",
      "        [-1.5289, -2.7826],\n",
      "        [-1.2445, -1.2492],\n",
      "        [-0.8196,  0.4494],\n",
      "        [-0.3602,  2.1695],\n",
      "        [-0.0631,  3.5761],\n",
      "        [-1.1202, -3.5917],\n",
      "        [-0.8160, -2.0828],\n",
      "        [-0.3916, -0.3989],\n",
      "        [ 0.0536,  1.3171],\n",
      "        [ 0.3638,  2.7787],\n",
      "        [-0.7717, -4.3602],\n",
      "        [-0.4245, -2.8965],\n",
      "        [ 0.0110, -1.2456],\n",
      "        [ 0.4594,  0.4357],\n",
      "        [ 0.7898,  1.9272],\n",
      "        [-0.4924, -5.0533],\n",
      "        [-0.1035, -3.6585],\n",
      "        [ 0.3278, -2.0489],\n",
      "        [ 0.7756, -0.3918],\n",
      "        [ 1.1400,  1.0960]], grad_fn=<AddmmBackward>)\n",
      "epoch: 204 Loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9295, -1.9733],\n",
      "        [-1.6336, -0.4473],\n",
      "        [-1.2083,  1.2526],\n",
      "        [-0.7451,  2.9741],\n",
      "        [-0.4420,  4.2657],\n",
      "        [-1.5289, -2.7822],\n",
      "        [-1.2442, -1.2486],\n",
      "        [-0.8194,  0.4490],\n",
      "        [-0.3605,  2.1680],\n",
      "        [-0.0629,  3.5770],\n",
      "        [-1.1204, -3.5916],\n",
      "        [-0.8159, -2.0818],\n",
      "        [-0.3915, -0.3985],\n",
      "        [ 0.0534,  1.3161],\n",
      "        [ 0.3642,  2.7785],\n",
      "        [-0.7719, -4.3610],\n",
      "        [-0.4245, -2.8957],\n",
      "        [ 0.0110, -1.2445],\n",
      "        [ 0.4592,  0.4354],\n",
      "        [ 0.7900,  1.9267],\n",
      "        [-0.4925, -5.0553],\n",
      "        [-0.1035, -3.6587],\n",
      "        [ 0.3279, -2.0477],\n",
      "        [ 0.7756, -0.3914],\n",
      "        [ 1.1401,  1.0957]], grad_fn=<AddmmBackward>)\n",
      "epoch: 205 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9294, -1.9729],\n",
      "        [-1.6334, -0.4472],\n",
      "        [-1.2084,  1.2516],\n",
      "        [-0.7454,  2.9732],\n",
      "        [-0.4420,  4.2681],\n",
      "        [-1.5288, -2.7818],\n",
      "        [-1.2439, -1.2480],\n",
      "        [-0.8193,  0.4487],\n",
      "        [-0.3608,  2.1666],\n",
      "        [-0.0627,  3.5780],\n",
      "        [-1.1205, -3.5914],\n",
      "        [-0.8159, -2.0808],\n",
      "        [-0.3914, -0.3981],\n",
      "        [ 0.0532,  1.3151],\n",
      "        [ 0.3645,  2.7782],\n",
      "        [-0.7720, -4.3618],\n",
      "        [-0.4246, -2.8949],\n",
      "        [ 0.0111, -1.2435],\n",
      "        [ 0.4590,  0.4352],\n",
      "        [ 0.7901,  1.9262],\n",
      "        [-0.4927, -5.0573],\n",
      "        [-0.1035, -3.6590],\n",
      "        [ 0.3279, -2.0465],\n",
      "        [ 0.7756, -0.3909],\n",
      "        [ 1.1403,  1.0954]], grad_fn=<AddmmBackward>)\n",
      "epoch: 206 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9293, -1.9727],\n",
      "        [-1.6332, -0.4470],\n",
      "        [-1.2085,  1.2506],\n",
      "        [-0.7457,  2.9722],\n",
      "        [-0.4420,  4.2705],\n",
      "        [-1.5287, -2.7814],\n",
      "        [-1.2435, -1.2474],\n",
      "        [-0.8192,  0.4483],\n",
      "        [-0.3611,  2.1651],\n",
      "        [-0.0625,  3.5789],\n",
      "        [-1.1207, -3.5913],\n",
      "        [-0.8158, -2.0798],\n",
      "        [-0.3914, -0.3978],\n",
      "        [ 0.0529,  1.3141],\n",
      "        [ 0.3648,  2.7780],\n",
      "        [-0.7722, -4.3626],\n",
      "        [-0.4246, -2.8941],\n",
      "        [ 0.0111, -1.2425],\n",
      "        [ 0.4587,  0.4350],\n",
      "        [ 0.7903,  1.9256],\n",
      "        [-0.4928, -5.0593],\n",
      "        [-0.1035, -3.6592],\n",
      "        [ 0.3280, -2.0454],\n",
      "        [ 0.7756, -0.3905],\n",
      "        [ 1.1405,  1.0951]], grad_fn=<AddmmBackward>)\n",
      "epoch: 207 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9292, -1.9724],\n",
      "        [-1.6330, -0.4469],\n",
      "        [-1.2086,  1.2496],\n",
      "        [-0.7461,  2.9713],\n",
      "        [-0.4420,  4.2728],\n",
      "        [-1.5287, -2.7811],\n",
      "        [-1.2432, -1.2468],\n",
      "        [-0.8191,  0.4479],\n",
      "        [-0.3614,  2.1636],\n",
      "        [-0.0623,  3.5798],\n",
      "        [-1.1208, -3.5912],\n",
      "        [-0.8157, -2.0788],\n",
      "        [-0.3913, -0.3974],\n",
      "        [ 0.0527,  1.3130],\n",
      "        [ 0.3652,  2.7778],\n",
      "        [-0.7723, -4.3634],\n",
      "        [-0.4246, -2.8933],\n",
      "        [ 0.0112, -1.2415],\n",
      "        [ 0.4585,  0.4347],\n",
      "        [ 0.7904,  1.9251],\n",
      "        [-0.4930, -5.0612],\n",
      "        [-0.1035, -3.6594],\n",
      "        [ 0.3281, -2.0443],\n",
      "        [ 0.7755, -0.3900],\n",
      "        [ 1.1406,  1.0947]], grad_fn=<AddmmBackward>)\n",
      "epoch: 208 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9291, -1.9721],\n",
      "        [-1.6329, -0.4468],\n",
      "        [-1.2088,  1.2487],\n",
      "        [-0.7464,  2.9703],\n",
      "        [-0.4420,  4.2751],\n",
      "        [-1.5286, -2.7807],\n",
      "        [-1.2429, -1.2462],\n",
      "        [-0.8190,  0.4475],\n",
      "        [-0.3618,  2.1621],\n",
      "        [-0.0621,  3.5806],\n",
      "        [-1.1210, -3.5910],\n",
      "        [-0.8156, -2.0778],\n",
      "        [-0.3913, -0.3971],\n",
      "        [ 0.0524,  1.3120],\n",
      "        [ 0.3655,  2.7776],\n",
      "        [-0.7725, -4.3642],\n",
      "        [-0.4247, -2.8926],\n",
      "        [ 0.0112, -1.2405],\n",
      "        [ 0.4582,  0.4345],\n",
      "        [ 0.7905,  1.9246],\n",
      "        [-0.4931, -5.0631],\n",
      "        [-0.1035, -3.6596],\n",
      "        [ 0.3282, -2.0432],\n",
      "        [ 0.7755, -0.3896],\n",
      "        [ 1.1408,  1.0944]], grad_fn=<AddmmBackward>)\n",
      "epoch: 209 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9290, -1.9719],\n",
      "        [-1.6327, -0.4467],\n",
      "        [-1.2089,  1.2477],\n",
      "        [-0.7468,  2.9693],\n",
      "        [-0.4420,  4.2775],\n",
      "        [-1.5286, -2.7803],\n",
      "        [-1.2426, -1.2457],\n",
      "        [-0.8189,  0.4471],\n",
      "        [-0.3621,  2.1606],\n",
      "        [-0.0619,  3.5815],\n",
      "        [-1.1211, -3.5909],\n",
      "        [-0.8155, -2.0769],\n",
      "        [-0.3913, -0.3967],\n",
      "        [ 0.0521,  1.3110],\n",
      "        [ 0.3657,  2.7773],\n",
      "        [-0.7726, -4.3650],\n",
      "        [-0.4247, -2.8918],\n",
      "        [ 0.0112, -1.2395],\n",
      "        [ 0.4579,  0.4343],\n",
      "        [ 0.7906,  1.9241],\n",
      "        [-0.4933, -5.0650],\n",
      "        [-0.1035, -3.6598],\n",
      "        [ 0.3282, -2.0421],\n",
      "        [ 0.7754, -0.3892],\n",
      "        [ 1.1409,  1.0941]], grad_fn=<AddmmBackward>)\n",
      "epoch: 210 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9289, -1.9716],\n",
      "        [-1.6325, -0.4466],\n",
      "        [-1.2090,  1.2468],\n",
      "        [-0.7471,  2.9683],\n",
      "        [-0.4420,  4.2797],\n",
      "        [-1.5285, -2.7800],\n",
      "        [-1.2423, -1.2451],\n",
      "        [-0.8188,  0.4467],\n",
      "        [-0.3625,  2.1592],\n",
      "        [-0.0617,  3.5823],\n",
      "        [-1.1213, -3.5907],\n",
      "        [-0.8154, -2.0759],\n",
      "        [-0.3912, -0.3963],\n",
      "        [ 0.0518,  1.3100],\n",
      "        [ 0.3660,  2.7771],\n",
      "        [-0.7728, -4.3657],\n",
      "        [-0.4248, -2.8910],\n",
      "        [ 0.0112, -1.2385],\n",
      "        [ 0.4576,  0.4340],\n",
      "        [ 0.7907,  1.9236],\n",
      "        [-0.4934, -5.0669],\n",
      "        [-0.1035, -3.6599],\n",
      "        [ 0.3283, -2.0409],\n",
      "        [ 0.7754, -0.3887],\n",
      "        [ 1.1411,  1.0938]], grad_fn=<AddmmBackward>)\n",
      "epoch: 211 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9288, -1.9714],\n",
      "        [-1.6323, -0.4464],\n",
      "        [-1.2091,  1.2459],\n",
      "        [-0.7475,  2.9673],\n",
      "        [-0.4420,  4.2820],\n",
      "        [-1.5284, -2.7796],\n",
      "        [-1.2420, -1.2445],\n",
      "        [-0.8187,  0.4463],\n",
      "        [-0.3629,  2.1577],\n",
      "        [-0.0615,  3.5831],\n",
      "        [-1.1214, -3.5906],\n",
      "        [-0.8153, -2.0749],\n",
      "        [-0.3912, -0.3960],\n",
      "        [ 0.0515,  1.3090],\n",
      "        [ 0.3663,  2.7769],\n",
      "        [-0.7729, -4.3664],\n",
      "        [-0.4248, -2.8901],\n",
      "        [ 0.0112, -1.2375],\n",
      "        [ 0.4574,  0.4338],\n",
      "        [ 0.7908,  1.9231],\n",
      "        [-0.4936, -5.0687],\n",
      "        [-0.1035, -3.6601],\n",
      "        [ 0.3284, -2.0398],\n",
      "        [ 0.7753, -0.3883],\n",
      "        [ 1.1412,  1.0935]], grad_fn=<AddmmBackward>)\n",
      "epoch: 212 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9287, -1.9711],\n",
      "        [-1.6321, -0.4463],\n",
      "        [-1.2092,  1.2450],\n",
      "        [-0.7478,  2.9663],\n",
      "        [-0.4420,  4.2843],\n",
      "        [-1.5283, -2.7792],\n",
      "        [-1.2417, -1.2440],\n",
      "        [-0.8186,  0.4459],\n",
      "        [-0.3632,  2.1563],\n",
      "        [-0.0613,  3.5839],\n",
      "        [-1.1215, -3.5904],\n",
      "        [-0.8152, -2.0740],\n",
      "        [-0.3912, -0.3956],\n",
      "        [ 0.0512,  1.3080],\n",
      "        [ 0.3666,  2.7767],\n",
      "        [-0.7730, -4.3671],\n",
      "        [-0.4248, -2.8894],\n",
      "        [ 0.0113, -1.2365],\n",
      "        [ 0.4571,  0.4336],\n",
      "        [ 0.7909,  1.9226],\n",
      "        [-0.4937, -5.0705],\n",
      "        [-0.1035, -3.6602],\n",
      "        [ 0.3284, -2.0387],\n",
      "        [ 0.7753, -0.3879],\n",
      "        [ 1.1414,  1.0931]], grad_fn=<AddmmBackward>)\n",
      "epoch: 213 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9285, -1.9709],\n",
      "        [-1.6319, -0.4462],\n",
      "        [-1.2093,  1.2441],\n",
      "        [-0.7482,  2.9653],\n",
      "        [-0.4419,  4.2865],\n",
      "        [-1.5282, -2.7789],\n",
      "        [-1.2414, -1.2434],\n",
      "        [-0.8185,  0.4456],\n",
      "        [-0.3636,  2.1549],\n",
      "        [-0.0610,  3.5847],\n",
      "        [-1.1217, -3.5903],\n",
      "        [-0.8151, -2.0730],\n",
      "        [-0.3912, -0.3953],\n",
      "        [ 0.0509,  1.3071],\n",
      "        [ 0.3668,  2.7765],\n",
      "        [-0.7732, -4.3678],\n",
      "        [-0.4249, -2.8886],\n",
      "        [ 0.0113, -1.2355],\n",
      "        [ 0.4568,  0.4334],\n",
      "        [ 0.7910,  1.9221],\n",
      "        [-0.4939, -5.0723],\n",
      "        [-0.1036, -3.6604],\n",
      "        [ 0.3285, -2.0377],\n",
      "        [ 0.7753, -0.3875],\n",
      "        [ 1.1415,  1.0928]], grad_fn=<AddmmBackward>)\n",
      "epoch: 214 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9284, -1.9707],\n",
      "        [-1.6317, -0.4461],\n",
      "        [-1.2094,  1.2432],\n",
      "        [-0.7485,  2.9643],\n",
      "        [-0.4419,  4.2888],\n",
      "        [-1.5281, -2.7786],\n",
      "        [-1.2410, -1.2429],\n",
      "        [-0.8184,  0.4452],\n",
      "        [-0.3640,  2.1535],\n",
      "        [-0.0608,  3.5855],\n",
      "        [-1.1218, -3.5901],\n",
      "        [-0.8149, -2.0721],\n",
      "        [-0.3912, -0.3950],\n",
      "        [ 0.0507,  1.3061],\n",
      "        [ 0.3671,  2.7763],\n",
      "        [-0.7733, -4.3685],\n",
      "        [-0.4249, -2.8878],\n",
      "        [ 0.0113, -1.2346],\n",
      "        [ 0.4565,  0.4331],\n",
      "        [ 0.7911,  1.9216],\n",
      "        [-0.4941, -5.0740],\n",
      "        [-0.1036, -3.6606],\n",
      "        [ 0.3286, -2.0366],\n",
      "        [ 0.7752, -0.3871],\n",
      "        [ 1.1417,  1.0925]], grad_fn=<AddmmBackward>)\n",
      "epoch: 215 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9283, -1.9705],\n",
      "        [-1.6315, -0.4459],\n",
      "        [-1.2095,  1.2424],\n",
      "        [-0.7489,  2.9633],\n",
      "        [-0.4418,  4.2910],\n",
      "        [-1.5281, -2.7782],\n",
      "        [-1.2407, -1.2423],\n",
      "        [-0.8183,  0.4448],\n",
      "        [-0.3643,  2.1521],\n",
      "        [-0.0606,  3.5863],\n",
      "        [-1.1219, -3.5900],\n",
      "        [-0.8148, -2.0712],\n",
      "        [-0.3911, -0.3946],\n",
      "        [ 0.0504,  1.3052],\n",
      "        [ 0.3674,  2.7761],\n",
      "        [-0.7734, -4.3692],\n",
      "        [-0.4249, -2.8870],\n",
      "        [ 0.0113, -1.2337],\n",
      "        [ 0.4563,  0.4329],\n",
      "        [ 0.7912,  1.9211],\n",
      "        [-0.4942, -5.0758],\n",
      "        [-0.1036, -3.6607],\n",
      "        [ 0.3287, -2.0356],\n",
      "        [ 0.7752, -0.3868],\n",
      "        [ 1.1418,  1.0922]], grad_fn=<AddmmBackward>)\n",
      "epoch: 216 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9282, -1.9703],\n",
      "        [-1.6313, -0.4458],\n",
      "        [-1.2096,  1.2416],\n",
      "        [-0.7492,  2.9624],\n",
      "        [-0.4418,  4.2933],\n",
      "        [-1.5280, -2.7779],\n",
      "        [-1.2404, -1.2418],\n",
      "        [-0.8182,  0.4445],\n",
      "        [-0.3647,  2.1507],\n",
      "        [-0.0603,  3.5871],\n",
      "        [-1.1220, -3.5899],\n",
      "        [-0.8147, -2.0702],\n",
      "        [-0.3911, -0.3943],\n",
      "        [ 0.0501,  1.3042],\n",
      "        [ 0.3677,  2.7759],\n",
      "        [-0.7736, -4.3699],\n",
      "        [-0.4249, -2.8863],\n",
      "        [ 0.0113, -1.2328],\n",
      "        [ 0.4560,  0.4327],\n",
      "        [ 0.7913,  1.9207],\n",
      "        [-0.4944, -5.0776],\n",
      "        [-0.1036, -3.6609],\n",
      "        [ 0.3288, -2.0345],\n",
      "        [ 0.7752, -0.3864],\n",
      "        [ 1.1420,  1.0919]], grad_fn=<AddmmBackward>)\n",
      "epoch: 217 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9280, -1.9700],\n",
      "        [-1.6311, -0.4456],\n",
      "        [-1.2097,  1.2408],\n",
      "        [-0.7495,  2.9615],\n",
      "        [-0.4417,  4.2955],\n",
      "        [-1.5279, -2.7776],\n",
      "        [-1.2401, -1.2412],\n",
      "        [-0.8181,  0.4442],\n",
      "        [-0.3651,  2.1494],\n",
      "        [-0.0601,  3.5879],\n",
      "        [-1.1221, -3.5898],\n",
      "        [-0.8146, -2.0693],\n",
      "        [-0.3911, -0.3940],\n",
      "        [ 0.0499,  1.3033],\n",
      "        [ 0.3680,  2.7757],\n",
      "        [-0.7737, -4.3706],\n",
      "        [-0.4250, -2.8855],\n",
      "        [ 0.0114, -1.2319],\n",
      "        [ 0.4557,  0.4325],\n",
      "        [ 0.7915,  1.9202],\n",
      "        [-0.4946, -5.0793],\n",
      "        [-0.1036, -3.6611],\n",
      "        [ 0.3289, -2.0335],\n",
      "        [ 0.7752, -0.3860],\n",
      "        [ 1.1422,  1.0916]], grad_fn=<AddmmBackward>)\n",
      "epoch: 218 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9279, -1.9698],\n",
      "        [-1.6309, -0.4455],\n",
      "        [-1.2098,  1.2400],\n",
      "        [-0.7498,  2.9605],\n",
      "        [-0.4416,  4.2977],\n",
      "        [-1.5278, -2.7773],\n",
      "        [-1.2398, -1.2407],\n",
      "        [-0.8180,  0.4438],\n",
      "        [-0.3654,  2.1481],\n",
      "        [-0.0598,  3.5887],\n",
      "        [-1.1223, -3.5896],\n",
      "        [-0.8145, -2.0684],\n",
      "        [-0.3911, -0.3937],\n",
      "        [ 0.0496,  1.3024],\n",
      "        [ 0.3683,  2.7756],\n",
      "        [-0.7739, -4.3713],\n",
      "        [-0.4250, -2.8848],\n",
      "        [ 0.0114, -1.2310],\n",
      "        [ 0.4555,  0.4323],\n",
      "        [ 0.7916,  1.9198],\n",
      "        [-0.4948, -5.0810],\n",
      "        [-0.1037, -3.6612],\n",
      "        [ 0.3290, -2.0325],\n",
      "        [ 0.7751, -0.3857],\n",
      "        [ 1.1423,  1.0914]], grad_fn=<AddmmBackward>)\n",
      "epoch: 219 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9278, -1.9696],\n",
      "        [-1.6307, -0.4453],\n",
      "        [-1.2099,  1.2393],\n",
      "        [-0.7502,  2.9596],\n",
      "        [-0.4415,  4.2999],\n",
      "        [-1.5278, -2.7770],\n",
      "        [-1.2394, -1.2401],\n",
      "        [-0.8179,  0.4435],\n",
      "        [-0.3658,  2.1468],\n",
      "        [-0.0595,  3.5895],\n",
      "        [-1.1224, -3.5895],\n",
      "        [-0.8144, -2.0675],\n",
      "        [-0.3911, -0.3933],\n",
      "        [ 0.0493,  1.3016],\n",
      "        [ 0.3686,  2.7754],\n",
      "        [-0.7740, -4.3720],\n",
      "        [-0.4250, -2.8840],\n",
      "        [ 0.0114, -1.2301],\n",
      "        [ 0.4552,  0.4321],\n",
      "        [ 0.7917,  1.9194],\n",
      "        [-0.4950, -5.0827],\n",
      "        [-0.1037, -3.6614],\n",
      "        [ 0.3291, -2.0316],\n",
      "        [ 0.7751, -0.3853],\n",
      "        [ 1.1425,  1.0911]], grad_fn=<AddmmBackward>)\n",
      "epoch: 220 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9277, -1.9695],\n",
      "        [-1.6305, -0.4452],\n",
      "        [-1.2100,  1.2386],\n",
      "        [-0.7505,  2.9587],\n",
      "        [-0.4414,  4.3021],\n",
      "        [-1.5277, -2.7767],\n",
      "        [-1.2391, -1.2396],\n",
      "        [-0.8178,  0.4432],\n",
      "        [-0.3661,  2.1455],\n",
      "        [-0.0593,  3.5902],\n",
      "        [-1.1225, -3.5894],\n",
      "        [-0.8143, -2.0666],\n",
      "        [-0.3910, -0.3930],\n",
      "        [ 0.0491,  1.3007],\n",
      "        [ 0.3689,  2.7752],\n",
      "        [-0.7742, -4.3727],\n",
      "        [-0.4251, -2.8833],\n",
      "        [ 0.0114, -1.2292],\n",
      "        [ 0.4549,  0.4318],\n",
      "        [ 0.7918,  1.9189],\n",
      "        [-0.4952, -5.0844],\n",
      "        [-0.1037, -3.6615],\n",
      "        [ 0.3291, -2.0306],\n",
      "        [ 0.7751, -0.3850],\n",
      "        [ 1.1427,  1.0908]], grad_fn=<AddmmBackward>)\n",
      "epoch: 221 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9276, -1.9693],\n",
      "        [-1.6303, -0.4451],\n",
      "        [-1.2100,  1.2378],\n",
      "        [-0.7509,  2.9578],\n",
      "        [-0.4413,  4.3042],\n",
      "        [-1.5276, -2.7764],\n",
      "        [-1.2388, -1.2391],\n",
      "        [-0.8178,  0.4429],\n",
      "        [-0.3665,  2.1443],\n",
      "        [-0.0590,  3.5910],\n",
      "        [-1.1226, -3.5893],\n",
      "        [-0.8141, -2.0658],\n",
      "        [-0.3910, -0.3927],\n",
      "        [ 0.0488,  1.2998],\n",
      "        [ 0.3692,  2.7750],\n",
      "        [-0.7743, -4.3734],\n",
      "        [-0.4251, -2.8826],\n",
      "        [ 0.0114, -1.2284],\n",
      "        [ 0.4547,  0.4316],\n",
      "        [ 0.7919,  1.9185],\n",
      "        [-0.4954, -5.0861],\n",
      "        [-0.1037, -3.6617],\n",
      "        [ 0.3292, -2.0296],\n",
      "        [ 0.7751, -0.3847],\n",
      "        [ 1.1429,  1.0905]], grad_fn=<AddmmBackward>)\n",
      "epoch: 222 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9275, -1.9691],\n",
      "        [-1.6301, -0.4449],\n",
      "        [-1.2101,  1.2371],\n",
      "        [-0.7512,  2.9568],\n",
      "        [-0.4412,  4.3064],\n",
      "        [-1.5275, -2.7761],\n",
      "        [-1.2385, -1.2386],\n",
      "        [-0.8177,  0.4426],\n",
      "        [-0.3669,  2.1430],\n",
      "        [-0.0588,  3.5917],\n",
      "        [-1.1227, -3.5892],\n",
      "        [-0.8140, -2.0649],\n",
      "        [-0.3910, -0.3924],\n",
      "        [ 0.0485,  1.2989],\n",
      "        [ 0.3694,  2.7749],\n",
      "        [-0.7745, -4.3740],\n",
      "        [-0.4251, -2.8818],\n",
      "        [ 0.0115, -1.2276],\n",
      "        [ 0.4544,  0.4314],\n",
      "        [ 0.7920,  1.9181],\n",
      "        [-0.4956, -5.0878],\n",
      "        [-0.1038, -3.6618],\n",
      "        [ 0.3294, -2.0287],\n",
      "        [ 0.7751, -0.3844],\n",
      "        [ 1.1431,  1.0902]], grad_fn=<AddmmBackward>)\n",
      "epoch: 223 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9274, -1.9689],\n",
      "        [-1.6299, -0.4448],\n",
      "        [-1.2102,  1.2364],\n",
      "        [-0.7516,  2.9559],\n",
      "        [-0.4411,  4.3085],\n",
      "        [-1.5275, -2.7758],\n",
      "        [-1.2382, -1.2381],\n",
      "        [-0.8176,  0.4423],\n",
      "        [-0.3672,  2.1418],\n",
      "        [-0.0585,  3.5924],\n",
      "        [-1.1228, -3.5891],\n",
      "        [-0.8139, -2.0641],\n",
      "        [-0.3910, -0.3921],\n",
      "        [ 0.0483,  1.2981],\n",
      "        [ 0.3697,  2.7747],\n",
      "        [-0.7746, -4.3746],\n",
      "        [-0.4251, -2.8811],\n",
      "        [ 0.0115, -1.2267],\n",
      "        [ 0.4541,  0.4312],\n",
      "        [ 0.7921,  1.9177],\n",
      "        [-0.4958, -5.0894],\n",
      "        [-0.1038, -3.6620],\n",
      "        [ 0.3295, -2.0277],\n",
      "        [ 0.7751, -0.3841],\n",
      "        [ 1.1432,  1.0899]], grad_fn=<AddmmBackward>)\n",
      "epoch: 224 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9273, -1.9688],\n",
      "        [-1.6297, -0.4447],\n",
      "        [-1.2104,  1.2357],\n",
      "        [-0.7519,  2.9550],\n",
      "        [-0.4410,  4.3105],\n",
      "        [-1.5274, -2.7755],\n",
      "        [-1.2379, -1.2376],\n",
      "        [-0.8175,  0.4419],\n",
      "        [-0.3676,  2.1405],\n",
      "        [-0.0583,  3.5931],\n",
      "        [-1.1229, -3.5890],\n",
      "        [-0.8138, -2.0632],\n",
      "        [-0.3910, -0.3919],\n",
      "        [ 0.0480,  1.2972],\n",
      "        [ 0.3700,  2.7745],\n",
      "        [-0.7747, -4.3753],\n",
      "        [-0.4251, -2.8804],\n",
      "        [ 0.0115, -1.2259],\n",
      "        [ 0.4539,  0.4310],\n",
      "        [ 0.7922,  1.9172],\n",
      "        [-0.4960, -5.0909],\n",
      "        [-0.1038, -3.6621],\n",
      "        [ 0.3296, -2.0268],\n",
      "        [ 0.7751, -0.3838],\n",
      "        [ 1.1434,  1.0896]], grad_fn=<AddmmBackward>)\n",
      "epoch: 225 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9272, -1.9686],\n",
      "        [-1.6295, -0.4445],\n",
      "        [-1.2105,  1.2350],\n",
      "        [-0.7523,  2.9541],\n",
      "        [-0.4409,  4.3126],\n",
      "        [-1.5273, -2.7753],\n",
      "        [-1.2375, -1.2370],\n",
      "        [-0.8175,  0.4416],\n",
      "        [-0.3680,  2.1393],\n",
      "        [-0.0580,  3.5938],\n",
      "        [-1.1230, -3.5889],\n",
      "        [-0.8136, -2.0623],\n",
      "        [-0.3910, -0.3916],\n",
      "        [ 0.0477,  1.2964],\n",
      "        [ 0.3702,  2.7743],\n",
      "        [-0.7748, -4.3759],\n",
      "        [-0.4251, -2.8797],\n",
      "        [ 0.0115, -1.2251],\n",
      "        [ 0.4536,  0.4308],\n",
      "        [ 0.7923,  1.9168],\n",
      "        [-0.4962, -5.0925],\n",
      "        [-0.1038, -3.6622],\n",
      "        [ 0.3297, -2.0259],\n",
      "        [ 0.7751, -0.3835],\n",
      "        [ 1.1436,  1.0893]], grad_fn=<AddmmBackward>)\n",
      "epoch: 226 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9271, -1.9685],\n",
      "        [-1.6293, -0.4444],\n",
      "        [-1.2106,  1.2343],\n",
      "        [-0.7526,  2.9532],\n",
      "        [-0.4408,  4.3146],\n",
      "        [-1.5272, -2.7750],\n",
      "        [-1.2372, -1.2366],\n",
      "        [-0.8174,  0.4413],\n",
      "        [-0.3684,  2.1381],\n",
      "        [-0.0578,  3.5944],\n",
      "        [-1.1231, -3.5887],\n",
      "        [-0.8135, -2.0615],\n",
      "        [-0.3910, -0.3913],\n",
      "        [ 0.0474,  1.2955],\n",
      "        [ 0.3705,  2.7741],\n",
      "        [-0.7749, -4.3765],\n",
      "        [-0.4251, -2.8790],\n",
      "        [ 0.0116, -1.2243],\n",
      "        [ 0.4533,  0.4306],\n",
      "        [ 0.7924,  1.9164],\n",
      "        [-0.4964, -5.0940],\n",
      "        [-0.1038, -3.6623],\n",
      "        [ 0.3298, -2.0249],\n",
      "        [ 0.7750, -0.3832],\n",
      "        [ 1.1438,  1.0891]], grad_fn=<AddmmBackward>)\n",
      "epoch: 227 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9270, -1.9683],\n",
      "        [-1.6291, -0.4443],\n",
      "        [-1.2107,  1.2336],\n",
      "        [-0.7530,  2.9522],\n",
      "        [-0.4407,  4.3166],\n",
      "        [-1.5271, -2.7747],\n",
      "        [-1.2369, -1.2361],\n",
      "        [-0.8173,  0.4410],\n",
      "        [-0.3688,  2.1369],\n",
      "        [-0.0575,  3.5951],\n",
      "        [-1.1232, -3.5886],\n",
      "        [-0.8134, -2.0607],\n",
      "        [-0.3910, -0.3910],\n",
      "        [ 0.0471,  1.2947],\n",
      "        [ 0.3707,  2.7739],\n",
      "        [-0.7751, -4.3771],\n",
      "        [-0.4251, -2.8783],\n",
      "        [ 0.0116, -1.2235],\n",
      "        [ 0.4531,  0.4304],\n",
      "        [ 0.7925,  1.9160],\n",
      "        [-0.4966, -5.0955],\n",
      "        [-0.1038, -3.6624],\n",
      "        [ 0.3299, -2.0240],\n",
      "        [ 0.7750, -0.3829],\n",
      "        [ 1.1440,  1.0888]], grad_fn=<AddmmBackward>)\n",
      "epoch: 228 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9269, -1.9682],\n",
      "        [-1.6290, -0.4441],\n",
      "        [-1.2108,  1.2330],\n",
      "        [-0.7534,  2.9513],\n",
      "        [-0.4406,  4.3186],\n",
      "        [-1.5271, -2.7745],\n",
      "        [-1.2366, -1.2356],\n",
      "        [-0.8173,  0.4407],\n",
      "        [-0.3692,  2.1357],\n",
      "        [-0.0573,  3.5957],\n",
      "        [-1.1233, -3.5885],\n",
      "        [-0.8133, -2.0599],\n",
      "        [-0.3910, -0.3908],\n",
      "        [ 0.0469,  1.2939],\n",
      "        [ 0.3710,  2.7737],\n",
      "        [-0.7752, -4.3776],\n",
      "        [-0.4251, -2.8776],\n",
      "        [ 0.0116, -1.2227],\n",
      "        [ 0.4528,  0.4302],\n",
      "        [ 0.7925,  1.9156],\n",
      "        [-0.4968, -5.0970],\n",
      "        [-0.1038, -3.6625],\n",
      "        [ 0.3300, -2.0231],\n",
      "        [ 0.7750, -0.3826],\n",
      "        [ 1.1441,  1.0885]], grad_fn=<AddmmBackward>)\n",
      "epoch: 229 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9268, -1.9681],\n",
      "        [-1.6288, -0.4440],\n",
      "        [-1.2109,  1.2324],\n",
      "        [-0.7537,  2.9505],\n",
      "        [-0.4405,  4.3206],\n",
      "        [-1.5270, -2.7742],\n",
      "        [-1.2363, -1.2351],\n",
      "        [-0.8172,  0.4404],\n",
      "        [-0.3695,  2.1345],\n",
      "        [-0.0570,  3.5963],\n",
      "        [-1.1234, -3.5884],\n",
      "        [-0.8132, -2.0591],\n",
      "        [-0.3910, -0.3905],\n",
      "        [ 0.0466,  1.2931],\n",
      "        [ 0.3712,  2.7735],\n",
      "        [-0.7753, -4.3782],\n",
      "        [-0.4251, -2.8769],\n",
      "        [ 0.0116, -1.2220],\n",
      "        [ 0.4525,  0.4300],\n",
      "        [ 0.7926,  1.9152],\n",
      "        [-0.4970, -5.0985],\n",
      "        [-0.1038, -3.6626],\n",
      "        [ 0.3302, -2.0222],\n",
      "        [ 0.7750, -0.3823],\n",
      "        [ 1.1443,  1.0883]], grad_fn=<AddmmBackward>)\n",
      "epoch: 230 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9267, -1.9680],\n",
      "        [-1.6286, -0.4439],\n",
      "        [-1.2110,  1.2317],\n",
      "        [-0.7541,  2.9496],\n",
      "        [-0.4404,  4.3226],\n",
      "        [-1.5269, -2.7740],\n",
      "        [-1.2360, -1.2347],\n",
      "        [-0.8172,  0.4401],\n",
      "        [-0.3699,  2.1334],\n",
      "        [-0.0568,  3.5969],\n",
      "        [-1.1235, -3.5883],\n",
      "        [-0.8130, -2.0583],\n",
      "        [-0.3910, -0.3902],\n",
      "        [ 0.0463,  1.2923],\n",
      "        [ 0.3715,  2.7733],\n",
      "        [-0.7754, -4.3788],\n",
      "        [-0.4251, -2.8762],\n",
      "        [ 0.0116, -1.2212],\n",
      "        [ 0.4523,  0.4298],\n",
      "        [ 0.7927,  1.9148],\n",
      "        [-0.4972, -5.0999],\n",
      "        [-0.1039, -3.6626],\n",
      "        [ 0.3303, -2.0214],\n",
      "        [ 0.7750, -0.3820],\n",
      "        [ 1.1445,  1.0880]], grad_fn=<AddmmBackward>)\n",
      "epoch: 231 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9266, -1.9679],\n",
      "        [-1.6284, -0.4437],\n",
      "        [-1.2111,  1.2311],\n",
      "        [-0.7545,  2.9487],\n",
      "        [-0.4402,  4.3245],\n",
      "        [-1.5269, -2.7738],\n",
      "        [-1.2357, -1.2342],\n",
      "        [-0.8171,  0.4398],\n",
      "        [-0.3703,  2.1322],\n",
      "        [-0.0565,  3.5976],\n",
      "        [-1.1235, -3.5882],\n",
      "        [-0.8129, -2.0575],\n",
      "        [-0.3910, -0.3900],\n",
      "        [ 0.0460,  1.2915],\n",
      "        [ 0.3717,  2.7731],\n",
      "        [-0.7756, -4.3794],\n",
      "        [-0.4250, -2.8755],\n",
      "        [ 0.0116, -1.2205],\n",
      "        [ 0.4520,  0.4296],\n",
      "        [ 0.7928,  1.9144],\n",
      "        [-0.4974, -5.1014],\n",
      "        [-0.1039, -3.6627],\n",
      "        [ 0.3304, -2.0205],\n",
      "        [ 0.7750, -0.3817],\n",
      "        [ 1.1447,  1.0878]], grad_fn=<AddmmBackward>)\n",
      "epoch: 232 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9265, -1.9677],\n",
      "        [-1.6283, -0.4436],\n",
      "        [-1.2112,  1.2306],\n",
      "        [-0.7548,  2.9479],\n",
      "        [-0.4401,  4.3264],\n",
      "        [-1.5268, -2.7736],\n",
      "        [-1.2354, -1.2337],\n",
      "        [-0.8171,  0.4396],\n",
      "        [-0.3707,  2.1311],\n",
      "        [-0.0562,  3.5982],\n",
      "        [-1.1236, -3.5882],\n",
      "        [-0.8128, -2.0567],\n",
      "        [-0.3911, -0.3897],\n",
      "        [ 0.0458,  1.2907],\n",
      "        [ 0.3720,  2.7729],\n",
      "        [-0.7757, -4.3799],\n",
      "        [-0.4250, -2.8749],\n",
      "        [ 0.0117, -1.2197],\n",
      "        [ 0.4517,  0.4295],\n",
      "        [ 0.7929,  1.9140],\n",
      "        [-0.4976, -5.1028],\n",
      "        [-0.1039, -3.6628],\n",
      "        [ 0.3305, -2.0196],\n",
      "        [ 0.7750, -0.3815],\n",
      "        [ 1.1449,  1.0875]], grad_fn=<AddmmBackward>)\n",
      "epoch: 233 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9265, -1.9676],\n",
      "        [-1.6281, -0.4435],\n",
      "        [-1.2113,  1.2300],\n",
      "        [-0.7552,  2.9471],\n",
      "        [-0.4400,  4.3283],\n",
      "        [-1.5267, -2.7733],\n",
      "        [-1.2351, -1.2333],\n",
      "        [-0.8170,  0.4393],\n",
      "        [-0.3710,  2.1300],\n",
      "        [-0.0560,  3.5987],\n",
      "        [-1.1237, -3.5881],\n",
      "        [-0.8127, -2.0559],\n",
      "        [-0.3911, -0.3895],\n",
      "        [ 0.0455,  1.2900],\n",
      "        [ 0.3722,  2.7727],\n",
      "        [-0.7758, -4.3805],\n",
      "        [-0.4250, -2.8742],\n",
      "        [ 0.0117, -1.2190],\n",
      "        [ 0.4515,  0.4293],\n",
      "        [ 0.7930,  1.9136],\n",
      "        [-0.4978, -5.1042],\n",
      "        [-0.1039, -3.6629],\n",
      "        [ 0.3306, -2.0188],\n",
      "        [ 0.7751, -0.3812],\n",
      "        [ 1.1451,  1.0873]], grad_fn=<AddmmBackward>)\n",
      "epoch: 234 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9264, -1.9676],\n",
      "        [-1.6279, -0.4433],\n",
      "        [-1.2114,  1.2294],\n",
      "        [-0.7556,  2.9463],\n",
      "        [-0.4398,  4.3302],\n",
      "        [-1.5266, -2.7731],\n",
      "        [-1.2348, -1.2328],\n",
      "        [-0.8170,  0.4390],\n",
      "        [-0.3714,  2.1289],\n",
      "        [-0.0557,  3.5993],\n",
      "        [-1.1238, -3.5880],\n",
      "        [-0.8125, -2.0552],\n",
      "        [-0.3911, -0.3892],\n",
      "        [ 0.0452,  1.2892],\n",
      "        [ 0.3725,  2.7725],\n",
      "        [-0.7759, -4.3811],\n",
      "        [-0.4250, -2.8736],\n",
      "        [ 0.0117, -1.2183],\n",
      "        [ 0.4512,  0.4291],\n",
      "        [ 0.7930,  1.9132],\n",
      "        [-0.4981, -5.1056],\n",
      "        [-0.1039, -3.6630],\n",
      "        [ 0.3308, -2.0180],\n",
      "        [ 0.7751, -0.3809],\n",
      "        [ 1.1453,  1.0870]], grad_fn=<AddmmBackward>)\n",
      "epoch: 235 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9263, -1.9675],\n",
      "        [-1.6277, -0.4432],\n",
      "        [-1.2115,  1.2289],\n",
      "        [-0.7559,  2.9455],\n",
      "        [-0.4397,  4.3321],\n",
      "        [-1.5266, -2.7729],\n",
      "        [-1.2345, -1.2324],\n",
      "        [-0.8169,  0.4388],\n",
      "        [-0.3718,  2.1278],\n",
      "        [-0.0555,  3.5999],\n",
      "        [-1.1238, -3.5879],\n",
      "        [-0.8124, -2.0544],\n",
      "        [-0.3911, -0.3890],\n",
      "        [ 0.0450,  1.2885],\n",
      "        [ 0.3727,  2.7723],\n",
      "        [-0.7760, -4.3816],\n",
      "        [-0.4249, -2.8730],\n",
      "        [ 0.0117, -1.2176],\n",
      "        [ 0.4510,  0.4289],\n",
      "        [ 0.7931,  1.9129],\n",
      "        [-0.4983, -5.1070],\n",
      "        [-0.1039, -3.6630],\n",
      "        [ 0.3309, -2.0172],\n",
      "        [ 0.7751, -0.3807],\n",
      "        [ 1.1454,  1.0868]], grad_fn=<AddmmBackward>)\n",
      "epoch: 236 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9262, -1.9674],\n",
      "        [-1.6276, -0.4431],\n",
      "        [-1.2116,  1.2283],\n",
      "        [-0.7563,  2.9447],\n",
      "        [-0.4395,  4.3340],\n",
      "        [-1.5265, -2.7727],\n",
      "        [-1.2342, -1.2319],\n",
      "        [-0.8169,  0.4385],\n",
      "        [-0.3721,  2.1268],\n",
      "        [-0.0552,  3.6004],\n",
      "        [-1.1239, -3.5879],\n",
      "        [-0.8123, -2.0537],\n",
      "        [-0.3911, -0.3887],\n",
      "        [ 0.0447,  1.2877],\n",
      "        [ 0.3729,  2.7721],\n",
      "        [-0.7761, -4.3822],\n",
      "        [-0.4249, -2.8723],\n",
      "        [ 0.0117, -1.2169],\n",
      "        [ 0.4507,  0.4288],\n",
      "        [ 0.7932,  1.9125],\n",
      "        [-0.4985, -5.1084],\n",
      "        [-0.1039, -3.6631],\n",
      "        [ 0.3310, -2.0163],\n",
      "        [ 0.7751, -0.3804],\n",
      "        [ 1.1456,  1.0866]], grad_fn=<AddmmBackward>)\n",
      "epoch: 237 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9262, -1.9673],\n",
      "        [-1.6274, -0.4429],\n",
      "        [-1.2117,  1.2278],\n",
      "        [-0.7567,  2.9439],\n",
      "        [-0.4394,  4.3358],\n",
      "        [-1.5264, -2.7725],\n",
      "        [-1.2339, -1.2315],\n",
      "        [-0.8168,  0.4382],\n",
      "        [-0.3725,  2.1257],\n",
      "        [-0.0549,  3.6010],\n",
      "        [-1.1240, -3.5878],\n",
      "        [-0.8122, -2.0530],\n",
      "        [-0.3911, -0.3885],\n",
      "        [ 0.0444,  1.2870],\n",
      "        [ 0.3732,  2.7719],\n",
      "        [-0.7763, -4.3827],\n",
      "        [-0.4249, -2.8717],\n",
      "        [ 0.0117, -1.2162],\n",
      "        [ 0.4504,  0.4286],\n",
      "        [ 0.7933,  1.9121],\n",
      "        [-0.4987, -5.1097],\n",
      "        [-0.1040, -3.6632],\n",
      "        [ 0.3312, -2.0155],\n",
      "        [ 0.7751, -0.3802],\n",
      "        [ 1.1458,  1.0863]], grad_fn=<AddmmBackward>)\n",
      "epoch: 238 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9261, -1.9672],\n",
      "        [-1.6272, -0.4428],\n",
      "        [-1.2118,  1.2273],\n",
      "        [-0.7570,  2.9431],\n",
      "        [-0.4392,  4.3376],\n",
      "        [-1.5264, -2.7724],\n",
      "        [-1.2336, -1.2311],\n",
      "        [-0.8168,  0.4380],\n",
      "        [-0.3729,  2.1247],\n",
      "        [-0.0547,  3.6015],\n",
      "        [-1.1240, -3.5877],\n",
      "        [-0.8120, -2.0522],\n",
      "        [-0.3911, -0.3883],\n",
      "        [ 0.0442,  1.2863],\n",
      "        [ 0.3734,  2.7717],\n",
      "        [-0.7764, -4.3832],\n",
      "        [-0.4249, -2.8711],\n",
      "        [ 0.0117, -1.2155],\n",
      "        [ 0.4502,  0.4284],\n",
      "        [ 0.7933,  1.9117],\n",
      "        [-0.4990, -5.1110],\n",
      "        [-0.1040, -3.6632],\n",
      "        [ 0.3313, -2.0147],\n",
      "        [ 0.7751, -0.3799],\n",
      "        [ 1.1460,  1.0861]], grad_fn=<AddmmBackward>)\n",
      "epoch: 239 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9260, -1.9671],\n",
      "        [-1.6271, -0.4427],\n",
      "        [-1.2119,  1.2268],\n",
      "        [-0.7574,  2.9423],\n",
      "        [-0.4391,  4.3393],\n",
      "        [-1.5263, -2.7722],\n",
      "        [-1.2333, -1.2306],\n",
      "        [-0.8167,  0.4377],\n",
      "        [-0.3732,  2.1236],\n",
      "        [-0.0544,  3.6020],\n",
      "        [-1.1241, -3.5876],\n",
      "        [-0.8119, -2.0515],\n",
      "        [-0.3912, -0.3881],\n",
      "        [ 0.0439,  1.2856],\n",
      "        [ 0.3736,  2.7714],\n",
      "        [-0.7765, -4.3837],\n",
      "        [-0.4248, -2.8705],\n",
      "        [ 0.0117, -1.2149],\n",
      "        [ 0.4499,  0.4283],\n",
      "        [ 0.7934,  1.9114],\n",
      "        [-0.4992, -5.1123],\n",
      "        [-0.1040, -3.6633],\n",
      "        [ 0.3314, -2.0139],\n",
      "        [ 0.7751, -0.3797],\n",
      "        [ 1.1462,  1.0859]], grad_fn=<AddmmBackward>)\n",
      "epoch: 240 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9259, -1.9671],\n",
      "        [-1.6269, -0.4425],\n",
      "        [-1.2120,  1.2263],\n",
      "        [-0.7578,  2.9415],\n",
      "        [-0.4389,  4.3411],\n",
      "        [-1.5262, -2.7720],\n",
      "        [-1.2330, -1.2302],\n",
      "        [-0.8167,  0.4375],\n",
      "        [-0.3736,  2.1226],\n",
      "        [-0.0542,  3.6025],\n",
      "        [-1.1241, -3.5876],\n",
      "        [-0.8118, -2.0508],\n",
      "        [-0.3912, -0.3878],\n",
      "        [ 0.0436,  1.2849],\n",
      "        [ 0.3738,  2.7712],\n",
      "        [-0.7766, -4.3842],\n",
      "        [-0.4248, -2.8699],\n",
      "        [ 0.0117, -1.2142],\n",
      "        [ 0.4496,  0.4281],\n",
      "        [ 0.7935,  1.9110],\n",
      "        [-0.4994, -5.1135],\n",
      "        [-0.1040, -3.6633],\n",
      "        [ 0.3316, -2.0132],\n",
      "        [ 0.7751, -0.3794],\n",
      "        [ 1.1463,  1.0857]], grad_fn=<AddmmBackward>)\n",
      "epoch: 241 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9259, -1.9670],\n",
      "        [-1.6267, -0.4424],\n",
      "        [-1.2121,  1.2258],\n",
      "        [-0.7581,  2.9408],\n",
      "        [-0.4387,  4.3428],\n",
      "        [-1.5261, -2.7718],\n",
      "        [-1.2327, -1.2298],\n",
      "        [-0.8167,  0.4372],\n",
      "        [-0.3740,  2.1216],\n",
      "        [-0.0539,  3.6029],\n",
      "        [-1.1242, -3.5875],\n",
      "        [-0.8117, -2.0501],\n",
      "        [-0.3912, -0.3876],\n",
      "        [ 0.0433,  1.2842],\n",
      "        [ 0.3741,  2.7710],\n",
      "        [-0.7767, -4.3847],\n",
      "        [-0.4247, -2.8693],\n",
      "        [ 0.0118, -1.2136],\n",
      "        [ 0.4493,  0.4280],\n",
      "        [ 0.7935,  1.9107],\n",
      "        [-0.4996, -5.1148],\n",
      "        [-0.1040, -3.6634],\n",
      "        [ 0.3317, -2.0124],\n",
      "        [ 0.7751, -0.3792],\n",
      "        [ 1.1465,  1.0855]], grad_fn=<AddmmBackward>)\n",
      "epoch: 242 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9258, -1.9670],\n",
      "        [-1.6266, -0.4422],\n",
      "        [-1.2122,  1.2253],\n",
      "        [-0.7585,  2.9400],\n",
      "        [-0.4386,  4.3445],\n",
      "        [-1.5261, -2.7716],\n",
      "        [-1.2324, -1.2294],\n",
      "        [-0.8166,  0.4370],\n",
      "        [-0.3743,  2.1206],\n",
      "        [-0.0536,  3.6034],\n",
      "        [-1.1242, -3.5875],\n",
      "        [-0.8115, -2.0494],\n",
      "        [-0.3912, -0.3874],\n",
      "        [ 0.0431,  1.2835],\n",
      "        [ 0.3743,  2.7708],\n",
      "        [-0.7768, -4.3852],\n",
      "        [-0.4247, -2.8687],\n",
      "        [ 0.0118, -1.2129],\n",
      "        [ 0.4491,  0.4278],\n",
      "        [ 0.7936,  1.9103],\n",
      "        [-0.4998, -5.1160],\n",
      "        [-0.1040, -3.6634],\n",
      "        [ 0.3318, -2.0116],\n",
      "        [ 0.7751, -0.3789],\n",
      "        [ 1.1467,  1.0852]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 243 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9258, -1.9669],\n",
      "        [-1.6264, -0.4421],\n",
      "        [-1.2123,  1.2249],\n",
      "        [-0.7589,  2.9393],\n",
      "        [-0.4384,  4.3462],\n",
      "        [-1.5260, -2.7715],\n",
      "        [-1.2321, -1.2290],\n",
      "        [-0.8166,  0.4368],\n",
      "        [-0.3747,  2.1196],\n",
      "        [-0.0534,  3.6039],\n",
      "        [-1.1243, -3.5874],\n",
      "        [-0.8114, -2.0487],\n",
      "        [-0.3913, -0.3872],\n",
      "        [ 0.0428,  1.2828],\n",
      "        [ 0.3745,  2.7705],\n",
      "        [-0.7769, -4.3857],\n",
      "        [-0.4247, -2.8681],\n",
      "        [ 0.0118, -1.2123],\n",
      "        [ 0.4488,  0.4277],\n",
      "        [ 0.7936,  1.9099],\n",
      "        [-0.5001, -5.1172],\n",
      "        [-0.1040, -3.6634],\n",
      "        [ 0.3320, -2.0109],\n",
      "        [ 0.7751, -0.3787],\n",
      "        [ 1.1469,  1.0850]], grad_fn=<AddmmBackward>)\n",
      "epoch: 244 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9257, -1.9669],\n",
      "        [-1.6262, -0.4420],\n",
      "        [-1.2124,  1.2244],\n",
      "        [-0.7593,  2.9386],\n",
      "        [-0.4382,  4.3479],\n",
      "        [-1.5259, -2.7713],\n",
      "        [-1.2318, -1.2286],\n",
      "        [-0.8166,  0.4365],\n",
      "        [-0.3751,  2.1186],\n",
      "        [-0.0531,  3.6043],\n",
      "        [-1.1243, -3.5873],\n",
      "        [-0.8113, -2.0480],\n",
      "        [-0.3913, -0.3870],\n",
      "        [ 0.0425,  1.2821],\n",
      "        [ 0.3747,  2.7703],\n",
      "        [-0.7770, -4.3861],\n",
      "        [-0.4246, -2.8676],\n",
      "        [ 0.0118, -1.2117],\n",
      "        [ 0.4485,  0.4275],\n",
      "        [ 0.7937,  1.9096],\n",
      "        [-0.5003, -5.1184],\n",
      "        [-0.1040, -3.6634],\n",
      "        [ 0.3321, -2.0102],\n",
      "        [ 0.7751, -0.3785],\n",
      "        [ 1.1470,  1.0848]], grad_fn=<AddmmBackward>)\n",
      "epoch: 245 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9256, -1.9668],\n",
      "        [-1.6261, -0.4418],\n",
      "        [-1.2125,  1.2240],\n",
      "        [-0.7596,  2.9379],\n",
      "        [-0.4381,  4.3496],\n",
      "        [-1.5259, -2.7712],\n",
      "        [-1.2315, -1.2282],\n",
      "        [-0.8165,  0.4363],\n",
      "        [-0.3754,  2.1177],\n",
      "        [-0.0529,  3.6047],\n",
      "        [-1.1244, -3.5873],\n",
      "        [-0.8112, -2.0473],\n",
      "        [-0.3913, -0.3868],\n",
      "        [ 0.0423,  1.2815],\n",
      "        [ 0.3749,  2.7701],\n",
      "        [-0.7771, -4.3866],\n",
      "        [-0.4246, -2.8670],\n",
      "        [ 0.0118, -1.2110],\n",
      "        [ 0.4482,  0.4274],\n",
      "        [ 0.7937,  1.9093],\n",
      "        [-0.5005, -5.1196],\n",
      "        [-0.1040, -3.6635],\n",
      "        [ 0.3323, -2.0094],\n",
      "        [ 0.7751, -0.3782],\n",
      "        [ 1.1472,  1.0846]], grad_fn=<AddmmBackward>)\n",
      "epoch: 246 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9256, -1.9668],\n",
      "        [-1.6259, -0.4417],\n",
      "        [-1.2126,  1.2236],\n",
      "        [-0.7600,  2.9372],\n",
      "        [-0.4379,  4.3512],\n",
      "        [-1.5258, -2.7710],\n",
      "        [-1.2312, -1.2278],\n",
      "        [-0.8165,  0.4361],\n",
      "        [-0.3758,  2.1168],\n",
      "        [-0.0526,  3.6052],\n",
      "        [-1.1244, -3.5872],\n",
      "        [-0.8110, -2.0467],\n",
      "        [-0.3914, -0.3866],\n",
      "        [ 0.0420,  1.2808],\n",
      "        [ 0.3751,  2.7698],\n",
      "        [-0.7772, -4.3871],\n",
      "        [-0.4245, -2.8665],\n",
      "        [ 0.0118, -1.2104],\n",
      "        [ 0.4480,  0.4273],\n",
      "        [ 0.7938,  1.9089],\n",
      "        [-0.5008, -5.1208],\n",
      "        [-0.1041, -3.6635],\n",
      "        [ 0.3324, -2.0087],\n",
      "        [ 0.7751, -0.3780],\n",
      "        [ 1.1474,  1.0845]], grad_fn=<AddmmBackward>)\n",
      "epoch: 247 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9255, -1.9667],\n",
      "        [-1.6258, -0.4416],\n",
      "        [-1.2127,  1.2232],\n",
      "        [-0.7604,  2.9365],\n",
      "        [-0.4377,  4.3528],\n",
      "        [-1.5258, -2.7709],\n",
      "        [-1.2309, -1.2274],\n",
      "        [-0.8165,  0.4358],\n",
      "        [-0.3761,  2.1158],\n",
      "        [-0.0524,  3.6056],\n",
      "        [-1.1245, -3.5872],\n",
      "        [-0.8109, -2.0460],\n",
      "        [-0.3914, -0.3864],\n",
      "        [ 0.0417,  1.2802],\n",
      "        [ 0.3753,  2.7696],\n",
      "        [-0.7773, -4.3876],\n",
      "        [-0.4245, -2.8659],\n",
      "        [ 0.0118, -1.2098],\n",
      "        [ 0.4477,  0.4272],\n",
      "        [ 0.7938,  1.9086],\n",
      "        [-0.5010, -5.1219],\n",
      "        [-0.1041, -3.6635],\n",
      "        [ 0.3325, -2.0080],\n",
      "        [ 0.7752, -0.3778],\n",
      "        [ 1.1476,  1.0843]], grad_fn=<AddmmBackward>)\n",
      "epoch: 248 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9255, -1.9667],\n",
      "        [-1.6256, -0.4414],\n",
      "        [-1.2128,  1.2228],\n",
      "        [-0.7607,  2.9358],\n",
      "        [-0.4375,  4.3545],\n",
      "        [-1.5257, -2.7707],\n",
      "        [-1.2306, -1.2270],\n",
      "        [-0.8164,  0.4356],\n",
      "        [-0.3765,  2.1149],\n",
      "        [-0.0521,  3.6060],\n",
      "        [-1.1245, -3.5872],\n",
      "        [-0.8108, -2.0454],\n",
      "        [-0.3914, -0.3862],\n",
      "        [ 0.0415,  1.2795],\n",
      "        [ 0.3755,  2.7693],\n",
      "        [-0.7774, -4.3880],\n",
      "        [-0.4244, -2.8654],\n",
      "        [ 0.0118, -1.2093],\n",
      "        [ 0.4474,  0.4270],\n",
      "        [ 0.7939,  1.9083],\n",
      "        [-0.5012, -5.1231],\n",
      "        [-0.1041, -3.6635],\n",
      "        [ 0.3327, -2.0073],\n",
      "        [ 0.7752, -0.3776],\n",
      "        [ 1.1477,  1.0841]], grad_fn=<AddmmBackward>)\n",
      "epoch: 249 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9255, -1.9667],\n",
      "        [-1.6255, -0.4413],\n",
      "        [-1.2128,  1.2224],\n",
      "        [-0.7611,  2.9351],\n",
      "        [-0.4373,  4.3561],\n",
      "        [-1.5256, -2.7706],\n",
      "        [-1.2303, -1.2266],\n",
      "        [-0.8164,  0.4354],\n",
      "        [-0.3768,  2.1140],\n",
      "        [-0.0519,  3.6064],\n",
      "        [-1.1245, -3.5871],\n",
      "        [-0.8107, -2.0447],\n",
      "        [-0.3915, -0.3860],\n",
      "        [ 0.0412,  1.2789],\n",
      "        [ 0.3757,  2.7691],\n",
      "        [-0.7775, -4.3885],\n",
      "        [-0.4243, -2.8649],\n",
      "        [ 0.0118, -1.2087],\n",
      "        [ 0.4472,  0.4269],\n",
      "        [ 0.7939,  1.9080],\n",
      "        [-0.5015, -5.1242],\n",
      "        [-0.1041, -3.6636],\n",
      "        [ 0.3328, -2.0066],\n",
      "        [ 0.7752, -0.3774],\n",
      "        [ 1.1479,  1.0839]], grad_fn=<AddmmBackward>)\n",
      "epoch: 250 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9254, -1.9667],\n",
      "        [-1.6253, -0.4412],\n",
      "        [-1.2129,  1.2220],\n",
      "        [-0.7615,  2.9344],\n",
      "        [-0.4371,  4.3576],\n",
      "        [-1.5256, -2.7705],\n",
      "        [-1.2300, -1.2262],\n",
      "        [-0.8164,  0.4352],\n",
      "        [-0.3772,  2.1131],\n",
      "        [-0.0516,  3.6069],\n",
      "        [-1.1246, -3.5871],\n",
      "        [-0.8105, -2.0441],\n",
      "        [-0.3915, -0.3858],\n",
      "        [ 0.0410,  1.2783],\n",
      "        [ 0.3759,  2.7689],\n",
      "        [-0.7776, -4.3889],\n",
      "        [-0.4243, -2.8643],\n",
      "        [ 0.0118, -1.2081],\n",
      "        [ 0.4469,  0.4268],\n",
      "        [ 0.7939,  1.9076],\n",
      "        [-0.5017, -5.1253],\n",
      "        [-0.1041, -3.6636],\n",
      "        [ 0.3330, -2.0059],\n",
      "        [ 0.7752, -0.3771],\n",
      "        [ 1.1481,  1.0838]], grad_fn=<AddmmBackward>)\n",
      "epoch: 251 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9254, -1.9666],\n",
      "        [-1.6252, -0.4410],\n",
      "        [-1.2130,  1.2216],\n",
      "        [-0.7618,  2.9338],\n",
      "        [-0.4369,  4.3592],\n",
      "        [-1.5255, -2.7704],\n",
      "        [-1.2297, -1.2259],\n",
      "        [-0.8164,  0.4350],\n",
      "        [-0.3775,  2.1123],\n",
      "        [-0.0514,  3.6072],\n",
      "        [-1.1246, -3.5870],\n",
      "        [-0.8104, -2.0435],\n",
      "        [-0.3915, -0.3857],\n",
      "        [ 0.0407,  1.2777],\n",
      "        [ 0.3761,  2.7686],\n",
      "        [-0.7777, -4.3893],\n",
      "        [-0.4242, -2.8638],\n",
      "        [ 0.0118, -1.2076],\n",
      "        [ 0.4466,  0.4267],\n",
      "        [ 0.7940,  1.9073],\n",
      "        [-0.5019, -5.1264],\n",
      "        [-0.1041, -3.6636],\n",
      "        [ 0.3332, -2.0053],\n",
      "        [ 0.7752, -0.3769],\n",
      "        [ 1.1483,  1.0836]], grad_fn=<AddmmBackward>)\n",
      "epoch: 252 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9254, -1.9666],\n",
      "        [-1.6250, -0.4409],\n",
      "        [-1.2131,  1.2213],\n",
      "        [-0.7622,  2.9331],\n",
      "        [-0.4367,  4.3607],\n",
      "        [-1.5255, -2.7702],\n",
      "        [-1.2295, -1.2255],\n",
      "        [-0.8163,  0.4348],\n",
      "        [-0.3778,  2.1114],\n",
      "        [-0.0511,  3.6076],\n",
      "        [-1.1246, -3.5870],\n",
      "        [-0.8103, -2.0429],\n",
      "        [-0.3916, -0.3855],\n",
      "        [ 0.0404,  1.2771],\n",
      "        [ 0.3763,  2.7684],\n",
      "        [-0.7777, -4.3898],\n",
      "        [-0.4242, -2.8633],\n",
      "        [ 0.0118, -1.2070],\n",
      "        [ 0.4464,  0.4266],\n",
      "        [ 0.7940,  1.9070],\n",
      "        [-0.5022, -5.1274],\n",
      "        [-0.1041, -3.6636],\n",
      "        [ 0.3333, -2.0046],\n",
      "        [ 0.7753, -0.3767],\n",
      "        [ 1.1485,  1.0835]], grad_fn=<AddmmBackward>)\n",
      "epoch: 253 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9253, -1.9666],\n",
      "        [-1.6249, -0.4407],\n",
      "        [-1.2132,  1.2209],\n",
      "        [-0.7625,  2.9325],\n",
      "        [-0.4365,  4.3623],\n",
      "        [-1.5254, -2.7701],\n",
      "        [-1.2292, -1.2251],\n",
      "        [-0.8163,  0.4346],\n",
      "        [-0.3782,  2.1105],\n",
      "        [-0.0509,  3.6080],\n",
      "        [-1.1247, -3.5870],\n",
      "        [-0.8102, -2.0422],\n",
      "        [-0.3916, -0.3853],\n",
      "        [ 0.0402,  1.2765],\n",
      "        [ 0.3765,  2.7681],\n",
      "        [-0.7778, -4.3902],\n",
      "        [-0.4241, -2.8628],\n",
      "        [ 0.0118, -1.2065],\n",
      "        [ 0.4461,  0.4265],\n",
      "        [ 0.7941,  1.9067],\n",
      "        [-0.5024, -5.1285],\n",
      "        [-0.1041, -3.6636],\n",
      "        [ 0.3335, -2.0040],\n",
      "        [ 0.7753, -0.3765],\n",
      "        [ 1.1486,  1.0833]], grad_fn=<AddmmBackward>)\n",
      "epoch: 254 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9253, -1.9666],\n",
      "        [-1.6247, -0.4406],\n",
      "        [-1.2133,  1.2206],\n",
      "        [-0.7629,  2.9319],\n",
      "        [-0.4363,  4.3637],\n",
      "        [-1.5254, -2.7700],\n",
      "        [-1.2289, -1.2248],\n",
      "        [-0.8163,  0.4344],\n",
      "        [-0.3785,  2.1097],\n",
      "        [-0.0506,  3.6084],\n",
      "        [-1.1247, -3.5869],\n",
      "        [-0.8101, -2.0416],\n",
      "        [-0.3917, -0.3851],\n",
      "        [ 0.0399,  1.2759],\n",
      "        [ 0.3767,  2.7678],\n",
      "        [-0.7779, -4.3906],\n",
      "        [-0.4240, -2.8623],\n",
      "        [ 0.0117, -1.2059],\n",
      "        [ 0.4458,  0.4264],\n",
      "        [ 0.7941,  1.9064],\n",
      "        [-0.5026, -5.1295],\n",
      "        [-0.1041, -3.6636],\n",
      "        [ 0.3336, -2.0033],\n",
      "        [ 0.7753, -0.3763],\n",
      "        [ 1.1488,  1.0831]], grad_fn=<AddmmBackward>)\n",
      "epoch: 255 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9253, -1.9666],\n",
      "        [-1.6246, -0.4405],\n",
      "        [-1.2134,  1.2202],\n",
      "        [-0.7632,  2.9312],\n",
      "        [-0.4361,  4.3652],\n",
      "        [-1.5253, -2.7699],\n",
      "        [-1.2286, -1.2244],\n",
      "        [-0.8163,  0.4341],\n",
      "        [-0.3788,  2.1089],\n",
      "        [-0.0504,  3.6087],\n",
      "        [-1.1247, -3.5869],\n",
      "        [-0.8099, -2.0410],\n",
      "        [-0.3917, -0.3850],\n",
      "        [ 0.0397,  1.2753],\n",
      "        [ 0.3769,  2.7676],\n",
      "        [-0.7780, -4.3910],\n",
      "        [-0.4240, -2.8618],\n",
      "        [ 0.0117, -1.2054],\n",
      "        [ 0.4455,  0.4263],\n",
      "        [ 0.7941,  1.9061],\n",
      "        [-0.5028, -5.1305],\n",
      "        [-0.1041, -3.6636],\n",
      "        [ 0.3338, -2.0027],\n",
      "        [ 0.7753, -0.3761],\n",
      "        [ 1.1490,  1.0830]], grad_fn=<AddmmBackward>)\n",
      "epoch: 256 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9253, -1.9666],\n",
      "        [-1.6244, -0.4403],\n",
      "        [-1.2134,  1.2199],\n",
      "        [-0.7636,  2.9306],\n",
      "        [-0.4359,  4.3667],\n",
      "        [-1.5252, -2.7698],\n",
      "        [-1.2283, -1.2241],\n",
      "        [-0.8163,  0.4339],\n",
      "        [-0.3792,  2.1080],\n",
      "        [-0.0501,  3.6091],\n",
      "        [-1.1247, -3.5869],\n",
      "        [-0.8098, -2.0405],\n",
      "        [-0.3918, -0.3848],\n",
      "        [ 0.0394,  1.2747],\n",
      "        [ 0.3771,  2.7673],\n",
      "        [-0.7781, -4.3914],\n",
      "        [-0.4239, -2.8613],\n",
      "        [ 0.0117, -1.2049],\n",
      "        [ 0.4453,  0.4262],\n",
      "        [ 0.7942,  1.9058],\n",
      "        [-0.5031, -5.1315],\n",
      "        [-0.1041, -3.6636],\n",
      "        [ 0.3339, -2.0021],\n",
      "        [ 0.7753, -0.3759],\n",
      "        [ 1.1492,  1.0829]], grad_fn=<AddmmBackward>)\n",
      "epoch: 257 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9253, -1.9666],\n",
      "        [-1.6243, -0.4402],\n",
      "        [-1.2135,  1.2195],\n",
      "        [-0.7639,  2.9300],\n",
      "        [-0.4358,  4.3681],\n",
      "        [-1.5252, -2.7697],\n",
      "        [-1.2281, -1.2237],\n",
      "        [-0.8162,  0.4337],\n",
      "        [-0.3795,  2.1072],\n",
      "        [-0.0499,  3.6094],\n",
      "        [-1.1248, -3.5868],\n",
      "        [-0.8097, -2.0399],\n",
      "        [-0.3918, -0.3847],\n",
      "        [ 0.0391,  1.2741],\n",
      "        [ 0.3773,  2.7670],\n",
      "        [-0.7782, -4.3918],\n",
      "        [-0.4238, -2.8609],\n",
      "        [ 0.0117, -1.2044],\n",
      "        [ 0.4450,  0.4261],\n",
      "        [ 0.7942,  1.9055],\n",
      "        [-0.5033, -5.1325],\n",
      "        [-0.1041, -3.6636],\n",
      "        [ 0.3341, -2.0015],\n",
      "        [ 0.7754, -0.3758],\n",
      "        [ 1.1494,  1.0827]], grad_fn=<AddmmBackward>)\n",
      "epoch: 258 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9252, -1.9666],\n",
      "        [-1.6241, -0.4401],\n",
      "        [-1.2136,  1.2192],\n",
      "        [-0.7643,  2.9294],\n",
      "        [-0.4356,  4.3696],\n",
      "        [-1.5251, -2.7696],\n",
      "        [-1.2278, -1.2234],\n",
      "        [-0.8162,  0.4335],\n",
      "        [-0.3798,  2.1064],\n",
      "        [-0.0497,  3.6098],\n",
      "        [-1.1248, -3.5868],\n",
      "        [-0.8096, -2.0393],\n",
      "        [-0.3919, -0.3845],\n",
      "        [ 0.0389,  1.2736],\n",
      "        [ 0.3775,  2.7667],\n",
      "        [-0.7782, -4.3921],\n",
      "        [-0.4237, -2.8604],\n",
      "        [ 0.0117, -1.2039],\n",
      "        [ 0.4447,  0.4260],\n",
      "        [ 0.7942,  1.9052],\n",
      "        [-0.5035, -5.1334],\n",
      "        [-0.1041, -3.6636],\n",
      "        [ 0.3343, -2.0009],\n",
      "        [ 0.7754, -0.3756],\n",
      "        [ 1.1495,  1.0826]], grad_fn=<AddmmBackward>)\n",
      "epoch: 259 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9252, -1.9666],\n",
      "        [-1.6240, -0.4399],\n",
      "        [-1.2137,  1.2189],\n",
      "        [-0.7646,  2.9288],\n",
      "        [-0.4353,  4.3710],\n",
      "        [-1.5251, -2.7695],\n",
      "        [-1.2275, -1.2231],\n",
      "        [-0.8162,  0.4333],\n",
      "        [-0.3801,  2.1057],\n",
      "        [-0.0494,  3.6101],\n",
      "        [-1.1248, -3.5867],\n",
      "        [-0.8094, -2.0387],\n",
      "        [-0.3919, -0.3844],\n",
      "        [ 0.0386,  1.2730],\n",
      "        [ 0.3776,  2.7665],\n",
      "        [-0.7783, -4.3925],\n",
      "        [-0.4237, -2.8599],\n",
      "        [ 0.0117, -1.2034],\n",
      "        [ 0.4444,  0.4259],\n",
      "        [ 0.7942,  1.9049],\n",
      "        [-0.5038, -5.1344],\n",
      "        [-0.1041, -3.6636],\n",
      "        [ 0.3344, -2.0003],\n",
      "        [ 0.7754, -0.3754],\n",
      "        [ 1.1497,  1.0825]], grad_fn=<AddmmBackward>)\n",
      "epoch: 260 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9252, -1.9666],\n",
      "        [-1.6238, -0.4398],\n",
      "        [-1.2138,  1.2186],\n",
      "        [-0.7650,  2.9283],\n",
      "        [-0.4351,  4.3724],\n",
      "        [-1.5250, -2.7694],\n",
      "        [-1.2272, -1.2227],\n",
      "        [-0.8162,  0.4331],\n",
      "        [-0.3804,  2.1049],\n",
      "        [-0.0492,  3.6104],\n",
      "        [-1.1248, -3.5867],\n",
      "        [-0.8093, -2.0382],\n",
      "        [-0.3920, -0.3842],\n",
      "        [ 0.0384,  1.2725],\n",
      "        [ 0.3778,  2.7662],\n",
      "        [-0.7784, -4.3929],\n",
      "        [-0.4236, -2.8595],\n",
      "        [ 0.0117, -1.2029],\n",
      "        [ 0.4442,  0.4258],\n",
      "        [ 0.7943,  1.9046],\n",
      "        [-0.5040, -5.1353],\n",
      "        [-0.1041, -3.6636],\n",
      "        [ 0.3346, -1.9997],\n",
      "        [ 0.7754, -0.3752],\n",
      "        [ 1.1499,  1.0823]], grad_fn=<AddmmBackward>)\n",
      "epoch: 261 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9252, -1.9666],\n",
      "        [-1.6237, -0.4397],\n",
      "        [-1.2138,  1.2183],\n",
      "        [-0.7653,  2.9277],\n",
      "        [-0.4349,  4.3738],\n",
      "        [-1.5250, -2.7693],\n",
      "        [-1.2270, -1.2224],\n",
      "        [-0.8162,  0.4329],\n",
      "        [-0.3807,  2.1041],\n",
      "        [-0.0490,  3.6107],\n",
      "        [-1.1248, -3.5867],\n",
      "        [-0.8092, -2.0376],\n",
      "        [-0.3920, -0.3841],\n",
      "        [ 0.0381,  1.2719],\n",
      "        [ 0.3780,  2.7659],\n",
      "        [-0.7784, -4.3932],\n",
      "        [-0.4235, -2.8590],\n",
      "        [ 0.0117, -1.2024],\n",
      "        [ 0.4439,  0.4258],\n",
      "        [ 0.7943,  1.9044],\n",
      "        [-0.5042, -5.1362],\n",
      "        [-0.1041, -3.6636],\n",
      "        [ 0.3348, -1.9991],\n",
      "        [ 0.7755, -0.3750],\n",
      "        [ 1.1501,  1.0822]], grad_fn=<AddmmBackward>)\n",
      "epoch: 262 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9252, -1.9666],\n",
      "        [-1.6235, -0.4395],\n",
      "        [-1.2139,  1.2180],\n",
      "        [-0.7656,  2.9272],\n",
      "        [-0.4347,  4.3751],\n",
      "        [-1.5249, -2.7692],\n",
      "        [-1.2267, -1.2221],\n",
      "        [-0.8162,  0.4328],\n",
      "        [-0.3811,  2.1034],\n",
      "        [-0.0487,  3.6110],\n",
      "        [-1.1248, -3.5867],\n",
      "        [-0.8091, -2.0371],\n",
      "        [-0.3921, -0.3840],\n",
      "        [ 0.0379,  1.2714],\n",
      "        [ 0.3781,  2.7656],\n",
      "        [-0.7785, -4.3936],\n",
      "        [-0.4234, -2.8586],\n",
      "        [ 0.0116, -1.2020],\n",
      "        [ 0.4436,  0.4257],\n",
      "        [ 0.7943,  1.9041],\n",
      "        [-0.5045, -5.1371],\n",
      "        [-0.1041, -3.6636],\n",
      "        [ 0.3349, -1.9986],\n",
      "        [ 0.7755, -0.3749],\n",
      "        [ 1.1502,  1.0821]], grad_fn=<AddmmBackward>)\n",
      "epoch: 263 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9252, -1.9666],\n",
      "        [-1.6234, -0.4394],\n",
      "        [-1.2140,  1.2178],\n",
      "        [-0.7659,  2.9266],\n",
      "        [-0.4345,  4.3765],\n",
      "        [-1.5249, -2.7691],\n",
      "        [-1.2265, -1.2218],\n",
      "        [-0.8162,  0.4326],\n",
      "        [-0.3814,  2.1026],\n",
      "        [-0.0485,  3.6113],\n",
      "        [-1.1248, -3.5866],\n",
      "        [-0.8089, -2.0365],\n",
      "        [-0.3921, -0.3838],\n",
      "        [ 0.0376,  1.2709],\n",
      "        [ 0.3783,  2.7653],\n",
      "        [-0.7786, -4.3940],\n",
      "        [-0.4234, -2.8582],\n",
      "        [ 0.0116, -1.2015],\n",
      "        [ 0.4433,  0.4256],\n",
      "        [ 0.7943,  1.9038],\n",
      "        [-0.5047, -5.1380],\n",
      "        [-0.1041, -3.6636],\n",
      "        [ 0.3351, -1.9980],\n",
      "        [ 0.7755, -0.3747],\n",
      "        [ 1.1504,  1.0820]], grad_fn=<AddmmBackward>)\n",
      "epoch: 264 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9252, -1.9666],\n",
      "        [-1.6233, -0.4393],\n",
      "        [-1.2141,  1.2175],\n",
      "        [-0.7663,  2.9261],\n",
      "        [-0.4343,  4.3778],\n",
      "        [-1.5248, -2.7690],\n",
      "        [-1.2262, -1.2215],\n",
      "        [-0.8162,  0.4324],\n",
      "        [-0.3817,  2.1019],\n",
      "        [-0.0483,  3.6116],\n",
      "        [-1.1249, -3.5866],\n",
      "        [-0.8088, -2.0360],\n",
      "        [-0.3922, -0.3837],\n",
      "        [ 0.0374,  1.2704],\n",
      "        [ 0.3785,  2.7650],\n",
      "        [-0.7787, -4.3943],\n",
      "        [-0.4233, -2.8577],\n",
      "        [ 0.0116, -1.2011],\n",
      "        [ 0.4431,  0.4255],\n",
      "        [ 0.7943,  1.9035],\n",
      "        [-0.5049, -5.1389],\n",
      "        [-0.1041, -3.6636],\n",
      "        [ 0.3352, -1.9975],\n",
      "        [ 0.7755, -0.3745],\n",
      "        [ 1.1506,  1.0819]], grad_fn=<AddmmBackward>)\n",
      "epoch: 265 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9252, -1.9667],\n",
      "        [-1.6231, -0.4391],\n",
      "        [-1.2141,  1.2172],\n",
      "        [-0.7666,  2.9256],\n",
      "        [-0.4341,  4.3792],\n",
      "        [-1.5248, -2.7689],\n",
      "        [-1.2259, -1.2212],\n",
      "        [-0.8162,  0.4322],\n",
      "        [-0.3820,  2.1012],\n",
      "        [-0.0481,  3.6119],\n",
      "        [-1.1249, -3.5866],\n",
      "        [-0.8087, -2.0355],\n",
      "        [-0.3922, -0.3836],\n",
      "        [ 0.0371,  1.2698],\n",
      "        [ 0.3786,  2.7647],\n",
      "        [-0.7787, -4.3946],\n",
      "        [-0.4232, -2.8573],\n",
      "        [ 0.0116, -1.2006],\n",
      "        [ 0.4428,  0.4255],\n",
      "        [ 0.7944,  1.9033],\n",
      "        [-0.5052, -5.1397],\n",
      "        [-0.1040, -3.6636],\n",
      "        [ 0.3354, -1.9970],\n",
      "        [ 0.7756, -0.3744],\n",
      "        [ 1.1508,  1.0818]], grad_fn=<AddmmBackward>)\n",
      "epoch: 266 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9252, -1.9667],\n",
      "        [-1.6230, -0.4390],\n",
      "        [-1.2142,  1.2170],\n",
      "        [-0.7669,  2.9251],\n",
      "        [-0.4339,  4.3805],\n",
      "        [-1.5247, -2.7688],\n",
      "        [-1.2257, -1.2209],\n",
      "        [-0.8161,  0.4320],\n",
      "        [-0.3822,  2.1005],\n",
      "        [-0.0479,  3.6122],\n",
      "        [-1.1249, -3.5865],\n",
      "        [-0.8086, -2.0350],\n",
      "        [-0.3923, -0.3835],\n",
      "        [ 0.0369,  1.2693],\n",
      "        [ 0.3788,  2.7644],\n",
      "        [-0.7788, -4.3950],\n",
      "        [-0.4231, -2.8569],\n",
      "        [ 0.0116, -1.2002],\n",
      "        [ 0.4425,  0.4254],\n",
      "        [ 0.7944,  1.9030],\n",
      "        [-0.5054, -5.1406],\n",
      "        [-0.1040, -3.6636],\n",
      "        [ 0.3356, -1.9964],\n",
      "        [ 0.7756, -0.3742],\n",
      "        [ 1.1509,  1.0817]], grad_fn=<AddmmBackward>)\n",
      "epoch: 267 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9252, -1.9667],\n",
      "        [-1.6228, -0.4389],\n",
      "        [-1.2143,  1.2167],\n",
      "        [-0.7672,  2.9245],\n",
      "        [-0.4337,  4.3817],\n",
      "        [-1.5247, -2.7688],\n",
      "        [-1.2254, -1.2206],\n",
      "        [-0.8161,  0.4318],\n",
      "        [-0.3825,  2.0998],\n",
      "        [-0.0476,  3.6125],\n",
      "        [-1.1249, -3.5865],\n",
      "        [-0.8085, -2.0344],\n",
      "        [-0.3923, -0.3833],\n",
      "        [ 0.0367,  1.2688],\n",
      "        [ 0.3790,  2.7641],\n",
      "        [-0.7789, -4.3953],\n",
      "        [-0.4230, -2.8565],\n",
      "        [ 0.0115, -1.1998],\n",
      "        [ 0.4422,  0.4254],\n",
      "        [ 0.7944,  1.9028],\n",
      "        [-0.5056, -5.1414],\n",
      "        [-0.1040, -3.6635],\n",
      "        [ 0.3358, -1.9959],\n",
      "        [ 0.7756, -0.3740],\n",
      "        [ 1.1511,  1.0816]], grad_fn=<AddmmBackward>)\n",
      "epoch: 268 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9252, -1.9667],\n",
      "        [-1.6227, -0.4387],\n",
      "        [-1.2143,  1.2165],\n",
      "        [-0.7675,  2.9240],\n",
      "        [-0.4335,  4.3830],\n",
      "        [-1.5246, -2.7687],\n",
      "        [-1.2252, -1.2203],\n",
      "        [-0.8161,  0.4316],\n",
      "        [-0.3828,  2.0991],\n",
      "        [-0.0474,  3.6127],\n",
      "        [-1.1249, -3.5865],\n",
      "        [-0.8083, -2.0339],\n",
      "        [-0.3924, -0.3832],\n",
      "        [ 0.0364,  1.2683],\n",
      "        [ 0.3791,  2.7638],\n",
      "        [-0.7789, -4.3956],\n",
      "        [-0.4229, -2.8560],\n",
      "        [ 0.0115, -1.1993],\n",
      "        [ 0.4419,  0.4253],\n",
      "        [ 0.7944,  1.9025],\n",
      "        [-0.5058, -5.1422],\n",
      "        [-0.1040, -3.6635],\n",
      "        [ 0.3359, -1.9954],\n",
      "        [ 0.7757, -0.3739],\n",
      "        [ 1.1513,  1.0816]], grad_fn=<AddmmBackward>)\n",
      "epoch: 269 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9252, -1.9667],\n",
      "        [-1.6226, -0.4386],\n",
      "        [-1.2144,  1.2162],\n",
      "        [-0.7678,  2.9235],\n",
      "        [-0.4333,  4.3843],\n",
      "        [-1.5246, -2.7686],\n",
      "        [-1.2249, -1.2200],\n",
      "        [-0.8161,  0.4314],\n",
      "        [-0.3831,  2.0984],\n",
      "        [-0.0472,  3.6130],\n",
      "        [-1.1249, -3.5864],\n",
      "        [-0.8082, -2.0334],\n",
      "        [-0.3925, -0.3831],\n",
      "        [ 0.0362,  1.2678],\n",
      "        [ 0.3793,  2.7635],\n",
      "        [-0.7790, -4.3959],\n",
      "        [-0.4229, -2.8556],\n",
      "        [ 0.0115, -1.1989],\n",
      "        [ 0.4417,  0.4253],\n",
      "        [ 0.7944,  1.9022],\n",
      "        [-0.5061, -5.1430],\n",
      "        [-0.1040, -3.6635],\n",
      "        [ 0.3361, -1.9949],\n",
      "        [ 0.7757, -0.3737],\n",
      "        [ 1.1515,  1.0815]], grad_fn=<AddmmBackward>)\n",
      "epoch: 270 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9252, -1.9668],\n",
      "        [-1.6224, -0.4385],\n",
      "        [-1.2145,  1.2160],\n",
      "        [-0.7681,  2.9231],\n",
      "        [-0.4331,  4.3855],\n",
      "        [-1.5245, -2.7685],\n",
      "        [-1.2247, -1.2198],\n",
      "        [-0.8161,  0.4313],\n",
      "        [-0.3834,  2.0977],\n",
      "        [-0.0470,  3.6133],\n",
      "        [-1.1249, -3.5864],\n",
      "        [-0.8081, -2.0329],\n",
      "        [-0.3925, -0.3830],\n",
      "        [ 0.0359,  1.2673],\n",
      "        [ 0.3794,  2.7632],\n",
      "        [-0.7790, -4.3962],\n",
      "        [-0.4228, -2.8552],\n",
      "        [ 0.0115, -1.1985],\n",
      "        [ 0.4414,  0.4252],\n",
      "        [ 0.7944,  1.9020],\n",
      "        [-0.5063, -5.1438],\n",
      "        [-0.1040, -3.6635],\n",
      "        [ 0.3363, -1.9944],\n",
      "        [ 0.7757, -0.3736],\n",
      "        [ 1.1516,  1.0814]], grad_fn=<AddmmBackward>)\n",
      "epoch: 271 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9253, -1.9668],\n",
      "        [-1.6223, -0.4384],\n",
      "        [-1.2145,  1.2157],\n",
      "        [-0.7684,  2.9226],\n",
      "        [-0.4328,  4.3867],\n",
      "        [-1.5245, -2.7685],\n",
      "        [-1.2244, -1.2195],\n",
      "        [-0.8161,  0.4311],\n",
      "        [-0.3837,  2.0970],\n",
      "        [-0.0468,  3.6135],\n",
      "        [-1.1249, -3.5864],\n",
      "        [-0.8080, -2.0325],\n",
      "        [-0.3926, -0.3829],\n",
      "        [ 0.0357,  1.2669],\n",
      "        [ 0.3796,  2.7629],\n",
      "        [-0.7791, -4.3965],\n",
      "        [-0.4227, -2.8548],\n",
      "        [ 0.0114, -1.1981],\n",
      "        [ 0.4411,  0.4252],\n",
      "        [ 0.7944,  1.9018],\n",
      "        [-0.5065, -5.1446],\n",
      "        [-0.1040, -3.6635],\n",
      "        [ 0.3365, -1.9939],\n",
      "        [ 0.7758, -0.3734],\n",
      "        [ 1.1518,  1.0813]], grad_fn=<AddmmBackward>)\n",
      "epoch: 272 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9253, -1.9668],\n",
      "        [-1.6222, -0.4382],\n",
      "        [-1.2146,  1.2155],\n",
      "        [-0.7687,  2.9221],\n",
      "        [-0.4326,  4.3879],\n",
      "        [-1.5245, -2.7684],\n",
      "        [-1.2242, -1.2192],\n",
      "        [-0.8161,  0.4309],\n",
      "        [-0.3840,  2.0964],\n",
      "        [-0.0466,  3.6137],\n",
      "        [-1.1249, -3.5863],\n",
      "        [-0.8079, -2.0320],\n",
      "        [-0.3926, -0.3828],\n",
      "        [ 0.0354,  1.2664],\n",
      "        [ 0.3797,  2.7626],\n",
      "        [-0.7791, -4.3968],\n",
      "        [-0.4226, -2.8545],\n",
      "        [ 0.0114, -1.1977],\n",
      "        [ 0.4408,  0.4251],\n",
      "        [ 0.7944,  1.9015],\n",
      "        [-0.5068, -5.1453],\n",
      "        [-0.1039, -3.6634],\n",
      "        [ 0.3367, -1.9935],\n",
      "        [ 0.7758, -0.3732],\n",
      "        [ 1.1520,  1.0813]], grad_fn=<AddmmBackward>)\n",
      "epoch: 273 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9253, -1.9669],\n",
      "        [-1.6220, -0.4381],\n",
      "        [-1.2147,  1.2153],\n",
      "        [-0.7690,  2.9217],\n",
      "        [-0.4324,  4.3891],\n",
      "        [-1.5244, -2.7683],\n",
      "        [-1.2239, -1.2190],\n",
      "        [-0.8161,  0.4307],\n",
      "        [-0.3842,  2.0957],\n",
      "        [-0.0464,  3.6140],\n",
      "        [-1.1249, -3.5863],\n",
      "        [-0.8077, -2.0315],\n",
      "        [-0.3927, -0.3827],\n",
      "        [ 0.0352,  1.2659],\n",
      "        [ 0.3799,  2.7622],\n",
      "        [-0.7792, -4.3971],\n",
      "        [-0.4225, -2.8541],\n",
      "        [ 0.0114, -1.1974],\n",
      "        [ 0.4406,  0.4251],\n",
      "        [ 0.7944,  1.9013],\n",
      "        [-0.5070, -5.1461],\n",
      "        [-0.1039, -3.6634],\n",
      "        [ 0.3368, -1.9930],\n",
      "        [ 0.7758, -0.3731],\n",
      "        [ 1.1522,  1.0812]], grad_fn=<AddmmBackward>)\n",
      "epoch: 274 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9253, -1.9669],\n",
      "        [-1.6219, -0.4380],\n",
      "        [-1.2147,  1.2151],\n",
      "        [-0.7692,  2.9212],\n",
      "        [-0.4322,  4.3903],\n",
      "        [-1.5244, -2.7683],\n",
      "        [-1.2237, -1.2187],\n",
      "        [-0.8161,  0.4305],\n",
      "        [-0.3845,  2.0951],\n",
      "        [-0.0462,  3.6142],\n",
      "        [-1.1249, -3.5863],\n",
      "        [-0.8076, -2.0310],\n",
      "        [-0.3928, -0.3826],\n",
      "        [ 0.0350,  1.2655],\n",
      "        [ 0.3800,  2.7619],\n",
      "        [-0.7792, -4.3974],\n",
      "        [-0.4224, -2.8537],\n",
      "        [ 0.0114, -1.1970],\n",
      "        [ 0.4403,  0.4251],\n",
      "        [ 0.7944,  1.9010],\n",
      "        [-0.5072, -5.1468],\n",
      "        [-0.1039, -3.6634],\n",
      "        [ 0.3370, -1.9926],\n",
      "        [ 0.7759, -0.3730],\n",
      "        [ 1.1523,  1.0812]], grad_fn=<AddmmBackward>)\n",
      "epoch: 275 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9254, -1.9669],\n",
      "        [-1.6218, -0.4378],\n",
      "        [-1.2148,  1.2149],\n",
      "        [-0.7695,  2.9208],\n",
      "        [-0.4320,  4.3915],\n",
      "        [-1.5243, -2.7682],\n",
      "        [-1.2235, -1.2185],\n",
      "        [-0.8161,  0.4304],\n",
      "        [-0.3848,  2.0945],\n",
      "        [-0.0460,  3.6144],\n",
      "        [-1.1249, -3.5863],\n",
      "        [-0.8075, -2.0306],\n",
      "        [-0.3928, -0.3826],\n",
      "        [ 0.0347,  1.2650],\n",
      "        [ 0.3801,  2.7616],\n",
      "        [-0.7793, -4.3976],\n",
      "        [-0.4223, -2.8533],\n",
      "        [ 0.0113, -1.1966],\n",
      "        [ 0.4400,  0.4250],\n",
      "        [ 0.7944,  1.9008],\n",
      "        [-0.5074, -5.1475],\n",
      "        [-0.1039, -3.6634],\n",
      "        [ 0.3372, -1.9921],\n",
      "        [ 0.7759, -0.3728],\n",
      "        [ 1.1525,  1.0811]], grad_fn=<AddmmBackward>)\n",
      "epoch: 276 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9254, -1.9670],\n",
      "        [-1.6216, -0.4377],\n",
      "        [-1.2148,  1.2147],\n",
      "        [-0.7698,  2.9203],\n",
      "        [-0.4318,  4.3927],\n",
      "        [-1.5243, -2.7682],\n",
      "        [-1.2232, -1.2182],\n",
      "        [-0.8161,  0.4302],\n",
      "        [-0.3851,  2.0939],\n",
      "        [-0.0458,  3.6146],\n",
      "        [-1.1248, -3.5862],\n",
      "        [-0.8074, -2.0301],\n",
      "        [-0.3929, -0.3825],\n",
      "        [ 0.0345,  1.2646],\n",
      "        [ 0.3803,  2.7613],\n",
      "        [-0.7793, -4.3979],\n",
      "        [-0.4222, -2.8530],\n",
      "        [ 0.0113, -1.1962],\n",
      "        [ 0.4398,  0.4250],\n",
      "        [ 0.7944,  1.9006],\n",
      "        [-0.5077, -5.1483],\n",
      "        [-0.1039, -3.6634],\n",
      "        [ 0.3374, -1.9917],\n",
      "        [ 0.7760, -0.3727],\n",
      "        [ 1.1527,  1.0811]], grad_fn=<AddmmBackward>)\n",
      "epoch: 277 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9254, -1.9670],\n",
      "        [-1.6215, -0.4376],\n",
      "        [-1.2149,  1.2145],\n",
      "        [-0.7701,  2.9199],\n",
      "        [-0.4316,  4.3938],\n",
      "        [-1.5243, -2.7681],\n",
      "        [-1.2230, -1.2180],\n",
      "        [-0.8161,  0.4300],\n",
      "        [-0.3853,  2.0932],\n",
      "        [-0.0457,  3.6149],\n",
      "        [-1.1248, -3.5862],\n",
      "        [-0.8072, -2.0296],\n",
      "        [-0.3930, -0.3824],\n",
      "        [ 0.0343,  1.2641],\n",
      "        [ 0.3804,  2.7609],\n",
      "        [-0.7794, -4.3982],\n",
      "        [-0.4221, -2.8526],\n",
      "        [ 0.0113, -1.1959],\n",
      "        [ 0.4395,  0.4250],\n",
      "        [ 0.7944,  1.9004],\n",
      "        [-0.5079, -5.1490],\n",
      "        [-0.1038, -3.6634],\n",
      "        [ 0.3376, -1.9913],\n",
      "        [ 0.7760, -0.3725],\n",
      "        [ 1.1529,  1.0811]], grad_fn=<AddmmBackward>)\n",
      "epoch: 278 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9255, -1.9670],\n",
      "        [-1.6214, -0.4375],\n",
      "        [-1.2150,  1.2143],\n",
      "        [-0.7703,  2.9195],\n",
      "        [-0.4314,  4.3949],\n",
      "        [-1.5242, -2.7680],\n",
      "        [-1.2227, -1.2177],\n",
      "        [-0.8161,  0.4299],\n",
      "        [-0.3856,  2.0926],\n",
      "        [-0.0455,  3.6151],\n",
      "        [-1.1248, -3.5862],\n",
      "        [-0.8071, -2.0292],\n",
      "        [-0.3930, -0.3823],\n",
      "        [ 0.0340,  1.2637],\n",
      "        [ 0.3805,  2.7606],\n",
      "        [-0.7794, -4.3984],\n",
      "        [-0.4220, -2.8523],\n",
      "        [ 0.0112, -1.1955],\n",
      "        [ 0.4392,  0.4249],\n",
      "        [ 0.7944,  1.9002],\n",
      "        [-0.5081, -5.1497],\n",
      "        [-0.1038, -3.6634],\n",
      "        [ 0.3377, -1.9909],\n",
      "        [ 0.7760, -0.3724],\n",
      "        [ 1.1531,  1.0810]], grad_fn=<AddmmBackward>)\n",
      "epoch: 279 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9255, -1.9671],\n",
      "        [-1.6212, -0.4373],\n",
      "        [-1.2150,  1.2141],\n",
      "        [-0.7706,  2.9191],\n",
      "        [-0.4312,  4.3960],\n",
      "        [-1.5242, -2.7680],\n",
      "        [-1.2225, -1.2175],\n",
      "        [-0.8161,  0.4297],\n",
      "        [-0.3859,  2.0921],\n",
      "        [-0.0453,  3.6153],\n",
      "        [-1.1248, -3.5861],\n",
      "        [-0.8070, -2.0288],\n",
      "        [-0.3931, -0.3822],\n",
      "        [ 0.0338,  1.2633],\n",
      "        [ 0.3807,  2.7603],\n",
      "        [-0.7795, -4.3987],\n",
      "        [-0.4219, -2.8519],\n",
      "        [ 0.0112, -1.1952],\n",
      "        [ 0.4390,  0.4249],\n",
      "        [ 0.7943,  1.8999],\n",
      "        [-0.5084, -5.1504],\n",
      "        [-0.1038, -3.6633],\n",
      "        [ 0.3379, -1.9905],\n",
      "        [ 0.7761, -0.3723],\n",
      "        [ 1.1532,  1.0810]], grad_fn=<AddmmBackward>)\n",
      "epoch: 280 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9256, -1.9671],\n",
      "        [-1.6211, -0.4372],\n",
      "        [-1.2151,  1.2139],\n",
      "        [-0.7708,  2.9187],\n",
      "        [-0.4310,  4.3971],\n",
      "        [-1.5241, -2.7679],\n",
      "        [-1.2223, -1.2173],\n",
      "        [-0.8161,  0.4295],\n",
      "        [-0.3861,  2.0915],\n",
      "        [-0.0451,  3.6155],\n",
      "        [-1.1248, -3.5861],\n",
      "        [-0.8069, -2.0283],\n",
      "        [-0.3932, -0.3821],\n",
      "        [ 0.0336,  1.2628],\n",
      "        [ 0.3808,  2.7599],\n",
      "        [-0.7795, -4.3989],\n",
      "        [-0.4218, -2.8516],\n",
      "        [ 0.0112, -1.1949],\n",
      "        [ 0.4387,  0.4249],\n",
      "        [ 0.7943,  1.8997],\n",
      "        [-0.5086, -5.1510],\n",
      "        [-0.1038, -3.6633],\n",
      "        [ 0.3381, -1.9901],\n",
      "        [ 0.7761, -0.3721],\n",
      "        [ 1.1534,  1.0810]], grad_fn=<AddmmBackward>)\n",
      "epoch: 281 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9256, -1.9672],\n",
      "        [-1.6210, -0.4371],\n",
      "        [-1.2151,  1.2137],\n",
      "        [-0.7711,  2.9183],\n",
      "        [-0.4308,  4.3982],\n",
      "        [-1.5241, -2.7679],\n",
      "        [-1.2221, -1.2170],\n",
      "        [-0.8161,  0.4294],\n",
      "        [-0.3864,  2.0909],\n",
      "        [-0.0449,  3.6156],\n",
      "        [-1.1248, -3.5861],\n",
      "        [-0.8068, -2.0279],\n",
      "        [-0.3932, -0.3821],\n",
      "        [ 0.0334,  1.2624],\n",
      "        [ 0.3809,  2.7596],\n",
      "        [-0.7796, -4.3992],\n",
      "        [-0.4217, -2.8512],\n",
      "        [ 0.0111, -1.1945],\n",
      "        [ 0.4384,  0.4249],\n",
      "        [ 0.7943,  1.8995],\n",
      "        [-0.5088, -5.1517],\n",
      "        [-0.1037, -3.6633],\n",
      "        [ 0.3383, -1.9897],\n",
      "        [ 0.7762, -0.3720],\n",
      "        [ 1.1536,  1.0810]], grad_fn=<AddmmBackward>)\n",
      "epoch: 282 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9257, -1.9672],\n",
      "        [-1.6209, -0.4370],\n",
      "        [-1.2152,  1.2136],\n",
      "        [-0.7713,  2.9179],\n",
      "        [-0.4306,  4.3993],\n",
      "        [-1.5241, -2.7678],\n",
      "        [-1.2218, -1.2168],\n",
      "        [-0.8161,  0.4292],\n",
      "        [-0.3866,  2.0903],\n",
      "        [-0.0448,  3.6158],\n",
      "        [-1.1248, -3.5861],\n",
      "        [-0.8067, -2.0275],\n",
      "        [-0.3933, -0.3820],\n",
      "        [ 0.0331,  1.2620],\n",
      "        [ 0.3810,  2.7592],\n",
      "        [-0.7796, -4.3994],\n",
      "        [-0.4216, -2.8509],\n",
      "        [ 0.0111, -1.1942],\n",
      "        [ 0.4381,  0.4249],\n",
      "        [ 0.7943,  1.8993],\n",
      "        [-0.5091, -5.1524],\n",
      "        [-0.1037, -3.6633],\n",
      "        [ 0.3385, -1.9893],\n",
      "        [ 0.7762, -0.3719],\n",
      "        [ 1.1538,  1.0810]], grad_fn=<AddmmBackward>)\n",
      "epoch: 283 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9257, -1.9673],\n",
      "        [-1.6207, -0.4368],\n",
      "        [-1.2152,  1.2134],\n",
      "        [-0.7716,  2.9175],\n",
      "        [-0.4304,  4.4004],\n",
      "        [-1.5240, -2.7678],\n",
      "        [-1.2216, -1.2166],\n",
      "        [-0.8161,  0.4290],\n",
      "        [-0.3869,  2.0897],\n",
      "        [-0.0446,  3.6160],\n",
      "        [-1.1248, -3.5860],\n",
      "        [-0.8065, -2.0270],\n",
      "        [-0.3934, -0.3819],\n",
      "        [ 0.0329,  1.2616],\n",
      "        [ 0.3811,  2.7589],\n",
      "        [-0.7797, -4.3996],\n",
      "        [-0.4215, -2.8506],\n",
      "        [ 0.0111, -1.1939],\n",
      "        [ 0.4379,  0.4249],\n",
      "        [ 0.7943,  1.8991],\n",
      "        [-0.5093, -5.1530],\n",
      "        [-0.1037, -3.6633],\n",
      "        [ 0.3387, -1.9890],\n",
      "        [ 0.7763, -0.3717],\n",
      "        [ 1.1540,  1.0810]], grad_fn=<AddmmBackward>)\n",
      "epoch: 284 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9258, -1.9673],\n",
      "        [-1.6206, -0.4367],\n",
      "        [-1.2153,  1.2132],\n",
      "        [-0.7718,  2.9171],\n",
      "        [-0.4302,  4.4014],\n",
      "        [-1.5240, -2.7678],\n",
      "        [-1.2214, -1.2164],\n",
      "        [-0.8162,  0.4289],\n",
      "        [-0.3871,  2.0892],\n",
      "        [-0.0444,  3.6162],\n",
      "        [-1.1247, -3.5860],\n",
      "        [-0.8064, -2.0266],\n",
      "        [-0.3934, -0.3819],\n",
      "        [ 0.0327,  1.2612],\n",
      "        [ 0.3813,  2.7585],\n",
      "        [-0.7797, -4.3999],\n",
      "        [-0.4215, -2.8502],\n",
      "        [ 0.0110, -1.1935],\n",
      "        [ 0.4376,  0.4249],\n",
      "        [ 0.7943,  1.8989],\n",
      "        [-0.5095, -5.1536],\n",
      "        [-0.1037, -3.6633],\n",
      "        [ 0.3388, -1.9886],\n",
      "        [ 0.7763, -0.3716],\n",
      "        [ 1.1541,  1.0810]], grad_fn=<AddmmBackward>)\n",
      "epoch: 285 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9258, -1.9674],\n",
      "        [-1.6205, -0.4366],\n",
      "        [-1.2153,  1.2131],\n",
      "        [-0.7721,  2.9167],\n",
      "        [-0.4300,  4.4025],\n",
      "        [-1.5240, -2.7677],\n",
      "        [-1.2211, -1.2162],\n",
      "        [-0.8162,  0.4287],\n",
      "        [-0.3874,  2.0886],\n",
      "        [-0.0443,  3.6163],\n",
      "        [-1.1247, -3.5860],\n",
      "        [-0.8063, -2.0262],\n",
      "        [-0.3935, -0.3818],\n",
      "        [ 0.0324,  1.2608],\n",
      "        [ 0.3814,  2.7581],\n",
      "        [-0.7797, -4.4001],\n",
      "        [-0.4214, -2.8499],\n",
      "        [ 0.0110, -1.1932],\n",
      "        [ 0.4374,  0.4249],\n",
      "        [ 0.7942,  1.8988],\n",
      "        [-0.5098, -5.1542],\n",
      "        [-0.1036, -3.6633],\n",
      "        [ 0.3390, -1.9883],\n",
      "        [ 0.7764, -0.3715],\n",
      "        [ 1.1543,  1.0810]], grad_fn=<AddmmBackward>)\n",
      "epoch: 286 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9259, -1.9674],\n",
      "        [-1.6204, -0.4365],\n",
      "        [-1.2154,  1.2129],\n",
      "        [-0.7723,  2.9163],\n",
      "        [-0.4298,  4.4035],\n",
      "        [-1.5239, -2.7677],\n",
      "        [-1.2209, -1.2159],\n",
      "        [-0.8162,  0.4286],\n",
      "        [-0.3876,  2.0881],\n",
      "        [-0.0441,  3.6165],\n",
      "        [-1.1247, -3.5859],\n",
      "        [-0.8062, -2.0258],\n",
      "        [-0.3936, -0.3818],\n",
      "        [ 0.0322,  1.2604],\n",
      "        [ 0.3815,  2.7578],\n",
      "        [-0.7798, -4.4003],\n",
      "        [-0.4213, -2.8496],\n",
      "        [ 0.0109, -1.1929],\n",
      "        [ 0.4371,  0.4249],\n",
      "        [ 0.7942,  1.8986],\n",
      "        [-0.5100, -5.1549],\n",
      "        [-0.1036, -3.6632],\n",
      "        [ 0.3392, -1.9879],\n",
      "        [ 0.7764, -0.3713],\n",
      "        [ 1.1545,  1.0810]], grad_fn=<AddmmBackward>)\n",
      "epoch: 287 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9260, -1.9675],\n",
      "        [-1.6203, -0.4364],\n",
      "        [-1.2154,  1.2128],\n",
      "        [-0.7726,  2.9160],\n",
      "        [-0.4295,  4.4045],\n",
      "        [-1.5239, -2.7676],\n",
      "        [-1.2207, -1.2157],\n",
      "        [-0.8162,  0.4284],\n",
      "        [-0.3879,  2.0876],\n",
      "        [-0.0440,  3.6166],\n",
      "        [-1.1247, -3.5859],\n",
      "        [-0.8061, -2.0254],\n",
      "        [-0.3937, -0.3817],\n",
      "        [ 0.0320,  1.2600],\n",
      "        [ 0.3816,  2.7574],\n",
      "        [-0.7798, -4.4005],\n",
      "        [-0.4212, -2.8493],\n",
      "        [ 0.0109, -1.1926],\n",
      "        [ 0.4368,  0.4249],\n",
      "        [ 0.7942,  1.8984],\n",
      "        [-0.5102, -5.1555],\n",
      "        [-0.1036, -3.6632],\n",
      "        [ 0.3394, -1.9876],\n",
      "        [ 0.7765, -0.3712],\n",
      "        [ 1.1547,  1.0810]], grad_fn=<AddmmBackward>)\n",
      "epoch: 288 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9260, -1.9675],\n",
      "        [-1.6202, -0.4363],\n",
      "        [-1.2155,  1.2127],\n",
      "        [-0.7728,  2.9156],\n",
      "        [-0.4293,  4.4055],\n",
      "        [-1.5239, -2.7676],\n",
      "        [-1.2205, -1.2155],\n",
      "        [-0.8162,  0.4282],\n",
      "        [-0.3881,  2.0870],\n",
      "        [-0.0438,  3.6168],\n",
      "        [-1.1247, -3.5859],\n",
      "        [-0.8060, -2.0250],\n",
      "        [-0.3937, -0.3816],\n",
      "        [ 0.0318,  1.2597],\n",
      "        [ 0.3817,  2.7571],\n",
      "        [-0.7799, -4.4008],\n",
      "        [-0.4211, -2.8490],\n",
      "        [ 0.0109, -1.1923],\n",
      "        [ 0.4366,  0.4249],\n",
      "        [ 0.7942,  1.8982],\n",
      "        [-0.5104, -5.1561],\n",
      "        [-0.1036, -3.6632],\n",
      "        [ 0.3396, -1.9873],\n",
      "        [ 0.7765, -0.3711],\n",
      "        [ 1.1549,  1.0811]], grad_fn=<AddmmBackward>)\n",
      "epoch: 289 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9261, -1.9676],\n",
      "        [-1.6200, -0.4361],\n",
      "        [-1.2155,  1.2125],\n",
      "        [-0.7730,  2.9153],\n",
      "        [-0.4291,  4.4065],\n",
      "        [-1.5238, -2.7676],\n",
      "        [-1.2203, -1.2153],\n",
      "        [-0.8162,  0.4281],\n",
      "        [-0.3884,  2.0865],\n",
      "        [-0.0436,  3.6169],\n",
      "        [-1.1246, -3.5859],\n",
      "        [-0.8058, -2.0246],\n",
      "        [-0.3938, -0.3816],\n",
      "        [ 0.0316,  1.2593],\n",
      "        [ 0.3818,  2.7567],\n",
      "        [-0.7799, -4.4010],\n",
      "        [-0.4210, -2.8487],\n",
      "        [ 0.0108, -1.1920],\n",
      "        [ 0.4363,  0.4249],\n",
      "        [ 0.7941,  1.8980],\n",
      "        [-0.5107, -5.1566],\n",
      "        [-0.1035, -3.6632],\n",
      "        [ 0.3398, -1.9870],\n",
      "        [ 0.7766, -0.3710],\n",
      "        [ 1.1550,  1.0811]], grad_fn=<AddmmBackward>)\n",
      "epoch: 290 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9262, -1.9676],\n",
      "        [-1.6199, -0.4360],\n",
      "        [-1.2155,  1.2124],\n",
      "        [-0.7732,  2.9149],\n",
      "        [-0.4289,  4.4075],\n",
      "        [-1.5238, -2.7675],\n",
      "        [-1.2201, -1.2151],\n",
      "        [-0.8162,  0.4279],\n",
      "        [-0.3886,  2.0860],\n",
      "        [-0.0435,  3.6171],\n",
      "        [-1.1246, -3.5858],\n",
      "        [-0.8057, -2.0242],\n",
      "        [-0.3939, -0.3815],\n",
      "        [ 0.0313,  1.2589],\n",
      "        [ 0.3819,  2.7563],\n",
      "        [-0.7799, -4.4012],\n",
      "        [-0.4209, -2.8484],\n",
      "        [ 0.0108, -1.1918],\n",
      "        [ 0.4360,  0.4249],\n",
      "        [ 0.7941,  1.8979],\n",
      "        [-0.5109, -5.1572],\n",
      "        [-0.1035, -3.6632],\n",
      "        [ 0.3400, -1.9867],\n",
      "        [ 0.7766, -0.3708],\n",
      "        [ 1.1552,  1.0811]], grad_fn=<AddmmBackward>)\n",
      "epoch: 291 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9263, -1.9677],\n",
      "        [-1.6198, -0.4359],\n",
      "        [-1.2156,  1.2123],\n",
      "        [-0.7735,  2.9146],\n",
      "        [-0.4287,  4.4084],\n",
      "        [-1.5238, -2.7675],\n",
      "        [-1.2198, -1.2150],\n",
      "        [-0.8162,  0.4278],\n",
      "        [-0.3888,  2.0855],\n",
      "        [-0.0433,  3.6172],\n",
      "        [-1.1246, -3.5858],\n",
      "        [-0.8056, -2.0239],\n",
      "        [-0.3939, -0.3815],\n",
      "        [ 0.0311,  1.2586],\n",
      "        [ 0.3820,  2.7559],\n",
      "        [-0.7800, -4.4014],\n",
      "        [-0.4208, -2.8481],\n",
      "        [ 0.0107, -1.1915],\n",
      "        [ 0.4358,  0.4249],\n",
      "        [ 0.7941,  1.8977],\n",
      "        [-0.5111, -5.1578],\n",
      "        [-0.1035, -3.6632],\n",
      "        [ 0.3401, -1.9864],\n",
      "        [ 0.7767, -0.3707],\n",
      "        [ 1.1554,  1.0812]], grad_fn=<AddmmBackward>)\n",
      "epoch: 292 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9263, -1.9677],\n",
      "        [-1.6197, -0.4358],\n",
      "        [-1.2156,  1.2121],\n",
      "        [-0.7737,  2.9142],\n",
      "        [-0.4285,  4.4094],\n",
      "        [-1.5237, -2.7675],\n",
      "        [-1.2196, -1.2148],\n",
      "        [-0.8162,  0.4276],\n",
      "        [-0.3891,  2.0850],\n",
      "        [-0.0432,  3.6173],\n",
      "        [-1.1246, -3.5858],\n",
      "        [-0.8055, -2.0235],\n",
      "        [-0.3940, -0.3814],\n",
      "        [ 0.0309,  1.2582],\n",
      "        [ 0.3821,  2.7556],\n",
      "        [-0.7800, -4.4016],\n",
      "        [-0.4207, -2.8478],\n",
      "        [ 0.0107, -1.1912],\n",
      "        [ 0.4355,  0.4249],\n",
      "        [ 0.7940,  1.8975],\n",
      "        [-0.5114, -5.1583],\n",
      "        [-0.1034, -3.6632],\n",
      "        [ 0.3403, -1.9861],\n",
      "        [ 0.7767, -0.3706],\n",
      "        [ 1.1556,  1.0812]], grad_fn=<AddmmBackward>)\n",
      "epoch: 293 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9264, -1.9678],\n",
      "        [-1.6196, -0.4357],\n",
      "        [-1.2156,  1.2120],\n",
      "        [-0.7739,  2.9139],\n",
      "        [-0.4283,  4.4103],\n",
      "        [-1.5237, -2.7674],\n",
      "        [-1.2194, -1.2146],\n",
      "        [-0.8162,  0.4275],\n",
      "        [-0.3893,  2.0845],\n",
      "        [-0.0431,  3.6174],\n",
      "        [-1.1245, -3.5857],\n",
      "        [-0.8054, -2.0231],\n",
      "        [-0.3941, -0.3814],\n",
      "        [ 0.0307,  1.2578],\n",
      "        [ 0.3822,  2.7552],\n",
      "        [-0.7800, -4.4018],\n",
      "        [-0.4206, -2.8475],\n",
      "        [ 0.0106, -1.1909],\n",
      "        [ 0.4353,  0.4249],\n",
      "        [ 0.7940,  1.8974],\n",
      "        [-0.5116, -5.1589],\n",
      "        [-0.1034, -3.6632],\n",
      "        [ 0.3405, -1.9858],\n",
      "        [ 0.7768, -0.3705],\n",
      "        [ 1.1558,  1.0812]], grad_fn=<AddmmBackward>)\n",
      "epoch: 294 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9265, -1.9678],\n",
      "        [-1.6195, -0.4356],\n",
      "        [-1.2157,  1.2119],\n",
      "        [-0.7741,  2.9136],\n",
      "        [-0.4281,  4.4113],\n",
      "        [-1.5237, -2.7674],\n",
      "        [-1.2192, -1.2144],\n",
      "        [-0.8162,  0.4274],\n",
      "        [-0.3895,  2.0840],\n",
      "        [-0.0429,  3.6175],\n",
      "        [-1.1245, -3.5857],\n",
      "        [-0.8053, -2.0228],\n",
      "        [-0.3942, -0.3814],\n",
      "        [ 0.0305,  1.2575],\n",
      "        [ 0.3823,  2.7548],\n",
      "        [-0.7801, -4.4019],\n",
      "        [-0.4205, -2.8472],\n",
      "        [ 0.0106, -1.1907],\n",
      "        [ 0.4350,  0.4250],\n",
      "        [ 0.7940,  1.8972],\n",
      "        [-0.5118, -5.1594],\n",
      "        [-0.1034, -3.6632],\n",
      "        [ 0.3407, -1.9855],\n",
      "        [ 0.7769, -0.3704],\n",
      "        [ 1.1560,  1.0813]], grad_fn=<AddmmBackward>)\n",
      "epoch: 295 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9266, -1.9679],\n",
      "        [-1.6194, -0.4355],\n",
      "        [-1.2157,  1.2118],\n",
      "        [-0.7743,  2.9133],\n",
      "        [-0.4279,  4.4122],\n",
      "        [-1.5236, -2.7674],\n",
      "        [-1.2190, -1.2142],\n",
      "        [-0.8162,  0.4272],\n",
      "        [-0.3898,  2.0836],\n",
      "        [-0.0428,  3.6176],\n",
      "        [-1.1245, -3.5857],\n",
      "        [-0.8052, -2.0224],\n",
      "        [-0.3943, -0.3813],\n",
      "        [ 0.0303,  1.2572],\n",
      "        [ 0.3824,  2.7544],\n",
      "        [-0.7801, -4.4021],\n",
      "        [-0.4204, -2.8469],\n",
      "        [ 0.0105, -1.1904],\n",
      "        [ 0.4347,  0.4250],\n",
      "        [ 0.7939,  1.8971],\n",
      "        [-0.5120, -5.1600],\n",
      "        [-0.1033, -3.6632],\n",
      "        [ 0.3409, -1.9853],\n",
      "        [ 0.7769, -0.3703],\n",
      "        [ 1.1561,  1.0814]], grad_fn=<AddmmBackward>)\n",
      "epoch: 296 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9266, -1.9679],\n",
      "        [-1.6192, -0.4353],\n",
      "        [-1.2157,  1.2117],\n",
      "        [-0.7745,  2.9130],\n",
      "        [-0.4277,  4.4131],\n",
      "        [-1.5236, -2.7673],\n",
      "        [-1.2188, -1.2140],\n",
      "        [-0.8163,  0.4271],\n",
      "        [-0.3900,  2.0831],\n",
      "        [-0.0426,  3.6177],\n",
      "        [-1.1244, -3.5856],\n",
      "        [-0.8050, -2.0220],\n",
      "        [-0.3943, -0.3813],\n",
      "        [ 0.0300,  1.2568],\n",
      "        [ 0.3824,  2.7540],\n",
      "        [-0.7801, -4.4023],\n",
      "        [-0.4203, -2.8467],\n",
      "        [ 0.0105, -1.1902],\n",
      "        [ 0.4345,  0.4250],\n",
      "        [ 0.7939,  1.8969],\n",
      "        [-0.5123, -5.1605],\n",
      "        [-0.1033, -3.6632],\n",
      "        [ 0.3411, -1.9850],\n",
      "        [ 0.7770, -0.3701],\n",
      "        [ 1.1563,  1.0814]], grad_fn=<AddmmBackward>)\n",
      "epoch: 297 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9267, -1.9680],\n",
      "        [-1.6191, -0.4352],\n",
      "        [-1.2158,  1.2116],\n",
      "        [-0.7747,  2.9127],\n",
      "        [-0.4275,  4.4140],\n",
      "        [-1.5236, -2.7673],\n",
      "        [-1.2186, -1.2139],\n",
      "        [-0.8163,  0.4269],\n",
      "        [-0.3902,  2.0826],\n",
      "        [-0.0425,  3.6178],\n",
      "        [-1.1244, -3.5856],\n",
      "        [-0.8049, -2.0217],\n",
      "        [-0.3944, -0.3812],\n",
      "        [ 0.0298,  1.2565],\n",
      "        [ 0.3825,  2.7536],\n",
      "        [-0.7802, -4.4025],\n",
      "        [-0.4202, -2.8464],\n",
      "        [ 0.0104, -1.1899],\n",
      "        [ 0.4342,  0.4251],\n",
      "        [ 0.7938,  1.8968],\n",
      "        [-0.5125, -5.1610],\n",
      "        [-0.1033, -3.6632],\n",
      "        [ 0.3413, -1.9847],\n",
      "        [ 0.7770, -0.3700],\n",
      "        [ 1.1565,  1.0815]], grad_fn=<AddmmBackward>)\n",
      "epoch: 298 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9268, -1.9681],\n",
      "        [-1.6190, -0.4351],\n",
      "        [-1.2158,  1.2115],\n",
      "        [-0.7749,  2.9124],\n",
      "        [-0.4273,  4.4149],\n",
      "        [-1.5235, -2.7673],\n",
      "        [-1.2184, -1.2137],\n",
      "        [-0.8163,  0.4268],\n",
      "        [-0.3904,  2.0822],\n",
      "        [-0.0424,  3.6179],\n",
      "        [-1.1244, -3.5855],\n",
      "        [-0.8048, -2.0213],\n",
      "        [-0.3945, -0.3812],\n",
      "        [ 0.0296,  1.2562],\n",
      "        [ 0.3826,  2.7532],\n",
      "        [-0.7802, -4.4027],\n",
      "        [-0.4201, -2.8461],\n",
      "        [ 0.0104, -1.1897],\n",
      "        [ 0.4340,  0.4251],\n",
      "        [ 0.7938,  1.8966],\n",
      "        [-0.5127, -5.1615],\n",
      "        [-0.1032, -3.6632],\n",
      "        [ 0.3414, -1.9845],\n",
      "        [ 0.7771, -0.3699],\n",
      "        [ 1.1567,  1.0816]], grad_fn=<AddmmBackward>)\n",
      "epoch: 299 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9269, -1.9681],\n",
      "        [-1.6189, -0.4350],\n",
      "        [-1.2158,  1.2114],\n",
      "        [-0.7751,  2.9121],\n",
      "        [-0.4271,  4.4158],\n",
      "        [-1.5235, -2.7673],\n",
      "        [-1.2182, -1.2135],\n",
      "        [-0.8163,  0.4266],\n",
      "        [-0.3906,  2.0817],\n",
      "        [-0.0423,  3.6180],\n",
      "        [-1.1243, -3.5855],\n",
      "        [-0.8047, -2.0210],\n",
      "        [-0.3946, -0.3812],\n",
      "        [ 0.0294,  1.2558],\n",
      "        [ 0.3827,  2.7528],\n",
      "        [-0.7802, -4.4028],\n",
      "        [-0.4200, -2.8459],\n",
      "        [ 0.0103, -1.1894],\n",
      "        [ 0.4337,  0.4251],\n",
      "        [ 0.7938,  1.8965],\n",
      "        [-0.5130, -5.1620],\n",
      "        [-0.1032, -3.6632],\n",
      "        [ 0.3416, -1.9843],\n",
      "        [ 0.7772, -0.3698],\n",
      "        [ 1.1569,  1.0816]], grad_fn=<AddmmBackward>)\n",
      "epoch: 300 Loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor([[-1.9270, -1.9682],\n",
      "        [-1.6188, -0.4349],\n",
      "        [-1.2159,  1.2113],\n",
      "        [-0.7753,  2.9118],\n",
      "        [-0.4269,  4.4167],\n",
      "        [-1.5235, -2.7672],\n",
      "        [-1.2180, -1.2134],\n",
      "        [-0.8163,  0.4265],\n",
      "        [-0.3909,  2.0813],\n",
      "        [-0.0421,  3.6181],\n",
      "        [-1.1243, -3.5855],\n",
      "        [-0.8046, -2.0207],\n",
      "        [-0.3946, -0.3811],\n",
      "        [ 0.0292,  1.2555],\n",
      "        [ 0.3828,  2.7524],\n",
      "        [-0.7803, -4.4030],\n",
      "        [-0.4199, -2.8456],\n",
      "        [ 0.0103, -1.1892],\n",
      "        [ 0.4335,  0.4252],\n",
      "        [ 0.7937,  1.8963],\n",
      "        [-0.5132, -5.1625],\n",
      "        [-0.1032, -3.6632],\n",
      "        [ 0.3418, -1.9840],\n",
      "        [ 0.7772, -0.3697],\n",
      "        [ 1.1571,  1.0817]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time used: 0.8055417999999985\n"
     ]
    }
   ],
   "source": [
    "#drift\n",
    "tis1 = time.perf_counter()    \n",
    "epoch = 300\n",
    "\n",
    "\n",
    "Loss = np.array([])\n",
    "\n",
    "x_mean1, y_mean1 = torch.from_numpy(x_mean).float(), torch.from_numpy(y_mean2).float()\n",
    "train_dataset = data.TensorDataset(x_mean1, y_mean1)\n",
    "\n",
    "\n",
    "loader = data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=1000000,\n",
    "    shuffle=True\n",
    "    )\n",
    "\n",
    "for i in range(epoch):    # 对整套数据训练iterations次\n",
    "    for step, (batch_x, batch_y) in enumerate(loader):\n",
    "        \n",
    "        optimizer1.zero_grad()\n",
    "        #optimizer2.zero_grad()\n",
    "        approx_mean = mean_model((batch_x))\n",
    "#         approx_std = ms_model((batch_x))[:, 1]\n",
    "#         log_prob = log_prob_loss(approx_mean, step_size, batch_x, batch_y)\n",
    "        absloss = square_loss(approx_mean, step_size, batch_x, batch_y)\n",
    "        loss = torch.mean(absloss)#+absloss)\n",
    "        loss.backward()\n",
    "        optimizer1.step()\n",
    "        #optimizer2.step()\n",
    "        Loss = np.append(Loss, loss.detach().numpy())\n",
    "        torch.cuda.empty_cache()\n",
    "        #print(\"step:\", i+1, \"Loss:\", loss)\n",
    "    print(\"epoch:\",i+1, \"Loss:\", loss)\n",
    "    print(mean_model(torch.Tensor(x_mean)))\n",
    "    \n",
    "## Plotting the loss function\n",
    "q=np.arange(0,len(Loss))\n",
    "plt.plot(q,Loss,'r')\n",
    "plt.show()\n",
    "\n",
    "tis2 = time.perf_counter()\n",
    "print(\"Time used:\", tis2-tis1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.00000000e-01  1.11022302e-16  4.00000000e-01  8.00000000e-01\n",
      "   1.20000000e+00]\n",
      " [-8.00000000e-01 -4.00000000e-01  2.22044605e-16  4.00000000e-01\n",
      "   8.00000000e-01]\n",
      " [-1.20000000e+00 -8.00000000e-01 -4.00000000e-01  2.22044605e-16\n",
      "   4.00000000e-01]\n",
      " [-1.60000000e+00 -1.20000000e+00 -8.00000000e-01 -4.00000000e-01\n",
      "   1.11022302e-16]\n",
      " [-2.00000000e+00 -1.60000000e+00 -1.20000000e+00 -8.00000000e-01\n",
      "  -4.00000000e-01]] [[-5.2 -3.6 -2.  -0.4  1.2]\n",
      " [-4.4 -2.8 -1.2  0.4  2. ]\n",
      " [-3.6 -2.  -0.4  1.2  2.8]\n",
      " [-2.8 -1.2  0.4  2.   3.6]\n",
      " [-2.  -0.4  1.2  2.8  4.4]]\n"
     ]
    }
   ],
   "source": [
    "true_f1 = np.flip(true_drift(x_mean)[:,0].reshape(n_x, n_x), axis = 0)\n",
    "true_f2 = np.flip(true_drift(x_mean)[:,1].reshape(n_x, n_x), axis = 0)\n",
    "print(true_f1, true_f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "estimate_f = mean_model(torch.Tensor(x_mean)).detach().numpy()\n",
    "\n",
    "estimate_f1 = np.flip(estimate_f[:,0].reshape(n_x, n_x), axis = 0)\n",
    "estimate_f2 = np.flip(estimate_f[:,1].reshape(n_x, n_x), axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "df11 = pd.DataFrame(np.round(true_f1, decimals=2),columns = [x for x in np.round(np.linspace(-1, 1, n_x+1)[:-1], decimals=2)], index = [x for x in np.round(np.linspace(1, -1, n_x+1)[1:], decimals=2)])\n",
    "#estimate_f1\n",
    "df12 = pd.DataFrame(estimate_f1,columns = [x for x in np.round(np.linspace(-1, 1, n_x+1)[:-1], decimals=2)], index = [x for x in np.round(np.linspace(1, -1, n_x+1)[1:], decimals=2)])\n",
    "\n",
    "\n",
    "df21 = pd.DataFrame(np.round(true_f2, decimals = 2),columns = [x for x in np.round(np.linspace(-1, 1, n_x+1)[:-1], decimals=2)], index = [x for x in np.round(np.linspace(1, -1, n_x+1)[1:], decimals=2)])\n",
    "#estimate_f2\n",
    "df22 = pd.DataFrame(estimate_f2,columns = [x for x in np.round(np.linspace(-1, 1, n_x+1)[:-1], decimals=2)], index = [x for x in np.round(np.linspace(1, -1, n_x+1)[1:], decimals=2)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x24b38cbb730>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#drift figure1\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (11,5))\n",
    "\n",
    "im = sns.heatmap(df11, annot=True, ax=ax1 ,cbar = False)\n",
    "ax1.set_title(\"True drift\")\n",
    "ax1.set_xlabel(\"x\")\n",
    "ax1.set_ylabel(\"y\")\n",
    "sns.heatmap(df12, annot=True, ax=ax2, cbar = False)\n",
    "ax2.set_title(\"Approximated drift\")\n",
    "ax2.set_xlabel(\"x\")\n",
    "ax2.set_ylabel(\"y\")\n",
    "\n",
    "mappable = im.get_children()[0]\n",
    "plt.colorbar(mappable, ax = [ax1,ax2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x24b38ee3ee0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAloAAAFNCAYAAADYYMFUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABNjUlEQVR4nO3dd3hUVf7H8fc3lQRCqKFLEZAioqAuKCiiIGBfe6OLfRUVK/YGu/uzoYJYEOxtVywUsYuIBURZu6iI0kso6cmc3x8zxITUCblzM+Tz8pnnmZl7Zu4nMfPlzLnnnmvOOURERESk+sX4HUBERERkT6WOloiIiIhH1NESERER8Yg6WiIiIiIeUUdLRERExCPqaImIiIh4RB0tiTgza2dmzsziymkz18xGFHl8h5ltNLO1kUkpIuEys2lmdqPfOUpjZk+a2R2VbKsaJdWmzD8i2fOY2Y4iD5OBHKAg9Ph859wzkU9VOufc0J33zWwv4EqgrXNuvZmNBMY65/r5lU/ED2b2PtATaO6cy/E5TgnOuQu8em8zc0An59zPXu0jHKpRUlka0apFnHP1dt6A34HjijxX2Mkq71uc1yxo17/LvYBNzrn1fmQSqQnMrB3QH3DA8R7uR1/Ay6EaJeFSR0swswFm9oeZXRMa9p5hZiPNbOEu7ZyZdQzdTzSzf5vZ72a2LnTIIKmM948Ntd1oZr8Ax+yy/X0zu9PMPgYygQ6h58aa2VHAAqClme0wsxeAaUDf0OP0av+FiNRMw4HFwJPAiKIbQofFppnZAjPbbmYfmFnbItudmf3DzH4JfQ7/tbOzEPqsf2xm95rZJuAWM0s1s1lmtsHMVprZRDOLMbNGoVpxXOi19czsZzMbXiTHHaH7O+vK1Wa23szWmNmJZjbMzH40s81mdn2RjAeb2Sdmlh5q+6CZJYS2fRhq9lXoc3966PljzWxZ6DWLzGy/Iu93gJktDf0+XgDqlPWLVY0SL6mjJTs1BxoBbYFxlWg/CegM7A90BFoBN5XR9jzgWOAA4EDglFLanBvabwqwcueTzrm3gaHA6tDI2+nABcAnoccNKpFVZE8wHHgmdDvazJrtsv1s4HagCbAs1K6okwh+/noBJwCji2z7G/AL0Ay4E5gCpAIdgMND+x7lnNscet2jZpYG3Assc87NKiNzc4IdnJ314VHgHKA3wdG5G82sfahtATA+lL8vcCRwEYBz7rBQm56hz/0LZnYA8ARwPtAYeAR4LfQlMAF4FXiKYF17CTi5jIygGiUeUkdLdgoANzvncpxzWeU1NDMjWHDGO+c2O+e2A3cBZ5TxktOA+5xzq0KF+u5S2jzpnPvGOZfvnMvbjZ9DZI9jZv0Ifgl60Tm3BFgBnLVLszedcx+G5m7dQHBEpU2R7ZNDn9ffgfuAM4tsW+2cm+KcywdyCX6Wr3PObXfO/Qb8H8GOBs65twh2XN4BhhHs6JQlD7gz9Jl+nmAn6v7Q+34DfEtwzhnOuSXOucWhGvAbwY7T4eW89zjgEefcp865AufcTILzTvuEbvEE606ec+5l4PNy3ks1SjyjjpbstME5l13Jtk0JTqZfEhqyTwfmhZ4vTUtgVZHHK0tps6qU50QkaATwlnNuY+jxs+xy+JAinyHn3A5gM8HPXontBD+DZW1rQrCTsnKX9q2KPJ4O7Euw87GpnNybnHM7T7jZ+QVuXZHtWUA9ADPrbGZvmNlaM9tG8Mtbk3Leuy1w5c4aFKpDbUI/V0vgT+ec2+VnKItqlHhGHS3Zye3yOINgZwoAM2teZNtGggWyu3OuQeiWGppkX5o1BAvgTntVYv/hZBXZY4XmPp4GHB7qhKwleIitp5n1LNK0TZHX1CN4yGx1adsJfgaLbiv6mdpIcCSq7S7t/wy9dyzBjtYs4KKd8zarwVTge4JnFtYHrgesnParCI6WNShyS3bOPUew5rQKjb4X/RnKoholnlFHS8ryFdDdzPY3szrALTs3OOcCBOda3Buap4GZtTKzo8t4rxeBf5hZazNrCFy7m9nWAa13TpQV2cOdSHD+UjeCcyL3B7oCHxGcO7XTMDPrF/pc3A4sds4VHYWZYGYNQ4cTLwNeKG1noRGoF4E7zSwlNKn+CuDpUJPrCXYkRgP/AmaFOl+7KwXYBuwwsy7AhbtsX0dwzthOjwIXmNnfLKiumR1jZinAJ0A+wboTb2Z/Bw4uZ9+qUeIZdbSkVM65H4HbgLeBn4CFuzS5BvgZWBwa5n8b2KeMt3sUmE+w87YU+M9uxnsX+AZYa2YbK2osEuVGADOcc78759buvAEPAmfbX8sxPAvcTPCQYW+Ck86Lmg0sIThR/k3g8XL2eSnBUe1fCH72nwWeMLPeBDtdw0MdsskEO1272zEBuIrgvLPtBGvGrh3BW4CZocOEpznnviA4if1BYAvBejQSwDmXC/w99HgzcDrl1x3VKPGMFT+ELSIi0cbMngT+cM5NLGN7jVrsU6Q20YiWiIiIiEfU0RIRERHxiA4dioiIiHhEI1oiIiIiHlFHS0RERMQjNfYq7XEJraLumGa/tK5+RwjLoNhdL5VW8w3Oz/Q7Qtg6D97ud4SwpM54u7xFImukaKwXfZt28TtCWAbHNa+4UQ0ztCDD7whh69h/q98RwtLgufd8qxdHDzzMbdy8JezXLf3qf/Odc0M8iFSqGtvREhERESnLxs1bWPxW+EueJTTrXN6lnaqdOloiIiISfZwDF/A7RYXU0RIREZHoFFBHS0RERMQDDqcRLREREREPODSiJSIiIuIZjWiJiIiIeMFBoMDvEBVSR0tERESik0cjWmYWC3wB/OmcO3Z33ksrw4uIiIgUdxnwXXW8kTpaIiIiEn2cC06GD/dWATNrDRwDPFYdMXXoUERERKJSFZd3aGJmXxR5PN05N73I4/uAq4GU3YhWSB0tERERiUKuqss7bHTOHVjaBjM7FljvnFtiZgN2I1whdbREREQk+ji8mAx/KHC8mQ0D6gD1zexp59w5VX1DzdESERGRKBRa3iHcW3nv6Nx1zrnWzrl2wBnAu7vTyQKNaImIiEi00oKlIiIiIh7w+BI8zrn3gfd3933U0RIREZEo5DSiJSIiIuIZXVRaRERExAsO53StQxEREZHq583yDtVOHS0RERGJQlVesDSi9tiO1uGH9eU/rzzBr7+tAuDVV+dwx533lWg3a+YUevfuSV5eHp9/vowLL7qG/Pz8CKcNOnTwIYyeMBIXCFCQX8CDt0xl+ef/K9EuLj6Oy+64lP379sQFAjz2zxl8OOcjHxKX1P3EQ+h7wXGYGbkZWcy9YQbrv/vd71jF7HXbGFIH9iaQlcOv46eQ+b9fymzbccZ1JO7VnG+OvCyCCf+SNPoq4nr+DbctnR03nldie3yfgSQOOwPMcNmZZM26n8Cqsn8eKV001ot+gw9h7IRRBFywXjxw88Ml6kVS3SQe+u99hY+btmjKW/95myk3PxzhtKXb98RDOCRUL3JC9WJdDagXbW4bW1gjfhv/QKk1otPTNxGf1hCLjWX7Z9/y+w3TIRCgw8NXUWfvVgDE1q9LwbYMvj16fERyJ51/NfEH9MFtS2f71aNLbI9p2Ybk868htn0nsl94nJw3X4xILk9pRMtfCxd+xgknjSi3zXPP/ZfhIy4F4OmnHmLM6LN4ZPqsSMQrYenCpXz81iIAOnRtzy1Tb2T4gJIflnP+cRbpG9M597CRmBn1G1TL5ZiqRfqqDTx92u1kb8tk7wE9GXb3GJ488Wa/YxVKHdiLxPYtWd7vIur26kzbu8/nu+OuKbVtw6F9CGRkRzhhcbkL55Pzzqskjy09Y2DjWnZMugIydxDX4yCSRown445LI5xyzxBt9WLJwqUsDNWLvbt24NZpN3LO4aOKtcnKyGL04PMLHz82d2qN+VIGwXoxq0i9OObuMTzhc71IHdibOu1b8L9+F1K3V2f2uvsCvj/u6hLtVlzwLwI7sgDYe/o1NDz2ELa8tpBfLvp3YZvWN46iYHtGxLLnfjCP3Pn/Jfmi60rd7nZsJ2vmFOIP7BexTJ5yrsIFSGuCWr8y/Nx57xbe//zzZbRu3cK3LFmZf/2jXiepDs65UtsNO30Izzz4HADOObZu2RaRfJXx55KfyN6WGby/9Cfqt2jkc6LiGhx9MJtefg+AjKU/Eptal/i0hiXaxSTXodm441l9/0uRjlhMwY/LcTu2l739528hcwcA+Su+I6ZR00hFq5VqbL1ILrte7NSmQ2saNGnAV58u9zpapf2xS71IqQH1osHgg9n08vtAsEbE1S+9RuzsZFlcLBYfF/xHfxeNjjuUzbMj17Et+P5r3I6y/z1w29Ip+OUHKPBnFNYTLhD+LcIi0tEys/pm1tvMSv61eqhPn94s+WIBb7z2FN26dS63bVxcHGeffTLz578XoXSl6zfkUGa9/wSTZt3J5Cv/XWJ7vfp1ARg9YSTT507llmk30rBJgwinrJyeZwxgxftf+R2jmITmjcldvanwcd6aTcQ3L1ncW119JmsfmU0gKyeS8XZLwmFDyV/+md8xdpvqReX1H3IoT38wg3/OvJNJpdSLoo48/gjefe39yASrgv1rSL2Ib96I3NUbCx/nllEjADo9fTM9l82kICOLLW9+Umxbvb91I29DOjm/rvE0b60XCIR/izBPOlpm9rSZNQndPxr4HzAZWGZmp3qxz10t/XI5HToeTO8DB/HQwzN45aUnym3/4JS7+OijT1n4sb//UC2c9zHDB4xm4pibGTNhVIntsbGxpLVM45sl3zBu6IV8s+RbLrzx/FLeyV9t+3Zj/9MH8O7dz/sdJWxJ3duR2LY56fM+9TtKpcV26UlC/yFkv/iY31HCpnpRdR/N+5hzDh/F9WNuYuyEkeW2PfKEI3j71XfLbeOXtn27ccDpA3gnyurFT+fcyle9RxGTEE/9Q3sU29bohP4RHc2SmsurEa2ezrmdXwluBg5zzh0F9AYmlvUiMxtnZl+Y2ReBQPjHtS+8YARffP4WX3z+FvXq1SUjIzgkPXfeu8THx9G4celfkG+cOJ6mTRtz1YRbwt7n7jpxxPE8Nn8aj82fRuNmjQuf//rT5bTYqwWpDesXa791yzayMrP4cM5CAN5/40M67dspopl31Xv4IMbOuYuxc+6iXloD0rq04ZjJY3lp7D1kpe/wNRtA2oihdH/rHrq/dQ9567aQ0PKv33N8i8bkrd1crH293vtQd7+O7Lf4Ebq+ehd1OrRgn5duj3TsSotp3Z6kUVeS+cBNuIyacxg5DKoXlXTSiBN44q1HeOKtR4rVi68+XU7LUurFTnt360BsXCw/Lv8pUlHLdODwQZw35y7OK1Ivjp08lhd8rBdNRwyl2/x76Tb/XvLWbyGhZZPCbQml1IiiXE4e6fM/pcHRB//1ZGwMDYf2ZfPrC72MLTtXhq/hhw69mgwfY2b1nXPbgADwO4BzbqOZlblP59x0YDpAXEKr8icclGLqtJlMnTYTgGbN/pqrctCB+xMTE8OmTVtKvGb0qDMZPGgAg44+vcI5Dl54deZrvDrzNQBatWtZ+HynfTsSnxhf6vyrTxYsZv++Pfly0TJ69zuAlT+tjFje0iyZtYAlsxYAUL9lY05+5HJmj5/K5l/X+pprp/Uz57J+5lwAUo/sTdrIYWyevZC6vTpTsC2TvPXF/y42zJrPhlnzAUho3ZROMyfyw6k3Rjx3ZVijNJIvuYWsRycRWPen33GqSvWikv47czb/nTkbKF4vOu/bifiEhDLnax51wsAaM5r1xawFfFGkXpxaA+rFhplz2bCzRgzsTdqoYWye/VGwRmzPKFEjYpLrEFsvKfh8bAypRx7I9s++Ldxev39Pslf8Qd6aTYiHPL7WYXXxqqN1K/CemT0EfAy8ZGavAUcA8zzaZzEn//0Yzj9/OPn5BWRnZXP2ORcVbnt99izGXTCBNWvW8fBDk1i58g8WfhTs7JR1WnckHDasP4NPHkRBfj452bncduEdhdsemz+NsUdfAMAjdz3K9fdfyyW3XkT6pnQmX1H+3IxI6n/ZSSQ1TGHo7cHDnoGCAp44ruZ0Ura+s4TUgb3p8fHU4PIOV0wp3Nb9rXv4ZvAVPqYrKen864nr0hOrl0rK/z1H9qszsdjgxzb3/Teoc8I5xNSrT9K5/wDAFRSQcdvFfkauCtWLKjh82GEMOWUQ+aF6cfOFf426PvHWI8XONhx43OFMOPd6P2KW67BS6sXjPteLre8Ga8S+C6cRyM7htyseKNzWbf69fHv0eGKSE+n4xPVYYjxmxrZP/seGp/76U210fH82vxr5w4bJl04kruv+WEoq9R98keyXn4S4WABy334dS21Iyp2PYEnJ4ByJQ09h24SRkJUZ8azVIzrW0TKvvpWZWUfgPKAzwQ7dH8Crzrn5lXl9Vb6h+q1fWle/I4RlUGwzvyOEbXB+9BWEzoPLPmuwJkqd8bZFep+1sV70bdrF7whhGRzX3O8IYRtaELmlFapLx/5b/Y4QlgbPvRfxerFTry7t3cfTw18OJPnwUUuccwd6EKlUnq2j5Zz7GSh98R8RkSJUL0QkbC46RrQivo6WmR0b6X2KSHRSvRCRckXBZHg/Fiw9yId9ikh0Ur0QkTK4qFhHy7NDh2bWBTgBaBV66k/gNedczbkei4jUCKoXIhI2R1Rc69CrBUuvAZ4HDPgsdDPgOTO71ot9ikh0Ur0QkSqrxSNaY4Duzrm8ok+a2T3AN8Akj/YrItFH9UJEqsDV3hEtgosOtizl+RahbSIiO6leiEj4di5YWktHtC4H3jGzn4BVoef2AjoCl3i0TxGJTpejeiEiYYuO5R086Wg55+aZWWfgYIpPbv3cOVfgxT5FJDqpXohIlUXBoUMvFywNAIu9en8R2XOoXohI2Gr5tQ5FREREPBQdk+HV0RIREZHoFAUjWn6sDC8iIiJSK2hES0RERKKQDh2KiIiIeEOT4UVEREQ8pI6WiIiIiBccOOd3iAqpoyUiIiLRR4cORURERDykjpaIiIiIF3TWoYiIiIg3dOhQRERExEOaDC8iIiLiAec0orU72qQ08TtC2DrENfA7Qlg65vidIHwt2231O0LY4jq38TvCHq9VSmO/I4StXVyq3xHC0jnX7wTha9Fum98RwhbftaXfEaKLOloiIiIiXtBkeBERERFvOHABzdESERER8YYOHYqIiIh4QYcORURERLzhgCg4dBjjdwARERGRPZVGtERERCQ6aY6WiIiIiBe0YKmIiIiINxxRcQkezdESERGR6BQIhH8rh5m1MbP3zOxbM/vGzC7b3Yga0RIREZHoVP1nHeYDVzrnlppZCrDEzBY4576t6huqoyUiIiLRx1X/OlrOuTXAmtD97Wb2HdAKUEdLREREahkP19Eys3bAAcCnu/M+6miJiIhIVHJVO+uwiZl9UeTxdOfc9KINzKwe8ApwuXNu225EVEdLREREopBzVR3R2uicO7CsjWYWT7CT9Yxz7j9VjbeTOloiIiISnap5jpaZGfA48J1z7p7qeE8t7yAiIiLRKeDCv5XvUOBcYKCZLQvdhu1ORI1oiYiISPRx1b8yvHNuIWDV+Z7qaImIiEh08vCsw+qijpaIiIhEp2qeo+UFdbREREQk+jg0oiUiIiLiDVfVdbQiao/vaO13QHdemTeLf4y9hrmvv11mu0efvp827VozpN/JEUxXXJ8T+jP0ghMxg+yMbJ6aOJ1V360s0a7rIT047fpzsRgjJyObx696iPUr10Y8b0rHFhx87/k07NGO5ZNe5Idpc0pt1+ehi2i4X3tcfgGbvlzBF1c/gcsviHDaoMQ+B5F6+SVYbAwZr81hx1PPldquzoD+NL77VtaPuoC873+McMryWUojEo8bh9WtDw7ylr1H/hcL/I61R9jvgO78d95TXDr2Gua8Xvbv9LGnH2Cvdq0Z3O/vEUxX3CEnHsYxF5yImZGdkcWTN0zn9+9+K9Gu26E9OPP6EcF2mdlMv3KK6kU5qloj4rt1ocE1VwBgZmx7fCbZHyyMWG6AhOPOI67zAbiMbWRNu7aU0MkkHj+OmIbNcPl55Lw2Hbfhj4hmrI326OUdYmJiuObmy/novU/KbXf0sUeSkZEZoVRl27BqPZNPv4mbhlzJ61NeZsTdF5Ta7tw7zmP6Zfdzy7AJLJ69kGMv9adzmLslgy8nzuKHaW+W227lKx8zt/8E5h1xLbF1Euhw1oDIBNxVTAwNrryMTVdcy7ozR5E8aCBx7dqWaGbJSdQ77WRy/1flS1t5K1BA7jvPkfXo9WTNuo343kdhjVv6nSrqxcTEcN3N4yusF0OOPZLMGlEv1nHnaTdy/dHjefWBlxhdRr0Yecf5TL3sXiYOu5JPZn/EiZeeEuGkQVFRL3ajRuSv+JUNoy9gw4hxbBx/DQ2uHg+xkf0nNv+rj8h+5p9lbo/vdwKBtb+T9ch15Lw6lcQh50YwnQd2Hjqs3uUdqt0e3dEacd6ZzHv9bTZt3Fxmm+S6SYy58FwevOfRCCYr3YqlP5C5LSN0/0caNm9UekPnSEpJBiCpfjLp67ZEKmIxOZu2sfmrXwjklf9tc827XxXe37xsBckty/i5PJbQrQv5f/xJweo1kJ9P5tvvUuewQ0q0qz9uNNuffg6Xm+tDyoq5jK0E1oVGOnOzCWxcjaU09DfUHmDkeWcx9/UFbKygXoy98Fym3DO9zDaR8tOSv+rFz0t/pGGLxqU3dI6kesF6kZySzBbVizLtTo1wOTlQEDyMZQkJBHsBkRX4/Xtc1o4yt8c0bUXBb98A4DatwVKbQt36kYrnDXW0/NOsRRpHHzOQp594sdx2V1x3MY89PIuszOwIJauc/qcfyfL3vyx124xrp3H5jOv59yePcMhJhzFn6n8jnK5qLC6Wdqf0Y817X/uy/5imTShYv77wccH6jcQ2bVqsTXznTsSmNSVn0W5dQzRiLLUJMc3aEli9wu8oUW1nvXiqgnpx5XWX8GgNrBcDzjiKr8uoF49d8zBXPjmR+xc/yqF/P5zXp+72FUUiwo96sbs1Ir5bF9KeeYK0px8n/Z/3FXa8aorAut+J63IQADEtO2ANmhBT358vvtXDBc86DPcWYZ50tMysjZk9b2Yfmdn1oesG7dz2qhf73NVNd05g0m334VzZvdeu++5D23ZteOvNdyMRqdK69O1O/9MH8tKkp0vdPnjMsdw36i6u6ns+C196jzMmjohwwqrpPWkUGxZ/z8ZPf/A7SunMSL3sQrY+MNXvJJUTn0jiSZeS+/YzkFuz/uEPR02oFzffeXWF9aJbqF7Mr2H1omvffTns9CN54e5ZpW4fMvY4/m/kHVzW5zw+fOldzr5xVIQTVk2NrBcV1Ii8b79n/dmj2TD6QlKGnwUJ8aW280vewtehTjJ1xt1F/MFHE1jzW1SctVemKDl06NVk+CcIXpBxMTAG+MDMjnPObQJKHvAOMbNxwDiAxsmtSKlTxlB4Gc4dczpnnBucnJpSP4Upj04GoGGjhgw4qj/5BQUsmPNeYfteB+1HjwO68dGXc4iNi6Nxk0Y8N/sxzjxhbFj73R0Dzx3CYWceCcB9I++iXqP6jJx0IfeOvJOM9JJDwCmN6tOma1t+WfYTAJ+9sYgrZt4QsbwdRw6iw9lHAPDhOf8ke116pV7X/Yq/k9g4hY8nPO5huvIFNmwkNi2t8HFsWhMKNmwofGzJycR1aE+Th+8Nbm/UiMb/vINNV0+scRPiiYkl8e+Xkv/NIgp+XOJ3mt212/WiUXIr6tUJ75v58DGnc8a5wfmN9YvUi0aNGnLEUf3JL8jnrWL1oif7HdCNhV/OJS5UL56f/ThnnDAmrP3ujqOGD2HAGYMA+PfIO0hpVJ8xky/i3yNuZ0cZ9WKvru1YEaoXn77+MRNm3RixvNFWL6qrRuSv/B2XmUV8h/Y1q3bkZpH72l+HvZP+cR+BLevLeUHN56Kgo+hVR6upc25a6P6lZnYO8KGZHU85B66dc9OB6QDtG/cM+7f31OMv8NTjL5R4/l8P3sa78z8s1skCeGbGSzwz4yUAWrVpyePPTYloJwvg3afm8e5T8wBo1LIJF0+7ikfHT2Hdr2tKbZ+xdQdJKck0a9+Cdb+uoXu//Vj9858Ry/vzkwv4+cnwznDrcNYAmg/owfun3RW8ZIJPcr/7nrg2rYht0ZyCDRtJPmogm2++s3C7y8hg7dCTCh83eegetk6ZVrMKZUjCsDG4TavJ/3y+31Gqw27Xi7aN9wv7D2vW4y8wq5R68e8Hb+fd+R8W62QBPD3jRZ6eETy02LpNS5547sGIdrIA3p41j7dnBetF45ZNuOyRq3lk/P2sLadeJKck07x9C9b+uoZ9+/dk9c+RO8ss2urF7tSI2BbNg4cdCwLENm9GXNs2FKyJ/Nmd5UpMhrwcCBQQd8ARFKz8HnKz/E61e2pxRyvezOo457IBnHNPm9laYD5Q16N9Vtqb77/AMQNO9ztGCcf/4xTqNUzh3DuCnb1AfoDbjr8GgMtnXM+T10wlff0WZl43jYunXoVzjoytGcyY8JAvees0TWXQvDuIT0nCBQJ0Pm8ocw+/mvwdWfR/egKfX/ko2evS6T15NJl/bOTI128F4I85n/PtvT7MKysIkP5/U2hy32SIiSXjjbnk//obKeeNJO+7H8leuCjymaogpnUn4nscSmD9KuqMvg2AvA9epmCFP3PfqkGNrhdz3n+RYQNO8ztGCSdedhr1GqYw4vZxABQUFHDzcVcDcNWTN/DY1Q+Tvn4Lj187lX9MuxoXcGRs3cGjqhdl240akdCzBynnnonLzwfnSP/3/QS2botM7pDEv19MTNuuWHIKSZdPIe/9lyE2+M98/pJ3iGnaksQTLgDnCGz4k5zX/T+pY7d4cK1DL1h5cxKq/KZm44GlzrkPdnn+AOCfzrlBFb1HVUa0/HZESie/I4Tl6JxEvyOErV+70r+512QNjm/jd4Sw1L1uZrVeULUi1VEvqjKi5bfD6nX0O0JYjs1N8jtC2KKyXgxt4XeEsNS96ZmI1ouieqWlug9OKXlWaEXqT523xDl3oAeRSuXJiJZz7t4ynv8SqLBoikjtoXohIlUSJZfgifjyDmZ2bKT3KSLRSfVCRMriAOdc2LdI82MdrYN82KeIRCfVCxEpQxWWdtiDlnfAzLoAJwCtQk/9CbzmnLvZq32KSHRSvRCRsNXmQ4dmdg3wPGDAZ6GbAc+ZWSlXuhSR2kr1QkSqygVc2LdI82pEawzQ3TmXV/RJM7sH+AaY5NF+RST6qF6ISNXU1hEtIAC0LOX5FqFtIiI7qV6ISPgcwQoR7i3CvBrRuhx4x8x+AlaFntsL6Ahc4tE+RSQ6XY7qhYhUQa29BI9zbp6ZdQYOpvjk1s+dcwVe7FNEopPqhYhUifPnLMJweXbWoXMuQPAisSIi5VK9EJE9lWcdLRERERFPRcEsTnW0REREJCrV2jlaIiIiIp7aedZhDaeOloiIiEQdh0a0RERERLyhES0RERER7zh1tEREREQ8oBEtEREREe9oREtERETEK+poiYiIiHjAaURLRERExDPqaImIiIh4wGlES0RERMRDzvxOUKEa29Fqm9TU7whh29sl+h0hLB1iMv2OELZ6XWL8jhC2mE6d/I6wx2uflOZ3hLB1IsnvCGGJxnqR0i3W7whhi9mns98RoopGtERERES84MAFNKIlIiIi4oloGNGKvuMwIiIiIlFCI1oiIiIShQynyfAiIiIi1U/LO4iIiIh4SJPhRURERDzinN8JKqaOloiIiEQfLe8gIiIi4h11tEREREQ84NChQxERERFvRMmhQy1YKiIiIlEouI5WuLcK39VsiJn9YGY/m9m1u5tSI1oiIiISlap7HS0ziwUeAgYBfwCfm9lrzrlvq/qe6miJiIhI1HFAoPpXhj8Y+Nk59wuAmT0PnACooyUiIiK1iMOLS/C0AlYVefwH8LfdeUN1tERERCQqVXEyfBMz+6LI4+nOuenVFKkEdbREREQkKlVxeYeNzrkDy9j2J9CmyOPWoeeqTB0tERERiT7eLO/wOdDJzNoT7GCdAZy1O2+ojpaIiIhEHYdV+2R451y+mV0CzAdigSecc9/sznuqoyUiIiIS4pybA8yprvdTR0tERESikgdnHVa7PbajdejgQxg9YSQuEKAgv4AHb5nK8s//V6JdXHwcl91xKfv37YkLBHjsnzP4cM5HPiQuXfcTD6HvBcdhZuRmZDH3hhms/+53v2MVs9dtY0gd2JtAVg6/jp9C5v9+KbNtxxnXkbhXc7458rIIJvxL0uiriOv5N9y2dHbceF6J7fF9BpI47Awww2VnkjXrfgKryv55vLY2PYOJL3/M5h3ZYHDyQZ04+5Cuxdpsz87lhhcXsnZrJvmBAMP7dePE3h19Shyd9oR6se+Jh3DoBcdBqFbMuWEG62pArahMfej89I3EN2uIxcay/bPvWHn9dAgESOrejnaTLiAmMQGXX8DK66eTseyniOSuM+pK4vb7G257Ohk3jSuxPW7/viSeODI4GztQQPZzD1Pw824dYdpta7dmMPGVT9ickQ0YJx+4N2f37VKszfbsXG54eVGoXjiGH9qFE3vt7U/gaqBrHfpo6cKlfPzWIgA6dG3PLVNvZPiA0SXanfOPs0jfmM65h43EzKjfICXSUcuVvmoDT592O9nbMtl7QE+G3T2GJ0+82e9YhVIH9iKxfUuW97uIur060/bu8/nuuGtKbdtwaB8CGdkRTlhc7sL55LzzKsljS88Y2LiWHZOugMwdxPU4iKQR48m449IIp/xLbIxx5dDedG3VmIycPM586E36dGzB3mkNCtu8sPgHOqQ14IHhA9mckc2J987mmJ7tiY+L9S13tNkT6kX6qg3MDNWKjgN6cuzdY3jc51pR2frw8wX/JrAjC4C9p19No2MPYfNrC2lzwwhW3/MiW99bSurAXrS+YTg/nHpjRLLnffwWue/MJmns1aVuz//uS/KXfQJATOv2JF0wkYyJYyKSrSyxMTFcOaQXXVs2CtaLafPos3cL9k5LLWzzwqc/0SEtlQfOGRCsFw+8wTH7tYvKeuHRgqXVbo+91mFW5l//oNdJqoMro9s77PQhPPPgcwA459i6ZVtE8lXWn0t+IntbZvD+0p+o36KRz4mKa3D0wWx6+T0AMpb+SGxqXeLTGpZoF5Nch2bjjmf1/S9FOmIxBT8ux+3YXvb2n7+FzB0A5K/4jphGTSMVrVRN6yfTtVVjAOomxtOhaSrrQ38PO5lBRk4ezjmycvJITUokNmaP/Wh7Yk+oF38UqRV/LP2JlBpQKypbH3Z2siwulpiEOIL/hALOEZuSBEBsSjJ56zZHJDeEakVG2bWCnL/+ZiyxTmFkPzVNSaJry+D/92C9qF9GvcgP1ovcfFKTEqK3XoQWLK3uax1WtwpHtMzsUuBp59yWCOSpVv2GHMq4a8fQoEkDrh1+Q4nt9erXBWD0hJHs37cnq1eu5v6JU9iyMT3CSSun5xkDWPH+V37HKCaheWNyV28qfJy3ZhPxzRuRt774n0urq89k7SOzCWTlRDpilSUcNpT85Z/5HaPQn1t28P2azfRo3aTY82f06cJlT73HoEmvkJGbx+TT+xMT48+3PNWLmuGAMwbwcw2oFZWtDwCdn7mJuvt3Yut7S9n8RnCk6Pebn6DzszfR5saRYMZ3J1wXqeiVEnfAoSSePJqY+g3IvH+i33GKCdaLLSXrxd86c9kzHzDoX/8lIzefyace6lu9qA7RcOiwMt3YZgQvqvhi6IrWlfo/YmZHm9kYM2u3y/Mlx+M9snDexwwfMJqJY25mzIRRJbbHxsaS1jKNb5Z8w7ihF/LNkm+58MbzIxUvLG37dmP/0wfw7t3P+x0lbEnd25HYtjnp8z71O0qlxXbpSUL/IWS/+JjfUQDIzMnjqmc/YMIxB1GvTkKxbYt+Ws0+LRqy4NqTeeGSY5j0xmfsyM71Kanqhd/ahWrFO1FWK348+zaW9RqNJcRT/9AeAKQNP5pVtzzBVwedx++3PkG7/7vY55TF5X/5MRkTx5D54C3B+Vo1RGZOHlc9/xEThvamXp34YtsW/bwmWC8mnMQLFw5l0ptfsCM7z6ekuy/gLOxbpFXY0XLOTQQ6AY8DI4GfzOwuMytz9pyZ3QXcAPQA3gl9y93pknJeN87MvjCzL1ZnhL8Q64kjjuex+dN4bP40GjdrXPj8158up8VeLUhtWL9Y+61btpGVmcWHcxYC8P4bH9Jp305h77e69R4+iLFz7mLsnLuol9aAtC5tOGbyWF4aew9Z6Tv8jkfaiKF0f+seur91D3nrtpDQ8q/fdXyLxuStLT68X6/3PtTdryP7LX6Erq/eRZ0OLdjnpdsjHbvSYlq3J2nUlWQ+cBMuw/9DQ3kFAa589gOG9WzPkd33KrF99pIVHNl9L8yMvRrXp1XDevy6wZ/cqheRdeDwQYybcxfjitSKYyeP5QUfa0W49aEol5NH+luf0eDogwFofOoRbJmzGIAtry+i3v7+1+fSFPy4nJimLbB69Stu7LG8ggBXPv8Rw/Zrx5Hd2pTYPnvpLxzZtU2oXqQE68XGrT4k3X2O8A8b1shDhwDOOWdma4G1QD7QEHjZzBY450qbKXgccEBo4a9bgGfNrINzbjxQ5k8ZutbQdIABrY8Ke0Dw1Zmv8erM1wBo1a5l4fOd9u1IfGJ8qfMpPlmwmP379uTLRcvo3e8AVv60MtzdVrslsxawZNYCAOq3bMzJj1zO7PFT2fzrWp+TBa2fOZf1M+cCkHpkb9JGDmPz7IXU7dWZgm2ZJQ4LbJg1nw2z5gOQ0LopnWZOjNiE1nBZozSSL7mFrEcnEVi3W1ddqBbOOW79zye0T0vl3H7dSm3TokFdPl2xll7tmrFpRxa/bdhG60b1Ipz0L6oXkfPFrAV8UaRWnPbI5bzqc60Itz7EJNchtl5S8PnYGBoc2Zvtn34LQN66LaT07c72T74hpV8Psn9dE/GfpyyW1hK3fjUAMXt1hLh43A5/v5g557j11cW0b5rKuYd2LbVNiwbJfPrLWnq1SwvWi43baN3Qv3qxu6JhMnxl5mhdBgwHNgKPAROcc3lmFgP8BJRWOOOcc/kAzrl0MzsOmG5mLwEJpbSvdocN68/gkwdRkJ9PTnYut114R+G2x+ZPY+zRFwDwyF2Pcv3913LJrReRvimdyVf8OxLxKq3/ZSeR1DCFobcHD2UECgp44ria00nZ+s4SUgf2psfHU4Onb18xpXBb97fu4ZvBV/iYrqSk868nrktPrF4qKf/3HNmvzsRigx+D3PffoM4J5xBTrz5J5/4DAFdQQMZt/h2uWLZyA28s+4VOzRpw2pQ3ALh08AGsTc8A4NS/dea8I3pw0yuLOOWB13HOcfmQXjSsW8eXvKoX/jksVCuGFakVj/lcKypTH2KSE+k04zosIR5iYti+aDnrnwp+MfttwsPsddsYLC6GQHYev139cMSyJ427nth99sPqpVLvX8+SM3sWhGpF3gdvEN+7P/F9j4KCAlxeDlnT7qjgHb237PcNvPHVb8F68XBwvc1Lj+rJ2q3BCfGnHtSJ8w7fl5v+u5hTHnwTB1w+eH/f6kV1iIIpWlhZZ9cUNjC7leAS9CW+uplZV+fcd6U8/wbwL+fcB7s8fwdwvXOuwkOWVfmG6rdBsc38jhCWwfmZFTeqYToPLucsoBoq4ZgBfkcIS9IpE6v8FVH1ovIGRlm9GBqF9WKfIf5PtQhX/OB+fkcIS9LpN/s2pNQlvqF7osnAsF936Nr/LCnnotLVrsIRLedcmQuxlFY0Q04to/1EM5tayWwiEmVUL0QkkmrtyvDOuaxytvk/8UVEagzVCxGpqoDfASoh4quUmdnSSO9TRKKT6oWIlM2CZx6GeYu0iF+CxznXK9L7FJHopHohImUJXoLH7xQV87SjZWbNgFahh38659Z5uT8RiV6qFyISroAPI1Th8qSjZWb7A9OAVGDnHIvWZpYOXOSc0+EAEQFUL0Sk6vw4FBgur0a0ngTOd84Vu+aKmfUBZgA9PdqviESfJ1G9EJE9lFcdrbq7Fk0A59xiM6vr0T5FJDqpXohI2BzRcdahVx2tuWb2JjALWBV6rg3BFaPnebRPEYlOqhciUiW19tChc+4fZjYUOIG/JreuBh5yzs3xYp8iEp1UL0SkqmrziBbOubnA3J2PzWypc+58r/YnItFL9UJEwlXbDx2WpuaP74lITaF6ISIVqrWHDsvwaAT3JSLRTfVCRCoUqPn9rMh1tJxzD0dqXyIS3VQvRKQiDqu9C5aKiIiIeC0KrsCjjpaIiIhEJ02GFxEREfGAAwKmQ4ciIiIintChQxERERGP6NChiIiIiAecaXkHEREREc9oeQcRERERj2iOloiIiIgHgmcd+p2iYjW2o9UhroHfEcLWMcfvBOFp2W6r3xHCFte5jd8Rwmbt9/U7wh4vGutFp1y/E4SnZdsorBdd2vkdIWzWsaffEaSa1diOloiIiEh5dNahiIiIiAccmqMlIiIi4hnN0RIRERHxiA4dioiIiHjAoY6WiIiIiGecDh2KiIiIeEMjWiIiIiIe0KFDEREREQ9peQcRERERj2h5BxEREREP6NChiIiIiIfU0RIRERHxSDTM0YrxO4CIiIhIuJwF52iFe9sdZvYvM/vezL42s/+aWYOKXqOOloiIiESlQBVuu2kBsK9zbj/gR+C6il6gjpaIiIhEJVeF227tz7m3nHP5oYeLgdYVvUZztERERCTqBM869HWW1mjghYoaqaMlIiIitUkTM/uiyOPpzrnpOx+Y2dtA81Jed4NzbnaozQ1APvBMRTtTR0tERESiUhXnXG10zh1Y1kbn3FHlvdjMRgLHAkc65yocUlNHS0RERKJSpA8cmtkQ4GrgcOdcZmVeo46WiIiIRB2fVoZ/EEgEFpgZwGLn3AXlvWCP7Wj1OaE/Qy84ETPIzsjmqYnTWfXdyhLtuh7Sg9OuPxeLMXIysnn8qodYv3KtD4khpWMLDr73fBr2aMfySS/yw7Q5pbbr89BFNNyvPS6/gE1fruCLq5/A5RdEOG1QYp+DSL38Eiw2hozX5rDjqedKbVdnQH8a330r60ddQN73P0Y4ZdkspRGJx43D6tYHB3nL3iP/iwV+xyqUk5vHqNumkZdfQH5BAYP+1oOLThlcot38xV8x7ZW3AdinbUsmXXJmpKNGtWitF33uCdaLrye/yPdl1Iu+D15Eo57tCeQVsHnZCj6LYL2oan2I79aFBtdcAYCZse3xmWR/sDAimXeylIYkDBuLJacCjvyvPiB/6dvF2zRqTsLQ0cSktSVv4X/I/3x+RDPuqjbWi0hf69A51zHc1+yxHa0Nq9Yz+fSbyNyWQY8BBzDi7gu448SSy12ce8d5TDlvMmtW/MkR5xzNsZeezBNXPeRDYsjdksGXE2fRamjvctutfOVjFl/8MAB9Hr6YDmcNYMWsdyIRsbiYGBpceRkbL5tAwfoNpD0xleyPFpH/W/F/oCw5iXqnnUzu/76NfMaKBArIfec5AutWQkIdkkbdSsGv3+A2rfY7GQAJ8XE8NnEcyXUSycsvYOStU+nXcx/269S2sM3KNRt5fPb7zLz5QurXS2bT1h0+Jo5O0Vovltw4i9ZDyq8Xv/3nYz65JFgvDnn4YvY+awA/R6Je7EZ9yF/xKxtGXwAFAWIaNyJt1qOsXbgICiI3fuECAXLfewG3/neIr0Od4TdRsPLbYrXBZWeQ986zxHbsFbFc5alt9aIGnHVYKXvsOlorlv5A5raM0P0fadi8UekNnSMpJRmApPrJpK/bEqmIJeRs2sbmr34hkFf+t801735VeH/zshUktyzjZ/NYQrcu5P/xJwWr10B+Pplvv0udww4p0a7+uNFsf/o5XG6uDynL5zK2BjtZALnZBDauxlIa+huqCDMjuU4iAPkFwW+pWPGvcP957zPOGNyX+vWCf8eNU+tFPGe0i+p6UcHoVNF6senLFSS3iEy92J364HJyCjtVlpCALxdaydga7GQB5GUT2LQGq9egeJvM7QTW/gYBf44o7Ko21otIr6NVFXvsiFZR/U8/kuXvf1nqthnXTuPyGdeTm51L9o5M7jjp+ginqzqLi6XdKf1YeuNTvuw/pmkTCtavL3xcsH4jCd27FmsT37kTsWlNyVn0KSlnnx7piGGx1CbENGtLYPUKv6MUUxAIcOYND/D72k2cPrgv+3Xcq9j2lWs2ADDilocpCAS48ORBHNpzHz+i7hFUL6rH7taH+G5daHjD1cQ2b8aW2+6O6GjWrqx+Y2Ka7UVgzS++Zais2lYvouGi0p6MaJnZSWbWKHS/qZnNMrPlZvaCmVW4imp16tK3O/1PH8hLk54udfvgMcdy36i7uKrv+Sx86T3OmDgikvF2S+9Jo9iw+Hs2fvqD31FKZ0bqZRey9YGpfiepWHwiiSddSu7bz0Butt9piomNieHFuy/nrQev538rVvHTquJzgvIDAVau3chjE89n0iVnceujr7AtI8untOFTvYiMA+8O1osNn9WQelFBfcj79nvWnz2aDaMvJGX4WZAQH+GAIfGJJJ5wMXnvPlfjakNp9vR6UZTDEajCLdK8OnR4p3Nuc+j+g8CXwFBgLjCjrBeZ2Tgz+8LMvvhhe/jfHAaeO4Rb5vyLW+b8iwZpDWndpS0jJ13IlPMmk5Fe8jh0SqP6tOnall+W/QTAZ28somPvyPbsO44cxOAFdzF4wV3Uadag0q/rfsXfSWycwpc3V7hWmmcCGzYSm5ZW+Dg2rQkFGzYUPrbkZOI6tKfJw/fS7D/PktC9G43/eQfxXTr7EbdsMbEk/v1S8r9ZRMGPS/xOU6b6dZM4qNveLPqq+D+UzRqlMqBXV+LjYmmd1oi2LZrw+9qNPqWsEtWLSuo0chBDFtzFkAV3kRRGvdj3ir9Tp3EKS2+JXL2orvqQv/J3XGYW8R3aRyx7oZhYEk+4mPzvFlPw09LI73837MH1opjafOgwtsj9js65nWPCT5rZ5WW9KLQy63SA0e1OCfv38e5T83j3qXkANGrZhIunXcWj46ew7tc1pbbP2LqDpJRkmrVvwbpf19C9336s/vnPcHe7W35+cgE/PxneWW4dzhpA8wE9eP+0u6DitdI8k/vd98S1aUVsi+YUbNhI8lED2XzznYXbXUYGa4eeVPi4yUP3sHXKtBp11iFAwrAxuE2rfT9jqDSbt+0gLjaW+nWTyM7NY/Hynxh13IBibQYe2J25i5Zx4oCD2LItg5VrNtI6zZ95e1WkelFJPz25gJ+qWC/ei3C92J36ENuiefCwY0GA2ObNiGvbhoI1kT+7M2HIKAKb1pD/xVsR33dV1JJ6UUw0HDr0qqP1vpndBtwdun+Sc+6/ZnYEsNWjfRZz/D9OoV7DFM69YywAgfwAtx1/DQCXz7ieJ6+ZSvr6Lcy8bhoXT70K5xwZWzOYMcGfM4gA6jRNZdC8O4hPScIFAnQ+byhzD7+a/B1Z9H96Ap9f+SjZ69LpPXk0mX9s5MjXbwXgjzmf8+29/4184IIA6f83hSb3TYaYWDLemEv+r7+Rct5I8r77keyFiyKfKUwxrTsR3+NQAutXUWf0bQDkffAyBSu+9jlZ0Mb07Uyc+iKBQICAcwzusx+H9+rKQy+9RfcOrRnQuxuH7NeZRV//yEkT/o+YmBjGnzWMBil1/Y4eDtWLKqjTNJWj5/5VL/YZO5Q3BwTrxeFPTeCzqx4la106B00aTcYfGxkUqher5nzON5GoF7tRHxJ69iDl3DNx+fngHOn/vp/A1m3eZy4iplUn4rofQmDDKmJH3AJA7oevEFO/MQD5X70PdetT59ybsIQkcI643oPIfmKib4cYa0m9KBQtZx1aJVaPD/9NzeKBGwhecBGCV7fOAF4HrnXO/V7Re1TlG6rfjs5J9DtCWPq1K/2be03W4Pg2fkcIW+zgkypuVIPU6X1iRFemqa31YlBudNWLw9pGX71o+Pd2fkcIW8zA4/2OEJZI14uimiU2cme1KLlOWEXuW/nCkvIuwVPdPBnRcs7lAbcAt5hZKhDnnNvkxb5EJLqpXohIVdXmQ4eFnHMRGfoXkeineiEi4XBRcOgw4guWmll0nbohIr5RvRCRsuy81mG4t0iL+IKlzrmaca0CEanxVC9EpDzRMBne046WmTUDWoUe/umcW+fl/kQkeqleiMieyJOOlpntD0wDUoGdC820NrN04CLnnA4HiAigeiEiVVfzx7O8G9F6EjjfOfdp0SfNrA/BlZ57erRfEYk+T6J6ISJhipZ1tLzqaNXdtWgCOOcWm1l0rowmIl5RvRCRKqnNyzvMNbM3gVnAqtBzbYDhwDyP9iki0Un1QkSqwEXF8g5eLVj6DzMbCpzAX5NbVwMPOefmeLFPEYlOqhciUhU7l3eo6Tw769A5NxeYu/OxmS11zp3v1f5EJHqpXohIVdTaEa0y+HY9JBGJOqoXIlKhWj2iVYpHI7gvEYluqhciUi4HBJxGtAo55x6O1L5EJLqpXohIZdT8bpYPl+ARERERqQ61eR0tEREREc+42ry8g4iIiIjXNBleRERExCM6dCgiIiLiAYfW0RIRERHxjA4dioiIiHjBgYuCdbRi/A4gIiIisqfSiJaIiIhEneBFpWv+iFaN7Wjt7RL9jhC2DjGZfkcIS70u0TegGdOpk98Rwhbbdj+/I+zxorJekOV3hLBEY72wjp39jhA21YvwaI6WiIiIiCe0YKmIiIiIJ3ToUERERMRD0XDWoTpaIiIiEpU0R0tERETEA1oZXkRERMRDmqMlIiIi4gmnOVoiIiIiXtBZhyIiIiIe0hwtEREREY8EdOhQRERExBs1v5uljpaIiIhEIc3REhEREfGMU0dLRERExCvRsLxDjN8BRERERPZUGtESERGRqBMtc7Q0oiUiIiJRyVXhv+pgZleamTOzJhW11YiWiIiIRB/nzxwtM2sDDAZ+r0x7jWiJiIhI1HGhsw7DvVWDe4GrqeQyXhrREhERkagU6REtMzsB+NM595WZVeo16miJiIhIVKriCFUTM/uiyOPpzrnpOx+Y2dtA81JedwNwPcHDhpWmjpaIiIhEpSpObt/onDuwzPd07qjSnjezHkB7YOdoVmtgqZkd7JxbW9b71aqOVvcTD6HvBcdhZuRmZDH3hhms/65Sc9kiZq/bxpA6sDeBrBx+HT+FzP/9UmbbjjOuI3Gv5nxz5GURTPiXpNFXEdfzb7ht6ey48bwS2+P7DCRx2BlghsvOJGvW/QRWlf3zeG1tegYTX/6YzTuyweDkgzpx9iFdi7XZnp3LDS8uZO3WTPIDAYb368aJvTv6lPgvBQUFnD7mH6Q1bcLD/7q11DYL3lvI+Il38vxj97Nv184RTrjnqan1ou3tY2gwsBeBrBxWjH+QzOVlf6Y6P3kdiXs1Y/nAywFoPeFMGh59EM458jduZcXlU8hbtyUiuaOvXuxg4osfsXlHFmCcfHBnzu7XvVibbZk53PzyQv7YvJ2EuFhuPaUfHZs39CdwSG2qFY7IXlTaObccSNv52Mx+Aw50zm0s73W1qqOVvmoDT592O9nbMtl7QE+G3T2GJ0+82e9YhVIH9iKxfUuW97uIur060/bu8/nuuGtKbdtwaB8CGdkRTlhc7sL55LzzKsljS88Y2LiWHZOugMwdxPU4iKQR48m449IIp/xLbIxx5dDedG3VmIycPM586E36dGzB3mkNCtu8sPgHOqQ14IHhA9mckc2J987mmJ7tiY+L9S03wNMvzaZDu73YkZFZ6vaMjEyefmk2+3XbJ8LJ9lw1sV6kDuxFnfYt+OrQi6nXqzPt7x7HN8deW2rbhkP/RkFGVrHn1kx9lT/+9RwAzcYMo9X40/jt2kc8zw3RWC9iuPKYg+jaqkmwXkx5jT6dWrF3swaFbR57/2v2admIe4cfya/r07l79mKmnzfEt8xQ22pF9S3X4KVaddbhn0t+Intb8I/vz6U/Ub9FI58TFdfg6IPZ9PJ7AGQs/ZHY1LrEp5X8dhSTXIdm445n9f0vRTpiMQU/Lsft2F729p+/hcwdAOSv+I6YRk0jFa1UTesn07VVYwDqJsbToWkq67cVL0ZmkJGTh3OOrJw8UpMSiY3x92Oydv0GPlz0GScfd3SZbaY8OovR55xKQmJCBJPt2WpivWh49MFsfPl9AHZUUCNanH88q+97udjzBTv+6njFJtWBCI4GRGe9CC6R9Fe9yCjW5pd16Ry8dwsA2qc1YPWWHWzanlXivSKlNtaKgHNh36qLc65dRaNZ4FFHy8zizOx8M5tnZl+HbnPN7AIzi/din+HqecYAVrz/ld8xiklo3pjc1ZsKH+et2UR885LFvdXVZ7L2kdkEsnIiGW+3JBw2lPzln/kdo9CfW3bw/ZrN9GhdfK25M/p04dcNWxk06RVOmfIGE445kJiYyp1Z4pXJ9z/CFReNwaz0j+u3P/zM2vUbOfyQgyOcrHqoXlReQvNG5Kz+q67nrt5EQik1ovXVZ7Jm2msUlFIjWl9zFvt/MZ3Gfz+MP/71vKd5q6rG1YvN2/l+9WZ6tCne+evcohHv/G8lAMtXbWBN+g7Wbc0o7S0iYk+vFbty+LdgaTi8+qr+FLA/cAswLHS7FegJPO3RPiutbd9u7H/6AN69u2YWmfIkdW9HYtvmpM/71O8olRbbpScJ/YeQ/eJjfkcBIDMnj6ue/YAJxxxEvTrFv9Ut+mk1+7RoyIJrT+aFS45h0hufsSM716ek8P7Hn9KoYQO6d+lU6vZAIMA/p0xnwqUl57xEEdWLapTcvR112jVnSxk14o/Jz7LswHFs+s+HNBs9NMLpKlYj68Uz7zHhuINL1IvRA3qwPTuX0+6fzfOLvmOflo19+2JWS2pFCX6OaFWWV3O0ejvndp1h9wew2Mx+LOtFZjYOGAdwQqODOaje7k9C7j18EAeccQQAz4/8J8mNUjhm8lieH/FPstJ37Pb77660EUNpevYgADKW/UxCy8aF2+JbNCZv7eZi7ev13oe6+3Vkv8WPYHExxDVOZZ+XbueHU2+MaO7KimndnqRRV5J5z3W4jG1+xyGvIMCVz37AsJ7tObL7XiW2z16ygtGHd8fM2KtxfVo1rMevG7bRo02FV1nwxJdff8v7Cxfz0Sefk5ObR0ZGJtfc+k8m33w1ABmZWfz8y0pGXRJ8vHHzFi695lamTL45mia5ql6Uo9nIIcVqRGLLJuxMktCyMbml1oi92f/TaVhsLHFN6tP15dv47pSbirXb+N8P2eepifz57xci8WNUSo2sF0+/y7D9O3Dkvu1KbK9XJ4HbTu0PBNdzGjb5ZVo3SolwyqBaUitKiIY5Wl51tDab2anAK865AIAFxzJPBco8xSW0jsV0gDvbnl0tv70lsxawZNYCAOq3bMzJj1zO7PFT2fxrmWdiRtT6mXNZP3MuAKlH9iZt5DA2z15I3V6dKdiWSd764r+uDbPms2HWfAASWjel08yJNbaTZY3SSL7kFrIenURg3Z9+x8E5x63/+YT2aamc269bqW1aNKjLpyvW0qtdMzbtyOK3Ddto3ahehJP+ZfyFoxh/4SgAPlv6NU8+90ph4QRIqVeXhXP++ody5CVXc9XFY6OtcKpelGPdk/NY9+Q8ABoc2Ztmo4ay6dWF1CujRqyfNZ/1RWrEPrNuKOxkJbZvQc6va4DgfK/sn/3/XO5UI+vFywtpn9aAc/vvW2qbbVk5JMXHER8Xy38+/5He7ZuVGPWKlFpSK4pxPo1QhcurjtYZwGTgYTPbWQUaAO+Ftvmi/2UnkdQwhaG3B/8YAwUFPHFczemkbH1nCakDe9Pj46nB5R2umFK4rftb9/DN4Ct8TFdS0vnXE9elJ1YvlZT/e47sV2discE/qdz336DOCecQU68+Sef+AwBXUEDGbRf7lnfZyg28sewXOjVrwGlT3gDg0sEHsDY9OKfi1L915rwjenDTK4s45YHXcc5x+ZBeNKxbx7fMZXnw0Vl079KZI/r38TtKdVC9qKT0d5bQ4Mhe9Fz0MIGsHH4Z/2Dhtn0X/B//G3Rlua/f6/pzqLN3KwgEyPlzA79eE5kzDiEa68V63vhyBZ2aN+S0+2cDcOnRvf6qF3268Ov6rdz40kcYsHezBtxycj/f8pZlD6sVJUTDiJZ5vXy9mTUGcM5tqqhtUdX1DTWSBueXfjptTdV5cNlnANVUCccM8DtC2OIGnOV3hLDEN+ng2+z/2lQvjsrz7+y0quhytP+H8sKVcHyp607WaHH9T/M7Qlj8rBeJccmuZWrpc9LK89vmr5eUt2BpdfP8vHXn3KaiRdPMSlvWXkRE9UJE9jh+LBD0uA/7FJHopHohImUK4MK+RVrEV4Z3zh0T6X2KSHRSvRCRsjgcXk9/qg4R72iZWT3nnP/rKohIjad6ISLl8WOEKlx+HDr81od9ikh0Ur0QkTI558K+RZonI1pmVtY6BAb4tyiRiNQ4qhciUhUOomIdLa9GtO4CGgIpu9zqebhPEYlOqhciUiXRcK1Dr+ZoLQVedc4t2XWDmY31aJ8iEp1UL0QkfD4dCgyXVx2tUUCxBQfNrLlzbi0QsUXCRCQqqF6ISJXU2snwzrkfnHMbd3l6TmjbOi/2KSLRSfVCRKrCUYsnw5fBt2X6RSTqqF6ISIWiYTJ8JDtaj0ZwXyIS3VQvRKRCtXmOVgnOuYcjtS8RiW6qFyJSEefTJXXCFfGV4UVERESqg0a0RERERLzgNEdLRERExDN+LEAaLnW0REREJOpEyyV41NESERGRKBQdK8PrOmIiIiIiHtGIloiIiEQlzdESERER8Ug0HDpUR0tERESizs5rHdZ06miJiIhIVKr53SywaOgNVjczG+ecm+53jsqKtrwQfZmjLS9EZ+ZoE42/Y2X2XrTlhejMXBEzmwc0qcJLNzrnhlR3nrLU1o7WF865A/3OUVnRlheiL3O05YXozBxtovF3rMzei7a8EJ2Z9xRa3kFERETEI+poiYiIiHiktna0ou04dbTlhejLHG15ITozR5to/B0rs/eiLS9EZ+Y9Qq2coyUiIiISCbV1REtERETEc3tsR8vMupjZJ2aWY2ZXldOuvZl9amY/m9kLZpYQyZy7ZDEzeyCU5Wsz61VGuwQzm25mP5rZ92Z2cqSzFslSYWYzSzazN0NZvzGzSX5kDWUZYmY/hPJeW8r2K8zs29DP8o6ZtfUj5y6Zys0canNaKPc3ZvZspDNGO9UL70VbrQjlUb2Q3eec2yNvQBpwEHAncFU57V4EzgjdnwZc6GPmYcBcwIA+wKdltLsVuCN0PwZoUpMzA8nAEaH7CcBHwFAfssYCK4AOoRxfAd12aXMEkBy6fyHwgl+/2zAydwK+BBqGHqf5mTkab6oXNSNvTakVof2rXuhWLbc9dkTLObfeOfc5kFdWGzMzYCDwcuipmcCJ3qcr0wnALBe0GGhgZi1KaTcauBvAORdwzm2MZMhdVJjZOZfpnHsvdD8XWAq0jnxUDgZ+ds79EsrxPMH8hZxz7znnMkMPF+NPzqIqzAycBzzknNsCwb/9CGeMeqoXERFNtQJUL6Sa7LEdrUpqDKQ75/JDj/8AWvmYpxWwqsjjEnnMrEHo7u1mttTMXjKzZhHKV5oKMxcVyn8c8I63sUoVVlZgDMFv4H6qTObOQGcz+9jMFptZxFY8rmVUL3ZPNNUKUL2QalLbO1rRKI7gt6ZFzrlewCfAv/2NVDlmFgc8BzzgnPvF7zzlMbNzgAOBf/mdpRLiCB4OGACcCTxa5B9Yqd2isl5EU60A1Qsp3x7V0TKzi81sWejWshIv2URw+HrnxbVbA396l7CkopmBNUCbIptLy7MJyAT+E3r8ElDqJFivVCHzTtOBn5xz93mbsEx/UomsZnYUcANwvHMuJ0LZylKZzH8Arznn8pxzvwI/EiykUg7VC+9Fca0A1QupLn5PEvP6BtxC+ZNbX6L45NaLfMx6DMUni35WRrvngYGh+yOBl6Ig8x3AK0CMj1njgF+A9vw1UbT7Lm0OIDiZtJNfOauQeQgwM3S/CcFDB439zh6NN9WLGpHX91oRyqF6oVv1/H/xO4BnPxg0J9hz3wakh+7XD22bA7QM3e8AfAb8HCqiiT5mNuCh0Ad3OXBgkW3LitxvC3wIfE1w/sJeNTkzwW9VDvgOWBa6jfUp7zCC3+BWADeEnruN4LdRgLeBdUVyvubX7zaMzAbcA3wb+n9wht+Zo+2melEz8takWhHKo3qh227ftDK8iIiIiEf2qDlaIiIiIjWJOloiIiIiHlFHS0RERMQj6miJiIiIeEQdLRERERGPqKMlIiIi4hF1tEREREQ8oo6WVBszO8jMvjazOmZW18y+MbN9/c4lIjWP6oXUFlqwVKqVmd0B1AGSgD+cc3f7HElEaijVC6kN1NGSamVmCcDnQDZwiHOuwOdIIlJDqV5IbaBDh1LdGgP1gBSC31RFRMqieiF7PI1oSbUys9eA5wlePb6Fc+4SnyOJSA2leiG1QZzfAWTPYWbDgTzn3LNmFgssMrOBzrl3/c4mIjWL6oXUFhrREhEREfGI5miJiIiIeEQdLRERERGPqKMlIiIi4hF1tEREREQ8oo6WiIiIiEfU0RIRERHxiDpaIiIiIh5RR0tERETEI/8PhbeD2RTq0UwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 792x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#drift figure2\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (11,5))\n",
    "\n",
    "im = sns.heatmap(df21, annot=True, ax=ax1 ,cbar = False)\n",
    "ax1.set_title(\"True drift\")\n",
    "ax1.set_xlabel(\"x\")\n",
    "ax1.set_ylabel(\"y\")\n",
    "sns.heatmap(df22, annot=True, ax=ax2, cbar = False)\n",
    "ax2.set_title(\"Approximated drift\")\n",
    "ax2.set_xlabel(\"x\")\n",
    "ax2.set_ylabel(\"y\")\n",
    "\n",
    "mappable = im.get_children()[0]\n",
    "plt.colorbar(mappable, ax = [ax1,ax2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-f08feca9d878>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;31m#         absloss = abs_loss(approx_mean, approx_std, step_size, batch_x, batch_y)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_prob1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#+log_prob2)#+absloss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0moptimizer2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m#optimizer3.step()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\aboutstudy\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\aboutstudy\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#diffusivity 1\n",
    "tis1 = time.perf_counter()    \n",
    "epoch = 10 #10 \n",
    "\n",
    "\n",
    "Loss = np.array([])\n",
    "\n",
    "x_data1, y_data1 = torch.from_numpy(x_data).float(), torch.from_numpy(y_data).float()\n",
    "train_dataset = data.TensorDataset(x_data1, y_data1)\n",
    "\n",
    "\n",
    "loader = data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    "    )\n",
    "\n",
    "for i in range(epoch):    # 对整套数据训练iterations次\n",
    "    for step, (batch_x, batch_y) in enumerate(loader):\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "        optimizer2.zero_grad()\n",
    "#         optimizer3.zero_grad()\n",
    "        approx_mean1 = mean_model((batch_x))[:, 0]\n",
    "        approx_std1 = std_model(((batch_x)[:,1]).reshape(-1,1))[:, 0]\n",
    "        log_prob1 = log_prob_loss(approx_mean1, approx_std1, step_size, batch_x[:,0], batch_y[:,0])\n",
    "        \n",
    "#         approx_mean2 = mean_model((batch_x))[:, 1]\n",
    "#         approx_std2 = std_model2(((batch_x)[:,1]).reshape(-1,1))[:, 0]\n",
    "#         log_prob2 = log_prob_loss(approx_mean2, approx_std2, step_size, batch_x[:,1], batch_y[:,1])\n",
    "#         print(log_prob)\n",
    "#         absloss = abs_loss(approx_mean, approx_std, step_size, batch_x, batch_y)\n",
    "        loss = torch.mean(log_prob1)#+log_prob2)#+absloss)\n",
    "        loss.backward()\n",
    "        optimizer2.step()\n",
    "        #optimizer3.step()\n",
    "        Loss = np.append(Loss, loss.detach().numpy())\n",
    "        torch.cuda.empty_cache()\n",
    "        #print(\"step:\", i+1, \"Loss:\", loss)\n",
    "    print(\"epoch:\",i+1, \"Loss:\", loss)\n",
    "    print(std_model(torch.Tensor(x_data[:,1]).reshape(-1,1))[::1000])\n",
    "#     print(std_model(torch.Tensor(x_data))[::1000])\n",
    "    \n",
    "## Plotting the loss function\n",
    "q=np.arange(0,len(Loss))\n",
    "plt.plot(q,Loss,'r')\n",
    "plt.show()\n",
    "\n",
    "tis2 = time.perf_counter()\n",
    "print(\"Time used:\", tis2-tis1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_std1 = std_model(torch.Tensor(x_data[:,1]).reshape(-1,1))[::1000]\n",
    "estimated_std1 = estimated_std1.reshape(n_x,n_x)\n",
    "# estimated_std2 = torch.load('2d_1.5_lin_lin_s2.pt')  \n",
    "# print(estimated_std1,estimated_std2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#diffusivity 2\n",
    "tis1 = time.perf_counter()    \n",
    "epoch = 20 #18 20\n",
    "\n",
    "\n",
    "Loss = np.array([])\n",
    "\n",
    "x_data1, y_data1 = torch.from_numpy(x_data).float(), torch.from_numpy(y_data).float()\n",
    "train_dataset = data.TensorDataset(x_data1, y_data1)\n",
    "\n",
    "\n",
    "loader = data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    "    )\n",
    "\n",
    "for i in range(epoch):    # 对整套数据训练iterations次\n",
    "    for step, (batch_x, batch_y) in enumerate(loader):\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         optimizer2.zero_grad()\n",
    "        optimizer3.zero_grad()\n",
    "#         approx_mean1 = mean_model((batch_x))[:, 0]\n",
    "#         approx_std1 = std_model(((batch_x)[:,0]).reshape(-1,1))[:, 0]\n",
    "#         log_prob1 = log_prob_loss(approx_mean1, approx_std1, step_size, batch_x[:,0], batch_y[:,0])\n",
    "        \n",
    "        approx_mean2 = mean_model((batch_x))[:, 1]\n",
    "        approx_std2 = std_model2(((batch_x)[:,0]).reshape(-1,1))[:, 0]\n",
    "        log_prob2 = log_prob_loss(approx_mean2, approx_std2, step_size, batch_x[:,1], batch_y[:,1])\n",
    "#         print(log_prob)\n",
    "#         absloss = abs_loss(approx_mean, approx_std, step_size, batch_x, batch_y)\n",
    "        loss = torch.mean(log_prob2)#+log_prob2)#+absloss)\n",
    "        loss.backward()\n",
    "#         optimizer2.step()\n",
    "        optimizer3.step()\n",
    "        Loss = np.append(Loss, loss.detach().numpy())\n",
    "        torch.cuda.empty_cache()\n",
    "        #print(\"step:\", i+1, \"Loss:\", loss)\n",
    "    print(\"epoch:\",i+1, \"Loss:\", loss)\n",
    "    print(std_model2(torch.Tensor(x_data[:,0]).reshape(-1,1))[::1000])\n",
    "#     print(std_model(torch.Tensor(x_data))[::1000])\n",
    "    \n",
    "## Plotting the loss function\n",
    "q=np.arange(0,len(Loss))\n",
    "plt.plot(q,Loss,'r')\n",
    "plt.show()\n",
    "\n",
    "tis2 = time.perf_counter()\n",
    "print(\"Time used:\", tis2-tis1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_std2 = std_model2(torch.Tensor(x_data[:,0]).reshape(-1,1))[::1000]\n",
    "estimated_std2 = estimated_std2.reshape(n_x,n_x);estimated_std2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#true_std\n",
    "true_s1 = true_diffusivity(x_mean)[:,0].reshape(n_x, n_x)\n",
    "true_s2 = true_diffusivity(x_mean)[:,1].reshape(n_x, n_x)\n",
    "df31 = pd.DataFrame(true_s1,columns = [x for x in np.round(np.linspace(-1, 1, n_x+1)[:-1], decimals=2)], index = [x for x in np.round(np.linspace(1, -1, n_x+1)[1:], decimals=2)])\n",
    "df32 = pd.DataFrame(true_s2,columns = [x for x in np.round(np.linspace(-1, 1, n_x+1)[:-1], decimals=2)], index = [x for x in np.round(np.linspace(1, -1, n_x+1)[1:], decimals=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#diffusivity figure1\n",
    "dfs1 = pd.DataFrame(estimated_std1.detach().numpy(),columns = [x for x in np.round(np.linspace(-1, 1, n_x+1)[:-1], decimals=2)], index = [x for x in np.round(np.linspace(1, -1, n_x+1)[1:], decimals=2)])\n",
    "dfs2 = pd.DataFrame(estimated_std2.detach().numpy(),columns = [x for x in np.round(np.linspace(-1, 1, n_x+1)[:-1], decimals=2)], index = [x for x in np.round(np.linspace(1, -1, n_x+1)[1:], decimals=2)])\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (11,5))\n",
    "\n",
    "im = sns.heatmap(df31, annot=True,fmt='.2f', ax=ax1, vmin=0, vmax=2, cbar = False)\n",
    "ax1.set_title(\"true diffusivity\")\n",
    "ax1.set_xlabel(\"x\")\n",
    "ax1.set_ylabel(\"y\")\n",
    "sns.heatmap(dfs1, annot=True, fmt='.2f', ax=ax2, vmin=0, vmax=2, cbar = False)\n",
    "ax2.set_title(\"Approximated diffusivity\")\n",
    "ax2.set_xlabel(\"x\")\n",
    "ax2.set_ylabel(\"y\")\n",
    "\n",
    "mappable = im.get_children()[0]\n",
    "plt.colorbar(mappable, ax = [ax1,ax2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#diffusivity figure2\n",
    "dfs1 = pd.DataFrame(estimated_std1.detach().numpy(),columns = [x for x in np.round(np.linspace(-1, 1, n_x+1)[:-1], decimals=2)], index = [x for x in np.round(np.linspace(1, -1, n_x+1)[1:], decimals=2)])\n",
    "dfs2 = pd.DataFrame(estimated_std2.detach().numpy(),columns = [x for x in np.round(np.linspace(-1, 1, n_x+1)[:-1], decimals=2)], index = [x for x in np.round(np.linspace(1, -1, n_x+1)[1:], decimals=2)])\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (11,5))\n",
    "\n",
    "im = sns.heatmap(df32, annot=True, fmt='.2f', ax=ax1 ,vmin=0, vmax=2, cbar = False)\n",
    "ax1.set_title(\"true diffusivity\")\n",
    "ax1.set_xlabel(\"x\")\n",
    "ax1.set_ylabel(\"y\")\n",
    "sns.heatmap(dfs2, annot=True, fmt='.2f', ax=ax2, vmin=0, vmax=2, cbar = False)\n",
    "ax2.set_title(\"Approximated diffusivity\")\n",
    "ax2.set_xlabel(\"x\")\n",
    "ax2.set_ylabel(\"y\")\n",
    "\n",
    "mappable = im.get_children()[0]\n",
    "plt.colorbar(mappable, ax = [ax1,ax2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#L2loss\n",
    "L2lossf=torch.mean(torch.square(torch.tensor(estimate_f)-torch.tensor(true_drift(x_mean))))\n",
    "L2lossg=torch.mean(torch.square(estimated_std1-torch.tensor(true_s1)))+torch.mean(torch.square(estimated_std2-torch.tensor(true_s2)))\n",
    "print(L2lossf,L2lossg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
